<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[A Malloc Tutorial]]></title>
      <url>%2F2019%2F02%2F17%2Fa_malloc_tutorial%2F</url>
      <content type="text"><![CDATA[前言本篇文章是对该文章的翻译，如有疑问可对照原文。 一、介绍什么是malloc？如果连这个名儿都没有听说的话，那么应该在读这篇文章之前先去学习一下Unix环境下的C语言。对于程序员来说，malloc是在C语言编程中分配一块内存的函数，然后大多数人并不知道其背后的真实情况，或者仅仅是认为这是一个syscall或者语言关键字。这篇文章中只需要一些C的技能和一些系统知识，就能了解到malloc也只不过是一个简单的函数而已。本文的主要目的是编写一个简单的malloc函数，来帮助我们了解底层概念。其目的并不是为了实现一个高效的malloc，仅仅提供基础功能。但是背后的概念能够帮助我们有效地去理解进程中内存是如何管理的，以及如何处理块的分配，再分配以及释放等等。站在教学的角度来说，这是一个很好的C语言编程练习。同样也是一个很好文档，它能够帮助我们理解指针怎么来的，它们在堆里面是怎样组织起来的。 malloc是什么12#include &lt;stdlib.h&gt; void *malloc(size_t size); malloc是一个标准C库函数，用于分配内存块。它遵循以下规则： malloc至少要分配请求字节大小（size）内存； malloc的返回的指针，指向一个已分配的内存（比如一个在编程时可读或者可写的空间）； 在该指针没有被释放之前，其他任何的malloc调用都不会分配该空间或者该空间中的任何一部分； malloc应该能很好处理，而且能够很快执行结束； malloc需要提供重新设置大小或者释放的能力； malloc函数返回的指针在失败或者没有可用内存空间的情况下为NULL。 二、堆和brk、sbrk系统调用在编写malloc之前，我们需要理解内存在多任务系统中是如何管理的。由于具体实现依赖于操作系统的实现细节，下面提到的内容更多是基于抽象的概念来进行阐述。 进程的内存每个进程都有它自己的虚拟地址空间，由MMU（内核）提供从虚拟地址空间到物理地址空间的转换。而该空间被分为多个部分，比如用户存储局部变量和volatile变量的栈，还有存储常量和全局变量的空间，以及用于存储程序数据，称为堆的散乱空间。 就虚拟地址而言，堆是一个连续的内存空间，它有三个划分的边界：起始点、最大值和称一个为break的终点。最大值的管理可以调用(原文中写成了sys/ressource.h)里面的setrlimit和getrlimit。break用于标记已映射内存空间的尾部，已映射内存空间指的是已经和实际内存一一对应起来的那部分虚拟地址空间（我的理解也就是对应的PTE里面有效位应该是为1，更或者TLB有对应的缓存的Page）。下图展示了内存组织的形式：为了能够编写malloc函数，我们需要知道堆（heap）的开始位置和break的位置。当然我们还需要有能力去移动break，可以使用brk和sbrk系统调用来实现。 brk和sbrk我们可以在他们的手册（比如man brk）里面找到关于这些系统调用的描述： 12int brk(const void *addr);void *sbrk(int incr); brk函数通过传入的 addr 来设置brak的值，成功返回0，失败返回-1。使用全局errno来指明错误的原因（错误码对应的错误信息可以在\中查看）； 而sbrk通过传入的增量（以字节为单位）来移动break的位置。基于不同系统的实现，其返回值可能会返回老的地址，也可能返回移动之后新的地址。如果函数调用失败则返回-1，并且设置errno的值。在有些系统上sbrk支持传入一个负数用于释放那些已被映射的地址空间。 由于sbrk没有规范其返回值的意义，因此我们在 移动break的时候 不会去使用它返回值。但是我们可以使用特定情况下的sbrk，当调用sbrk其增量为0时，它的返回值就是实际的break地址（也就是老的地址和新的地址是同一个值）。因此sbrk用于获取堆的开始位置，也就是break的初始位置（上图中mapped Region长度为0的时候，也就是break的初始位置）。 因此我们将使用sbrk作为我们主要的工具。而我们的目的是在需要更多空间的情况下，我们要做的就是获取更多的资源来满足需求。 未映射区域和无人区（No-Man’s Land）我们看一下早期break标记已映射虚拟地址空间结束点的原理：在访问break之前的区域时会触发一个总线错误。在break点和最大限制（rlimit）之间的空间，系统（MMU和内核部分）是没有将物理内存和虚拟内存关联起来的。如果知道一点关于虚拟内存的知识的话，应该清楚内存是通过页的方式来进行管理：物理内存和虚拟内存通常情况下以固定大小的页面进行组织，而页的大小在实际系统中通常为4096Byte（4KB）。因此break点可能并不是在整页的边界上。说点题外话，在《现代操作系统》中介绍缺页处理程序是通过懒加载的方式来将物理内存和虚拟内存联系起来的。不考虑TLB的情况下，MMU是将VPN和PPN通过PTE来进行映射的图二相比于图一，我们增加了页面边界的表示。可以看到break并没有和页边界吻合对应起来。那么处于break和下一页边界之间的内存是什么状态呢？实际上，这一段空间是可用的，我们可以对这段空间进行读写操作。但问题在于我们没有办法知道下一页边界的任何头绪，它的实现是非常依赖于特定系统的，所以对于可移植性来说，不建议这么去做。 无人区（no-man’s land）可能是大部分BUG的根源：在堆外面进行错误地指针操作时，对于小规模测试大部分时间是可以成功的，但是在更大量数据的时候该操作就会出现失败。 mmap尽管在这个教程中我们并不会使用它，但是我们应该要注意到mmap系统调用。mmap大部分情况用于将文件和内存映射起来，但是它可以以匿名模式来实现malloc（在某些特定情况下）。匿名模式下的mmap可以分配指定数量的内存（以页面大小为单位），munmap可以释放掉它们。使用这种方式实现的malloc相较于传统基于sbrk实现的malloc通过更加简单。 有些malloc使用mmap来实现大内存的分配（超过一页的大小）。OpenBSD的做法是使用mmap并搭配一些奇技淫巧来增加安全性（页与页之间在分配的时候增加边框来进行分配。这里翻译不太顺，加边框的意思是在页的边界处使用额外的空间来达到整页使用的效果，想象卷积的时候增加padding来读取矩阵左上角的数据。如果翻译有问题请联系我）。 三、Dummy malloc首先，我们会使用sbrk来假设一个malloc。这个版本的malloc可能是最差的一个，甚至是最简单的一个。 原理思想很简单，每次在调用malloc的时候，我们根据请求的空间大小来移动break，并且返回break之前的地址。这样做的确够简单，也够快。。。它仅仅只需要三行代码。但是这样的话我们没法去实现一个真实的free，当然realloc同样也不行。 这个版本的malloc会浪费很大一部分用过的内存块儿。在这儿只是出于科普的目的来指出如何sbrk系统调用，同样还将为malloc添加一些错误管理。 实现123456789void *malloc(size_t size)&#123; void *p; p = sbrk(0); /// 如果sbrk失败，返回NULL if (-1 == sbrk(size)) &#123; return NULL; &#125; return p;&#125; 四、组织堆（Organizing the Heap）在上一节我们写了第一个版本的malloc函数，但是并没有满足我们所有的需求（前面提到的free和realloc）。在这一节我们会尝试找到一个高效组织heap的方案，其中包括了malloc、free和realloc。 我们需要什么如果我们在编程上下文之外思考问题，能推断出在解决这个问题的时候我们需要哪些信息吗？来看个比喻：你拥有一片农场，并将他们划分成很多块农田区域出来。将这些分块的农田出租出去。租户希望租用连续的，但不同长度的农田（这里只使用长度这个维度来划分，不考虑面积）。当租户使用完成之后将其租用农田归还，以便下次继续向外出租。 在农场边提供了用于行驶“可编程”车的道路：输入距离开始点的偏移量和目的地（目的地是一块不是一个点，所以这里表达的是该块的开始点位）。因此我们需要知道每一块的开始点在哪儿，而且当我们处于某一块的起始点的时候，我们还需要知道下一块的地址。 其中一个解决方案是在每一块农田的开头部分放入一个标签来标明下一块的地址（和当前块的大小以避免不必要的计算），当租户将农田资源归还的时候，在空闲区域添加一个标记。好了，现在当租户想要固定大小农田的时候，我们可以带着他行驶在一处一处的标签那儿去。当我们发现一块标记为可用状态的农田，并且足够交付租户需求的时候，我们将该空闲标记从标签中移除。但是如果到达最后一块农田（也就是标签中没有下一个农田的地址），我们只需要到达该区域的末尾并添加一个新的标记。 现在我们将这个比喻转换到内存： 我们需要在每一块开始部分存储额外的信息，包括每一个块的大小、下一个块的地址、以及是否空闲等信息。 如何表示块信息我们需要在每一个大块（chunk）的开始部分包含一小段（block）用于容纳额外信息，这一小段我们成为“meta-data”；该段至少包含了下一块的指针、用于空闲块的标记、以及该块数据大小。当然，该段信息是在mallc函数返回的指针之前。图三展示了一个堆组织的例子，含有已分配段前面的meta-data。 每一个大块（chunk）由数据块和meta-data组成，malloc函数返回的指针在上图下面由红色标记出来，需要注意的是该指针是指向的数据块，并不是完整的大块（chunk，不是指向meta-data的起始点）。现在我们需要怎样来把这些用C代码表示出来呢？这个看起来像传统的链表（实际上就是个链表）。我们编写一个链表类型，该类型成员用来表示所需的信息。我们使用 typedef来简化结构类型： 123456typedef struct s_block* t_block;struct s_block &#123; size_t size; t_block next; int free;&#125;; 在这儿看起来使用int型的free标记有点浪费空间，但由于struct默认是内存对齐的，因此它不会改变任何内容，稍后我们会看到如何缩小meta-data的大小。后续我们会看到malloc返回的地址必须是内存对齐的地址。这儿出现最频繁的问题是：我们如何在没有malloc的情况下去创建一个struct？答案很简单，我们只需要知道struct实际上是什么。在内存中，struct只是将一块儿区域结合了起来，所以结构s_block仅仅只是12字节（对于32位整型来说）。size字段对应前面的4字节，接下来的4字节是指向下一个block的next指针，最后4个字节是一个整型的free标记。当编译器遇到访问结构的域时（比如s.free或者p-&gt;free），将其转换为该结构的基地址加上该域之前长度的和。比如：p-&gt;free就是((char )p+8)，s.free就是((char )&amp;s+8)。我们所需要做的就是使用sbrk分配足够的空间块（包含了meta-data的大小和数据块的大小），并将老的break放入t_block类型的变量内： 12345678/* Example of using t_block without malloc */t_block b;/// 使用b保存老的breakb = sbrk(0);/// 添加所需空间/// size变量是malloc函数的参数sbrk(sizeof(struct s_block)+size);b-&gt;size = size; 五、首次适配策略的malloc“首次适配”是我采用《深入了解计算计算机系统》的翻译词。在这一节我们将会实现经典的首次适配策略的malloc函数。首次适配算法很简单：我们只要找到了一个空间大小足够满足请求分配的时候就停止遍历其他的块（chunk）。 指针对齐通常情况需要将指针和整型大小对齐（即 指针大小就是一个整型的大小）。此处我们只考虑32位的情况，所以指针是4的倍数（32bit = 4 byte，那当然是4的倍数）。因此我们的meta-data已对齐，我们仅仅需要做的只是去对齐数据块的大小。那我们该怎么做呢？这儿有几种方式，最有效的方式是使用算术技巧添加预处理宏。首先，算术技巧：给定任意正整数除以4，然后再将它乘以4得到最接近4的倍数。因此为了获得最接近且大于它时，只需要乘以4，然后在此基础上加4。这种方式的确很简单，但它没办法很好地工作在本身就是4的倍数上，结果会变成4的倍数的下一个（由于加了4）。再来使用一次算术，假设x是整型，并且满足：1）、如果x是4的倍数，那么q = 0，并且满足：运用上面说的，先除以4，然后乘以4，最后再加上4： 在这个推算过程是将上面x-1的表示用p来进行表示。这里需要注意一点的是，在整型除法中3/4结果为0； 2）、如果x不是4的倍数，此时q != 0：同样运用上面的，先除以4，然后乘以4，最后再加上4： 因此，公式 (x-1)/4 * 4 + 4 的结果是最接近并且大于或者等于4的倍数。 那么我们在C里面该怎么做呢？首先，注意到除法和乘法我们可以使用右移和左移移位操作符来解决（&gt;&gt;和&lt;&lt;），它们相对于简单乘法要快很多。因此我们的公式在C里面可以写成这样 ((x-1)&gt;&gt;2)&lt;&lt;2+4，但是在宏里面需要使用额外的括号： 1#define align4(x) (((((x)-1)&gt;&gt;2)&lt;&lt;2)+4) 寻找块：首次适配算法找到一个足够长度的块非常简单：从堆的起始点开始（以某种方式会保存在代码，后续会看到）测试当前块，如果该块成功适配则返回该块的头部，否则继续向下一块寻找，直到最后一个块的头部。这里唯一的技巧是需要保存上一次遍历过的块，所以当没有找到合适的块的时候，malloc函数可以很轻松地去扩展堆的尾部（长度）。代码逻辑很直接，base是一个全局指针变量，指向堆的开始位置： 12345678t_block find_block(t_block *last, size_t size) &#123; t_block b = base; while (b &amp;&amp; !(b-&gt;free &amp;&amp; b-&gt;size &gt;= size)) &#123; *last = b; b = b-&gt;next; &#125; return b;&#125; 这个函数会返回一个合适的块，或者返回NULL（在没有找到的情况下）。函数执行后，last指针指向上一次访问过的块。 扩展堆现在，并不能总是找到合适的块，有时候（特别是最开始使用malloc函数）需要去扩展堆。实现同样很简单：移动break，并初始化新的block。当然还需要更新堆中上一个块的next域。在后续开发过程中需要知道struct s_block的大小，所以在这儿定义一个宏： 1#define BLOCK_SZIE sizeof(struct s_block) 下面代码没有什么可惊讶的，仅仅只是当sbrk失败之后返回NULL（没必要想这么做的原因）。注意，前面提到过我们不能确信sbrk函数返回的上一个break，因此我们首先保存break值，然后移动它。我们需要使用last和last-&gt;size来进行计算： 123456789101112131415t_block extend_heap(t_block last, size_t size)&#123; t_block b; b = sbrk(0); if ((void *)-1 == sbrk(BLOCK_SZIE+size)) &#123; /// sbrk失败 return NULL; &#125; b-&gt;size = size; b-&gt;next = NULL; if (last) &#123; last-&gt;next = b; &#125; b-&gt;free = 0; return b;&#125; 拆分块（block）注意到我们寻找首个可用的块，但并没有管它的大小（足够大）。假想一下，如果只需要2byte的大小，但是找到的块是256byte的，如果这样做会丢失很大一部分的空间。第一个解决方案是拆分块：当一个块足够宽到请求的大小加上一个新块大小（至少BLOCK_SIZE+4），那么向链表中插入一个新块。下面的函数（split_block）会在空间可用的时候被调用。提供的大小(参数size)必须要是对齐的。在这个函数中我们会做一些关于指针运算，为了防止错误，我们将使用一些小技巧来确保我们所有的操作都以一个字节的精度完成（需要注意一下p+1是依赖于p的类型的，也就是不同类型指针加一的步长不一样）。我们只需要在struct s_block中添加一个字符数组的域。结构体中添加数组很简单：数组直接定义在结构的内存块中，因此数组指针的作用是指向meta-data的尾部。C禁止长度为零的数组，那么我们就定义个一字节长的数组： 123456struct s_block &#123; size_t size; t_block next; int free; char data[1];&#125;; 并且需要更新一下宏BLOCK_SIZE的值，由于扩展了s_block的data，如果还是使用sizeof的话将会把data字段也算进去。所以这里需要将BLOCK_SIZE固定位12字节（注意，现在说的32位整型）： 1#define BLOCK_SZIE 12 这里我说一下这里加了一个data域，为什么BLOCK_SIZE要设置为12，不随sizeof(struct s_block)呢？前面也说过结构只是把内存里面的各个字节赋予了含义而已，我们只是想把12字节认为是meta-data，而并不是硬生生得塞了一块数据到meta-data和数据块之间。加这个域只是为了我们在拆分block的时候方便，不加这个域同样也是可以操作的。 增加了这个扩展之后，并不需要明确为之前 extend_heap函数适配新增的data域。函数split_block：会根据传入的参数来拆分为所需大小的块。图四展示该函数的相关操作： 1234567891011121314/// 参数s必须要对齐的void split_block(t_block b, size_t s) &#123; if (!b) &#123; return; &#125; t_block new; new = b-&gt;data + s; new-&gt;size = b-&gt;size - s - BLOCK_SZIE; new-&gt;free = 1; new-&gt;next = b-&gt;next; b-&gt;size = s; b-&gt;next = new;&#125; 注意代码b-&gt;data+s，由于data域时char[]类型，所以我们能够精确地控制是以字节的步长进行增加。 malloc函数现在我们可以开始写malloc函数了，它主要是将前面讲到的函数封装起来。我们必须要将请求的size对齐，并测试是否是第一次调用malloc函数，以及已告知其余所需的条件。在上一节的find_block函数中使用了一个全局变量 base，下面是该变量的定义： 1void *base = NULL; 它是一个void *类型的指针，并初始化为NULL。在malloc中我们首先要做的就是判断base是否为NULL？如果为NULL那么就表示第一次调用malloc函数，否则就是用前面提到的相关算法。 malloc函数需要具备下面几行中的特性： 首先需要对齐请求的大小； 当base已经初始化： 搜索足够大小的空闲块； 如果找到该块的情况下： 尝试着去拆分该块（请求的大小和块的大小足够存储meta-data和最小块数据，比如4byte）； 标记该块为已是用(b-&gt;free = 0)； 否则：扩展堆；注意在find_block函数中使用的last指针，它用于记录上一次访问过的块（chunk），因此当我们在扩展块的时候就不用再重新去遍历整个链表。 否则：扩展堆（空指针）。注意此时工作在extend_heap函数时last=NULL。 也需要注意在每次失败之后，我们按照预期指定的malloc函数返回NULL。 1234567891011121314151617181920212223242526void *malloc(size_t size)&#123; t_block last,b; size_t align_size = align4(size); if (base) &#123; last = base; if ((b = find_block(&amp;last, align_size))) &#123; if (b-&gt;size - align_size &gt;= (BLOCK_SZIE + 4)) &#123;/// meta-data + 4 split_block(b, align_size); &#125; b-&gt;free = 0; &#125;else&#123;///查找heap失败，extend heap b = extend_heap(base, align_size); if (!b) &#123; return NULL; &#125; &#125; &#125;else&#123;///首次调用malloc函数，extend heap /// base = null; b = extend_heap(base, align_size); if (!b) &#123; return NULL; &#125; base = b; &#125; return b-&gt;data;&#125; 六、calloc, free和realloc函数calloc函数calloc函数： 首先调用malloc函数，并分配正确的大小； 将块里面的每一个字节设置为0； 这里使用一个小技巧：chunk中数据块的大小总是4的倍数，所以我们以4字节的步长进行迭代。因此我们把new指针当做无符号整型的数组： 123456789101112void *calloc(size_t number, size_t size) &#123; size_t *new; size_t s4,i; new = malloc(number*size); if (new) &#123; s4 = align4(number*size)&lt;&lt;2; for (i = 0; i &lt; s4; i++) &#123; new[i] = 0;/// new为size_t，所以这里+1的步长为size_t的字节数，在32位整型下面，size_t为4字节 &#125; &#125; return 0;&#125; free函数注：在下文提到的块在原文中的描述如果没有特殊注明均为chunk，而非在malloc一节大量使用的block。 快速实现free是很简单的，但简单并不意味着很方便就能完成。我们有两个问题：找到被释放的块，并且防止出现空间碎片。 碎片：malloc函数遗留问题malloc函数的一个重大问题是碎片：在多次使用malloc和free之后，堆被划分为许多块，这些块已经小到足够满足大的malloc，直到整个可用空间使用。这就是空间碎片的问题。在这个算法中我们虽然没有办法避免出现额外的碎片，但可以避免其他来源的碎片。当我们选择的空闲块足以容纳请求分配的量和另外的块时，我们会拆分当前块。在提供更好地内存使用率（新的块为空闲状态以备后用）的同时也引入了更多的碎片。解决碎片化的一个问题就是空闲块。当我们释放一个块时，如果临接的块同样是空闲状态时，我们合并他们成一个更大的块。在这儿我们所有需要的就是去测试前面块和后面块的状态。那么如何去获取之前的块（block）呢？下面有几个解决方案： 从头开始搜索，但非常慢（特别是我们已经搜了一些空闲块之后，再从头搜索）； 当我们搜索到当前块的时候，使用一个指针指向上一个访问的块； 双链表； 我们选择最后这个解决方案，该方案非常简单地去跟踪目标块。所以我们再一次去修改struct s_block（第一次修改是malloc的时候增加的data成员）。但由于我们还有另外一个待修改的地方（下一节），因此先不急着做修改。 所以我们现在要做的就是合并，我们先写一个简单的合并函数来合并块。在下面的代码中我们会用一个 prev域来作为直接前驱： 12345678910t_block fusion(t_block b) &#123; if (b-&gt;next &amp;&amp; b-&gt;next-&gt;free) &#123; b-&gt;size += BLOCK_SZIE + b-&gt;next-&gt;size; b-&gt;next = b-&gt;next-&gt;next; if (b-&gt;next) &#123; b-&gt;next-&gt;prev = b; &#125; &#125; return b;&#125; fusion函数很直截了当：如果下一个块是空闲块，那么就将当前块的size和下一个块的size，以及meta-data的大小。然后将next域指向当前变量后继的后继（b-&gt;next-&gt;next），此时如果当前的后继存在，那么久更新该后继的直接前驱（b-&gt;next-&gt;prev）。 找到正确的块关于其余释放带来的问题是如何高效地寻找由malloc函数返回的正确的块。实际上，这儿存在几个问题： 验证输入的指针（它是否真的是一个malloc指针）； 找到meta-data指针； 我们可以通过quick range test来消除无用的指针：如果该指针在堆外，那么它肯定不是一个有效指针。那么剩下的case和上一个case相关，我们如何确定该指针是由malloc函数获得？其中一个解决方案是在结构内使用一个魔数（magic number）。相对于魔数更优的一个方案是我们可以使用一个指针指向它自己。解释一下：我们有一个ptr域指向data域，如果b-&gt;ptr == b-&gt;data的时候，那么该指针大概率是有效块（block）。下面是扩展之后的结构，以及访问和校验给定的指针是否为相应的块（block）： 1234567891011121314151617181920212223242526typedef struct s_block* t_block;struct s_block &#123; size_t size; t_block next;/// 后继 t_block prev;/// 前驱 int free; void *ptr; char data[1];&#125;;t_block get_block(void *p)&#123; char *tmp; tmp = p; tmp = tmp-BLOCK_SZIE; p = tmp; return p;&#125;int vaild_addr(void *p) &#123; if (base) &#123; if (p &gt; base &amp;&amp; p &lt; sbrk(0)) &#123;/// sbrk(0)是获取当前break线，结合前面提到的图 return p == (get_block(p)-&gt;ptr); &#125; &#125; return 0;&#125; 实现free函数free函数到现在也渐渐揭开了神秘面纱：验证指针的正确性，并找到相应的块，然后将其标记为空闲块，最后如果有必要就进行合并操作。释放内存时，当我们处于堆的尾部，我们需要调用一下brk函数来调整break先到当前块的位置处。下面的代码展示具体实现，大致的逻辑如下： 如果指针有效： 获取block块的地址； 标记为空闲状态； 如果当前节点的直接前驱是空闲的，那么就合并两个块； 继续尝试合并直接后继块； 如果当前处于最后一个块，那么我们释放内存； 如果这儿没有更多的块了，那我们重置为原始状态（base设置为NULL）； 如果该指针不是有效指针的话，我们就什么也不做； 12345678910111213141516171819202122void free(void *ptr) &#123; t_block b; if (vaild_addr(ptr)) &#123; b = get_block(ptr); b-&gt;free = 1; /// 如果可以合并直接前驱 if (b-&gt;prev &amp;&amp; b-&gt;prev-&gt;free) &#123; b = fusion(b-&gt;prev); &#125; /// 合并直接后继 if (b-&gt;next) &#123; fusion(b); &#125;else&#123; if (b-&gt;prev) &#123; b-&gt;prev-&gt;next = NULL; &#125;else&#123; base = NULL; &#125; brk(0); &#125; &#125;&#125; 使用realloc重置块的大小realloc函数和calloc函数差不多一样直接。基本上我们只需要一个内存拷贝的操作，在这里我们不使用里面的memcpy我们可以写一个更好的（大小以块为单位，并且已经对齐）。拷贝函数如下： 12345678910void copy_block(t_block src, t_block dst) &#123; int *sdata; int *ddata; size_t i; sdata = src-&gt;ptr; ddata = dst-&gt;ptr; for (i = 0; src-&gt;size &gt; 4*i &amp;&amp; dst-&gt;size &gt; 4*i; i++) &#123; ddata[i] = sdata[i]; &#125;&#125; 按照下面的做法可以实现一个非常幼稚（但是能工作）的realloc函数： 使用malloc根据指定的大小分噢诶一个新块； 将数据从旧内存数据复制到新内存地址处； 释放旧内存中的数据； 返回指向内内存地址处的指针； 当然我们还想做一点事儿让realloc函数更高效一点。当我们有足够的空间的时候，此时并不需要去分配新的空间。因此不同点有： 如果大小未发生变化，或者额外可用大小足够使用，那么我们什么也不做； 如果需要收缩块，那么拆分该块； 如果下一个是空闲块而且提供了足够的空间，如果需要的话我们可以合并或者拆分这些块； 下面是realloc函数的具体实现： 1234567891011121314151617181920212223242526272829303132333435void *realloc(void *p, size_t size) &#123; if (NULL == p) &#123; return malloc(size); &#125; size_t s; t_block b, new; void *newp; if (vaild_addr(p)) &#123; s = align4(size); b = get_block(p); if (b-&gt;size &gt; s) &#123; if (b-&gt;size &gt;= s+BLOCK_SZIE+4) &#123; split_block(b, s); &#125; &#125;else&#123; if (b-&gt;next &amp;&amp; b-&gt;next-&gt;free &amp;&amp; (b-&gt;next-&gt;size + b-&gt;size + BLOCK_SZIE) &gt;= s) &#123; fusion(b); if (b-&gt;size - s &gt; BLOCK_SZIE+4) &#123; split_block(b, s); &#125; &#125;else&#123; newp = malloc(s); if (!newp) &#123; return NULL; &#125;else&#123; new = get_block(newp); copy_block(b, new); free(p); return newp; &#125; &#125; &#125; &#125; return p;&#125; 别忘了realloc(NULL, s)是可以直接提到malloc(s)的。 FreeBSD中reallocf函数FreeBSD提供了另外一个realloc函数的实现：reallocf，它会在任何情况下释放输入的指针（即使是再分配失败之后）。我们一样会调用realloc函数，但是只有我们在获得空的指针之后才会调用free函数。下面是具体的实现部分： 1234567void *reallocf(void *p, size_t size) &#123; void *ptr = realloc(p, size); if (!p) &#123; free(p); &#125; return ptr;&#125; 到这儿基本翻译完成，如有错误请及时本联系我，谢谢❤️]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[细看objc-weak源码]]></title>
      <url>%2F2018%2F05%2F18%2Fsource_code_objc_weak_t%2F</url>
      <content type="text"><![CDATA[本文不看其他，只专注于weak的内部结构实现细节和源码解读，看了网上很多的文章都是贴上一篇open source里面的代码，并没有对实现细节进行解释。所以在这篇文章中，主要分为weak_entry_t、weak_table_t的源码解析，weak_entry_t和weak_table_t的相互关系，以及对应的操作函数。 下文的主要是基于两个对象来说的，一个是被引用的对象，一个是弱引用变量（也就是源代码中大量出现的指向指针的指针）。 我说一下我源码阅读的习惯，先把目光放在头文件中，因为头文件能够给我们一个整体基础结构。弄清楚具体的结构之后，然后再跳到实现文件中去看具体的实现细节。先交代一下我的编译环境和源代码版本： 编译环境：Apple LLVM version 9.1.0 (clang-902.0.39.1)Target: x86_64-apple-darwin17.5.0Thread model: posixInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin源代码版本： objc4-723 头文件类关系和结构分析我先根据头文件画一个基本的UML类图： DisguisedPtr模板类先将视线放在weak_entry_t上面，结构weak_entry_t的第一个成员变量是referent，它是一个DisguisedPtr类模板实例化之后的变量（点开前面的链接吧，不然我讲不清楚，不然你会骂我的），这个成员其实就是保存被引用的对象。DisguisedPtr类里面看起来这个类并不复杂，有一个uintptr_t类型的成员变量，由此DisguisedPtr类的对象所占用的内存空间大小也应该为8字节。public下面主要是构造函数加三大函数中的两个：重载复制运算符，赋值构造函数；由于该类里面并没有涉及到动态new指针变量，所以其析构函数便使用了默认析构函数。除此之外还重载一些其他的操作符。主要看一下私有的两个成员函数： 123456static uintptr_t disguise(T* ptr) &#123; return -(uintptr_t)ptr;&#125;static T* undisguise(uintptr_t val) &#123; return (T*)-val;&#125; 其中disguise函数是将指针变量强转为uintptr_t的整形变量，具体怎么伪装呢？就是把该指针指向的内存地址（16进制数据比如：0x7ffeefbff4e8）强制转换为无符号长整型的十进制数据。由于其类型是无符号长整型，因此取负数是数据溢出之后取该类型取值范围内较大的长整型值达到伪装的效果（也就是不好去找到原内存地址）。 123456unsigned long ul_val = 2;unsigned long*bitl = &amp;ul_val;cout&lt;&lt;&quot;ul_val address: &quot;&lt;&lt;bitl&lt;&lt;endl;///0x7ffeefbff4e8///140732920755432 取负数 -&gt; 18446744069408184208cout&lt;&lt;&quot;disguise: &quot;&lt;&lt;disguise(bitl)&lt;&lt;endl;cout&lt;&lt;&quot;undisguise: &quot;&lt;&lt;undisguise(*bitl)&lt;&lt;endl;/// 0xfffffffffffffffe 1111...1110 其作用在源文件的注释中也说了，我通俗总结是：对那些比如leak这种内存检测工具进行伪装，然后这些检测工具可能就不好去跟踪被引用的对象。 weak_entry_t现在来看一下union的具体内存分布细节，怎么来解释这个问题呢？奉上objc-weak.h的源码，打开源码配合文章来看。 12345678910111213union &#123; struct &#123;/// 为了方便说明问题，我将该结构取名为：struct1 weak_referrer_t *referrers; uintptr_t out_of_line : 2; uintptr_t num_refs : PTR_MINUS_1;/// num_refs记录的是实际引用数量 uintptr_t mask;/// 记录当前referrers数组容器的大小 uintptr_t max_hash_displacement;/// 根据hash-key寻找index的最大移动数，这个在后面的append_referrer会讲 &#125;; struct &#123;/// 为了方便说明问题，我将该结构取名为：struct2 // out_of_line=0 is LSB of one of these (don&apos;t care which) weak_referrer_t inline_referrers[WEAK_INLINE_COUNT]; &#125;;&#125;; 首先要有一个概念，union里面的多个成员是共享同一且相同大小的内存空间，在strcut1结构成员中算出其总共所占内存大小为64*4，也就是32个字节。其中我的机器是64位机，我的编译器对于指针类型所占内存大小的ABI实现为64位，而无符号长整型占用的内存大小也为64位。多说一句，在C++中结构和类的内存存储区域好像都是在堆上面，由低地址向高地址生长。基于此来画出inline_referrers和上面第一个结构大致的内存分布样式（关于inline_referrers的元素类型模板类DisguisedPtr所占内存大小在上面讲DisguisedPtr类时提到了）：在源码中注释也说了： 12345// out_of_line_ness field overlaps with the low two bits of inline_referrers[1].// inline_referrers[1] is a DisguisedPtr of a pointer-aligned address.// The low two bits of a pointer-aligned DisguisedPtr will always be 0b00// (disguised nil or 0x80..00) or 0b11 (any other address).// Therefore out_of_line_ness == 0b10 is used to mark the out-of-line state. out_of_line_ness是和inline_referrers[1]的低2位是等同的，out_of_line_ness和num_refs使用了位段，一共占用64位（2位和62位）。由于此时已经是结构内存对齐了，所以下一个结构成员mask的内存地址就刚好换行。上面还提到的0x0b10，它应该是经过DisguisedPtr伪装之后得到的值，并不是实际的等于0b10，一个只占两位内存空间的，怎么也存储不了16位的数据。out_of_line_ness == 0b10是标记使用out-of-line的状态。关于这个0b10我没有想清楚它的由来，有知道的同学麻烦告知于我！！！继续来看该结构的构造函数： 12345678weak_entry_t(objc_object *newReferent, objc_object **newReferrer) : referent(newReferent)&#123; inline_referrers[0] = newReferrer; for (int i = 1; i &lt; WEAK_INLINE_COUNT; i++) &#123; inline_referrers[i] = nil; &#125;&#125; 在创建weak_entry_t实例的时候，默认是使用inline_referrers的方式来管理对象引用的，并把其余的位上的数据清空。out_of_line_ness用来判断使用out_of_line的方式来进行引用管理，这个out_of_line_ness的值主要是依据于被引用的对象，其引用变量的个数决定的，具体的逻辑在下文会讲到。再看看struct1的referrers成员，看起来是一个指针变量，更具体的说是存储的引用变量数组的起始地址，而这些引用变量指针指向的地址被DisguisedPtr进行了伪装。 到这里我把weak_entry_t的内存分布讲了一遍（具体的含义在上面代码块中的注释里），然后下面来看一下weak_table_t。 weak_table_tweak_table_t在头文件中看不出什么特别的内容，但是从源码中可以看出，应该是一个基于C的结构，没有使用C++中结构独有的特性。 123456struct weak_table_t &#123; weak_entry_t *weak_entries; size_t num_entries;/// 和weak_entry_t的num_refs概念类似 uintptr_t mask;///和 weak_entry_t的mask概念类似 uintptr_t max_hash_displacement;/// 和weak_entry_t的max_hash_displacement概念类似&#125;; 同样的，其weak_entries成员也应该是一个数组，存储着weak_entry_t变量的指针。针对该结构头文件中公开的操作函数有： 1234567id weak_register_no_lock(weak_table_t *weak_table, id referent, id *referrer, bool crashIfDeallocating);void weak_unregister_no_lock(weak_table_t *weak_table, id referent, id *referrer);#if DEBUGbool weak_is_registered_no_lock(weak_table_t *weak_table, id referent);#endifvoid weak_clear_no_lock(weak_table_t *weak_table, id referent); 这看不了什么具体的内容，所以针对头文件的解读就到这里。下面去实现文件中看看具体的实现，看看网上为什么都在说的基于Hash表的一个存储结构。源码地址，老规矩，打开这个网页对照着源码来看。 objc-weak具体实现细节首先看两个hash函数： 12static inline uintptr_t hash_pointer(objc_object *key);static inline uintptr_t w_hash_pointer(objc_object **key); 它们会根据对象的指针（不管是指针还是指向指针的指针）调用一个fast-hash函数来生成一个key，其原理是基于fast_hash，而这个key的作用目前我们无从得知。 grow_refs_and_insert函数继续看源码，下面主要来看看一个很重要的函数： 12345678910111213141516171819202122232425262728293031__attribute__((noinline, used))static void grow_refs_and_insert(weak_entry_t *entry, objc_object **new_referrer)&#123; assert(entry-&gt;out_of_line); /** * #define TABLE_SIZE(entry) (entry-&gt;mask ? entry-&gt;mask + 1 : 0) * entry-&gt;mask用来记录referrers的数量 */ size_t old_size = TABLE_SIZE(entry); size_t new_size = old_size ? old_size * 2 : 8;/// 增长一倍的大小 size_t num_refs = entry-&gt;num_refs; weak_referrer_t *old_refs = entry-&gt;referrers; entry-&gt;mask = new_size - 1; entry-&gt;referrers = (weak_referrer_t *) _calloc_internal(TABLE_SIZE(entry), sizeof(weak_referrer_t)); entry-&gt;num_refs = 0; entry-&gt;max_hash_displacement = 0; /// 开始处理数据 for (size_t i = 0; i &lt; old_size &amp;&amp; num_refs &gt; 0; i++) &#123; if (old_refs[i] != nil) &#123; append_referrer(entry, old_refs[i]);/// 把老数据复制进新的entry里面 num_refs--; &#125; &#125; // Insert append_referrer(entry, new_referrer);/// 给entry插入新的数据 if (old_refs) _free_internal(old_refs);&#125; 由于基于C的数组其实都是定长的，为了能够动态地增加新元素就需要不断地去申请新的内存空间，并且还要是连续的内存地址（要是不连续的地址就去使用链表的方式，但是链表的索引明显弱于数组的）。正是因为新动态申请的连续内存空间，这就需要把老数据复制过来，并把需要新增的数据也追加进去，最后释放掉原内存空间：它其实和C++里面的动态数组的原理一样，为了不频繁地去申请（calloc）新的空间和频繁地数据移动。所以每次2倍增长来增加weak_entry_t的长度。为什么说是C++里面动态数组的做法，在《数据结构与算法实现-C++描述》里有提及这些内容。 append_referrer和remove_referrer在grow_refs_and_insert函数中调用了append_referrer函数，这个函数很明显是做插入操作的，默认使用inline的方式来增加新增的weak引用，如果使用inline的方式失败了，则是以outline的方式，并申请对应的存储空间，把entry-&gt;referrers指向新申请的内存地址，把inline_referrers数组里的数据拷贝到new_referrers中，其源码如下： 12345678910111213141516171819202122if (! entry-&gt;out_of_line) &#123; // Try to insert inline. for (size_t i = 0; i &lt; WEAK_INLINE_COUNT; i++) &#123; if (entry-&gt;inline_referrers[i] == nil) &#123; entry-&gt;inline_referrers[i] = new_referrer; return; &#125; &#125; // Couldn&apos;t insert inline. Allocate out of line. weak_referrer_t *new_referrers = (weak_referrer_t *) _calloc_internal(WEAK_INLINE_COUNT, sizeof(weak_referrer_t)); // This constructed table is invalid, but grow_refs_and_insert // will fix it and rehash it. for (size_t i = 0; i &lt; WEAK_INLINE_COUNT; i++) &#123; new_referrers[i] = entry-&gt;inline_referrers[I]; &#125; entry-&gt;referrers = new_referrers; entry-&gt;num_refs = WEAK_INLINE_COUNT; entry-&gt;out_of_line = REFERRERS_OUT_OF_LINE; entry-&gt;mask = WEAK_INLINE_COUNT-1; entry-&gt;max_hash_displacement = 0;&#125; 从这里就可以看出，当被引用对象的弱引用referrers个数小于WEAK_INLINE_COUNT时，其entry里面是以inline小数组方式来存储这些弱引用变量的，只有当inline_referrers全部装满之后，该entry out_of_line被设置为REFERRERS_OUT_OF_LINE，后续如若有变量继续引用该对象则是以outline的方式存储的。 union是在被引用变量的referrers个数小于等于WEAK_INLINE_COUNT时，使用inline数组的内存表现形式；当referrers个数超过了WEAK_INLINE_COUNT则以struct1的内存表现形式！ 由于使用inline的方式是使用小数组的方式，但是针对弱引用对象过多，那么它的存取性能就是考虑的一个重点。而散列是一种用于以常数平均时间执行插入、删除和查找的技术。下面这个过程我不是很确定，如有不同的建议希望指出。 123456789101112size_t index = w_hash_pointer(new_referrer) &amp; (entry-&gt;mask);size_t hash_displacement = 0;while (entry-&gt;referrers[index] != NULL) &#123; index = (index+1) &amp; entry-&gt;mask; hash_displacement++;&#125;if (hash_displacement &gt; entry-&gt;max_hash_displacement) &#123; entry-&gt;max_hash_displacement = hash_displacement;&#125;weak_referrer_t &amp;ref = entry-&gt;referrers[index];ref = new_referrer;entry-&gt;num_refs++; begin是通过引用new_referrer调用散列函数获取一个散列值，这个散列值就是散列表中的元素查找自己所在散列槽的key。从源码可以看出，通过散列值查找元素对应散列槽的方式好像是使用了线性探测法。简化上面的代码，配合下方这图来看一下把new_referrer指针查找正确index的过程：如上图，假设使用w_hash_pointer获取到的key为2，obj1成功插入到散列槽2中，obj2使用w_hash_pointer获取到的key也为2，此时散列槽2已经放入了obj1，那么只有正向地去寻找下一个散列槽，如果为空则放入obj2。回到源码中，在求begin值的时候。把hash值和entry-&gt;mask做了按位与的操作，但是这里为什么要对entry-&gt;mask做一次按位与操作呢？entry-&gt;mask存储着weak_entry_t的referrers数组大小，这样做能保证所得的散列值是小于当前数组的出界的，因为大于referrers数组大小对应的二进制位的高位全部被置为0，从而避免出现数组越界带来的问题。关于出界和入界的概念，可以在《C陷阱与缺陷》中关于一个介绍for循环越界导致的死循环一节，具体的记得不是很清楚了。针对出界这个概念还是蛮重要的，老板们可以去看一看。remove_referrer和append_referrer在源码上来看基本没有什么区别，区别只不过是一个赋值，一个置空而已。 weak_table_t的扩容和减容针对weak_table_t的扩容和减容源码相对来说比较简单，限于篇幅我没有提供对应的代码，所以在看的时候还麻烦自己打开上面提到的源码地址对照来看。在源码中主要提供了如下函数： weak_entry_insert；函数weak_entry_insert和上一节提到的append_referrer是类似的，weak_table_t的内部实现同样也是使用散列表的方式来管理所有的entry变量的。只是weak_entry_insert没有去尝试inline的那一步。 weak_resize；函数weak_resize和上面提到的grow_refs_and_insert函数类似，在调整大小时，都是创建一个新尺寸大小的内存空间，然后将原内存空间的数据移动到新的内存空间。weak_resize只有移动老数据，没有新数据的添加！最后释放掉原内存。 weak_grow_maybe；函数weak_grow_maybe是在原weak_table的entry数量大于了weak_table数组容量的3/4时，便调用weak_resize去扩充容量到原数组容量的2倍。 weak_compact_maybe；函数weak_compact_maybe是用来收缩容量的，当数组的容量内大部分都为空的话，则减容。 1234if (old_size &gt;= 1024 &amp;&amp; old_size / 16 &gt;= weak_table-&gt;num_entries) &#123; weak_resize(weak_table, old_size / 8); // leaves new table no more than 1/2 full&#125; weak_entry_remove；函数weak_entry_remove用来weak_table_t的entries里对应的entry 1234if (entry-&gt;out_of_line()) free(entry-&gt;referrers);bzero(entry, sizeof(*entry));weak_table-&gt;num_entries--;weak_compact_maybe(weak_table); sizeof(*entry)获取到了weak_entry_t所占用的内存大小，使用bzero是将该内存段全部置为0，使用bzero而不使用memset影响并不大，使用memset需要多传入一个参数来确定需要重置的值。在《Unix网络编程》里创建sockaddr_in结构变量时，把对应内存空间数据清空用到了bzero，并讲了一下和memset的区别，具体内容可以去看看这本书。 头文件暴露的四个函数在头文件中暴露了四个外部可用的函数，分别是：weak_register_no_lock、weak_unregister_no_lock、weak_is_registered_no_lock和weak_clear_no_lock，根据注释来看主要是针对weak_table_t的添加、删除和清空数据等操作。在这里以下面的代码为基础来讲解： 1__weak id refer = obj; 下面再来具体看看这几个函数在干什么？weak_register_no_lock源代码中提出，注册一个新的键值对，如果新的弱对象不存在则去新创建一个对应的entry。 1if (!referent || referent-&gt;isTaggedPointer()) return referent_id; 如果被弱引用指向的对象（obj）是isTaggedPointer，这里便不做相关操作，直接返回弱引用指向的对象（obj）。关于什么是Tagged Pointer，后面我再去细看一下里面的源码。从这里的源码可以看出，如果是TaggedPointer就不做后续操作，因为指针并没有指向真正的内存地址，返回的值则是被引用对象自身。 12345678weak_entry_t *entry;if ((entry = weak_entry_for_referent(weak_table, referent))) &#123; append_referrer(entry, referrer);&#125;else &#123; weak_entry_t new_entry(referent, referrer); weak_grow_maybe(weak_table); weak_entry_insert(weak_table, &amp;new_entry);&#125; 如果存在对应的entry则直接调用append_referrer进行插入。如果不存在，则调用weak_entry_t的构造函数创建一个新的对象，并查看是否需要针对weak_table进行扩容，将新的entry插入到weak_table中。下图是一个为对象增加弱引用，并将引用添加到weak_table中的简易流程： 现在来看一下weak_unregister_no_lock函数，针对weak_table的移除，必须确保entry已经存在于weak_table中，才会去进行后续的操作，同样把对应的流程图画出来：最后两个函数是一个是debug状态下用于判断某一entry是否存在于weak_table中，另一个函数则是对特定的被弱引用的对象（obj）的所有引用做清楚操作。 结语到这里objc-weak应该算是讲清楚了（天知道我的表达能力怎么样。。。），最后我从外层结构到内层结构来一一总结下：1、weak_table可以存储多个entry，而且它会根据其散列表中entry的个数来伸缩其所占内存大小；2、一个entry表示的是一个被弱引用的对象（上文提到的obj），该变量可以被多个变量弱引用（refer）。所以entry也存在一个散列表，其用来存储对应的弱引用变量的引用。也就是前面源码里面提到的指向指针的指针。3、entry的out_of_line_ness只有在弱引用变量大于WEAK_INLINE_COUNT时才会置为REFERRERS_OUT_OF_LINE。也就是只有在这时候union才会使用struct1结构内存布局。4、还有就是out_of_line_ness == 0b10没有看懂。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[记一次LFU缓存实现]]></title>
      <url>%2F2018%2F01%2F17%2Flfu4cIniOS%2F</url>
      <content type="text"><![CDATA[这篇文章大多是我自己的基于iOS开发一个想法过程，实现并不难。不过我并不会贴出全部代码，天知道我组织文章的根据是什么，能看懂都是缘分。 前言讨论缓存时，都会分内存缓存和硬盘缓存，本文主要是基于内存缓存的，但是完全可以稍加改动便可以应用于硬盘缓存中。在做其他文件IO的时，会有很多情况会基于C。基于此，我选择了使用C来实现核心部分。而它的作用是主要用于WebView在内存中的缓存数据。 关于LFU的一些概念之类的东西就不说了，原理实现网上一大堆。基于自己单链表通过栈来实现LFU的方式实现一下，这不一定是最优解，也有可能是最差解。不管怎么说，先通过一个图阐述一下主要的数据结构： 多想一点儿东西在看了上图之后，首先的想法就是去把具体算法撸出来。但是在开动写代码之前，我们需要想的东西应该要更多。在面向过程的思想中想开来，使用栈的时候取出操作可以很快速的完成最快可以达到时间复杂度为O(1)，而在维护栈顺序的时候，最坏的时间复杂度为O(N)，其查找和位置更新是在同一个循环中完成的，避免了不必要的时间消耗。 加入到面向对象中显然用C来做业务逻辑开发始终有点儿蹩脚，所以得引入到面向对象中。我把这个类取名叫做PPWebFetchCache吧，既然都面向对象了，要不再弄点儿设计模式进去？考虑到易于操作性，对于PPWebFetchCache类，我做了一个单例，当然也可以自己生成一个对象。到了这里下面应该要想的就是对象的属性和操作方法等等事情，但是自己想着就用了一个单例模式这不是表明我设计模式很low吗？不过事实的确是这样，我没有什么好的设计模式拿出来~~~所以我就硬塞了一个简单工厂模式进去。它做什么呢？我想的是“现在只是做LFU，万一哪一天变化来了，让我用写一个LRU的缓存策略，那我不是死得很惨！”，所以我又创建了一个继承于PPWebFetchCache类的PPWebFetchLFUCache，和另一个用于将来实现LRU算法的PPWebFetchLRUCache类。并在最后给父类添加了属性maxMemoryCost、maxMemoryCountLimit和两个操作方法storeCacheInMemory、memoryCacheWithURL。 走进实现细节上面说的LFU是针对于某一个URL的使用次数。在思考如何使用最少时间拿到URL对应的数据时，显然散列表最理想的数据结构，而且在iOS中用散列表实现的代表便是Dictionary。所以大致的逻辑是： 使用NSDictionary来实现URL和数据一对一在内存中的存储。而LFU主要用于管理某一URL的使用次数，淘汰掉使用次数最少的URL，并在内存字典中删除对应的数据。 PPWebFetchCache对外暴露的接口只有存和取，而具体的加入和删除操作则是在内部通过maxMemoryCost、maxMemoryCountLimit控制实现。 异步环境显然在数据存取的时候，我们不应该放在主线程中去做这些事儿。因此我创建串行队列用来执行这些事务： 12345678910111213static dispatch_queue_t background_serialQueue()&#123; static dispatch_queue_t queue; if (!queue) &#123; char *const label = &quot;com.example.webprefetchCache&quot;; dispatch_queue_attr_t attr = dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_USER_INITIATED, 0); queue = dispatch_queue_create(label, attr); &#125; return queue;&#125;void async_inbackground(void(^block)(void))&#123; dispatch_async(background_serialQueue(), block);&#125; 为什么要用串行队列？因为在队列内部操作，我不需要关心会出现资源竞争的问题。而在串行队列以外其他队列中来操作单例的相关数据时，我就需要去关心的线程安全的问题。因此我直接使用适用于静态分配的的互斥量PTHREAD_MUTEX_INITIALIZER来保证数据的同步操作。反观如果我去使用pthread_mutex_init来动态生成一个互斥量的话，我还要操心什么时候去destroy掉它（当然这里得仔细思考造成死锁的问题）。 1234567891011static inline pthread_mutex_t mutext_lock(void)&#123; static pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; return lock;&#125;static void safeProgressWith(void(^block)(void))&#123; pthread_mutex_t lock = mutext_lock(); pthread_mutex_lock(&amp;lock); block(); pthread_mutex_unlock(&amp;lock);&#125; 在加锁等操作时，尽量让其颗粒度更低。这样可以减少不必要的线程处于waiting状态，也就相应地减少出现低优先级线程饿死的情况发生（尽量减少CPU密集型线程的时间片）。 LFU的具体实现LFU只是针对于URL的淘汰策略，淘汰了URL之后，根据该URL到NSDictionary中找出对应的数据进行移除。这里使用链表的方式实现栈结构，其结构如下： 123456typedef struct __PPWebLFUFetchInlayerNode_ * _PPWebLFUInlayerNodeRef;typedef struct __PPWebLFUFetchInlayerNode_ &#123; char *url; int use_count; _PPWebLFUInlayerNodeRef next;&#125;_PPWebLFUFetchInlayerNode; 在PPWebFetchLFUCache类中保存了一个_PPWebLFUInlayerNodeRef的指针，这个指针指向栈顶： 123@interface PPWebFetchLFUCache:PPWebFetchCache&#123; _PPWebLFUInlayerNodeRef _lfuStack;&#125; 走到这里我们大可以直接使用_lfuStack成员变量来对栈进行相应的操作，但是我们可以更进一步！这里思维跳跃一下，当我们在插入一个节点时如何去判断当前节点是新增节点、还是存在于栈中的节点、抑或是需要删除的结点？如果只是简单的回答“我在插入节点时，先遍历一遍栈看元素是否存在于其中”，这样做毫无意义，而且平添一倍的时间消耗，因为后面的插入操作时，还要去遍历一次找到对应的节点位置。为了能够更好地在同一个循环中处理插入数据，查找数据，删除数据等操作。这里需要在执行C操作时在适当地点给我们回调，让我们有机会在一次循环中做完这些操作。为什么要用回调呢？我们完全可以把删除的相关逻辑放在某一次循环中，这样就需要我们在调用逻辑时传入一些判断条件。这无疑是增加了算法的局限性，从另一点来说，这个算法的适用范围就大大降低了。所以我引入了一个上下文环境，这个环境主要用于包裹相关信息数据和函数指针回调： 1234567891011121314151617181920212223typedef struct __PPWebLFUFetchCacheContext *PPWebLFUFetchCacheContextRef;typedef struct __PPWebLFUFetchCacheContext &#123; _PPWebLFUInlayerNodeRef *node;/// root void *info;/// 一般传入fetchCacher对象 void (*appendInStackRootCallback)(void *info, char *const key);/// 栈顶插入回调 void (*appendInStackBottomCallback)(void *info, char *const key);/// 栈底插入回调 void (*appendInStackCallback)(void *info, char *const key);/// 栈中插入回调&#125;PPWebLFUFetchCacheContext;/// 调用这个方法之后，如果不再需要使用这个指针，需要调用free来释放内存空间PPWebLFUFetchCacheContextRef PPWebLFUFetchCacheContextCreate(void *root, void *info, void (* _Nonnull appendInStackRootCallback)(void *info, char *const key), void (* _Nonnull appendInStackBottomCallback)(void *info, char *const key), void (* _Nonnull appendInStackCallback)(void *info, char *const key))&#123; PPWebLFUFetchCacheContextRef ctx = (PPWebLFUFetchCacheContextRef)malloc(sizeof(PPWebLFUFetchCacheContext)); ctx-&gt;node = root; ctx-&gt;info = info; ctx-&gt;appendInStackRootCallback = appendInStackRootCallback; ctx-&gt;appendInStackBottomCallback = appendInStackBottomCallback; ctx-&gt;appendInStackCallback = appendInStackCallback; return ctx;&#125; 至于这里为什么选择一个上下文？当我们需要多个回调时，完全没有必要把每一个回调都添加到函数参数中去，我们可以把这些参数包装起来。而且这样包装起来做还有一个优势，就是新增回调场景时就要方便许多！ 元素添加现在所有的条件都已具备，是时候来处理这些具体的逻辑了。就像是在学红黑树的时候一般都会把它那5个特性先提出来是吧。所以这里需要明确几点特性： 1、由链表实现的一个栈，只有一个根节点（上面提到的，包装在上下文中的lfustack）； 2、栈的深度是有限制的； 3、添加和删除操作是基于栈顶； 4、栈内元素的使用次数是从小到大，从上到下生长； 基于以上，我定义了一个元素添加函数的原型： 1bool _PPWebFetchLFUInlayerQueueAdd(PPWebLFUFetchCacheContextRef context,char *const url) 很明显传入的context是需要在外面创建好的一个指针变量，但是context的具体成员变量我们没有控制，全部传入NULL都可以（因为懒，不想对函数指针做非空判断，所以我把函数指针设置为_Nonnull。。。），这没有什么问题。因此首先要做的就是判断栈是否为空： 123456789101112if (!(*(context-&gt;node))) &#123;/// 创建栈顶指针 _PPWebLFUInlayerNodeRef node = allocNewNode(url); if (!node) &#123; return false; &#125; __block _PPWebLFUInlayerNodeRef *_broot = (context-&gt;node); safeProgressWith(^&#123; *_broot = node; (context-&gt;appendInStackRootCallback)(context-&gt;info,url); &#125;); return true;&#125; 在上面这段代码中我们使用了context的一个函数指针回调，当在空栈中加入根节点，这是符合该函数指针回调语义的。此时的栈分布情况很简单，但还是画出来更加明显：在这之后插入结点时，我们便需要考虑新添加进来的URL是新节点还是在原有节点上增加使用次数。这里我们需要一个循环从根节点开始遍历栈，如果找到了对应的URL，便将其使用次数加一，如果走到栈底还是未能命中对应的URL，则需要以该URL为数据创建一个新节点，并将这个节点作为栈根。实现代码如下： 123456if (0 == strcmp(lead-&gt;url, url)) &#123; (context-&gt;node)-&gt;use_count++;&#125;else&#123; (context-&gt;appendInStackRootCallback)(context-&gt;info,url); return appendRootNodeInStack((context-&gt;node), url);&#125; 上面涉及到的函数appendRootNodeInStack主要用于生成一个节点之后，并将该节点设置为根： 12345678910111213bool appendRootNodeInStack(_PPWebLFUInlayerNodeRef *root ,char *const url)&#123; /// 在栈顶插入 _PPWebLFUInlayerNodeRef node = allocNewNode(url); if (!node) &#123; return false; &#125; __block _PPWebLFUInlayerNodeRef *_broot = root; safeProgressWith(^&#123; node-&gt;next = *_broot; *_broot = node; &#125;); return true;&#125; 所以现在会出现两种情况，如下所示：这段逻辑代码目前并没有放在循环中来做，它和栈中已经存在四个、五个节点的情况是类似的，但它的情况要简单许多，它只需要处理使用次数更新或者头节点插入的情况，不会涉及到删除（除非你不做缓存）、移位操作。到最后我会把这段代码合并起来，而那正是我设计这套算法的中心思想。 节点移动和删除针对节点的移动，需要考虑多个情况，包括：从栈顶移动到栈底、从栈顶移动到栈中某一个位置、从栈中某一个位置移动到栈中另一个位置、从栈中某一个位置移动到栈底、不移动。我把这些情况依次描述到图中，这样看着更直观：下面是后面两种情况：从上面虚线箭头到实线箭头的变化可以很明显看出来，是复杂了不少。而最后一种无变化的，我就没有列出来。看看前面四种情况变化后的栈元素排列情况，从左到右，从上到下依次是： 2-&gt;3-&gt;4-&gt;1; 3-&gt;2-&gt;4-&gt;1; 2-&gt;4-&gt;3-&gt;1; 2-&gt;3-&gt;1-&gt;4; 从上面四种情况来看，对于一个节点的移动可以分为两部拆开来看，分别是——取出、放入两个过程。我直接把中间的的算法列出来： 1234567891011121314151617181920212223242526272829303132333435363738_PPWebLFUInlayerNodeRef previous = lead;_PPWebLFUInlayerNodeRef pivot = NULL;_PPWebLFUInlayerNodeRef prepivot = NULL;do &#123; if (0 != strcmp(lead-&gt;url, url)) &#123; if (!pivot) &#123; continue; &#125; if (pivot-&gt;use_count &lt;= lead-&gt;use_count) &#123; break;/// 跳出循环去执行放入 &#125; if (*(context-&gt;node)==pivot) &#123; __block _PPWebLFUInlayerNodeRef *_broot = (context-&gt;node); safeProgressWith(^&#123; *_broot = previous-&gt;next; &#125;); &#125;else&#123;/// 取出 prepivot-&gt;next=pivot-&gt;next; &#125; continue; &#125; lead-&gt;use_count++; pivot = lead; prepivot = previous;&#125; while ((void)(previous=lead),(void)(lead=lead-&gt;next),lead);if (!pivot) &#123;/// 在栈顶插入 (context-&gt;appendInStackRootCallback)(context-&gt;info,url); return appendRootNodeInStack((context-&gt;node), url);&#125;if (!lead) &#123;/// 处理栈底情况 previous-&gt;next=pivot; pivot-&gt;next=NULL; (context-&gt;appendInStackBottomCallback)(context-&gt;info,url);&#125;else&#123;/// 处理栈中的放入 pivot-&gt;next=previous-&gt;next; previous-&gt;next=previous==pivot?lead:pivot; (context-&gt;appendInStackCallback)(context-&gt;info,url);&#125; 这段代码把上面提到的if-else判断也一起合并进来了，这里pivot主要是用来记录找到目标URL的哨兵，而prepivot用来记录哨兵前面一个节点（如果使用双向链表完全可以不用这个零时变量）。到这里基本上是把该算法的核心部分说完了，该算法的最坏时间复杂度就是O(N)，这种最坏时间复杂度的情况分别是：新节点插入，栈顶一次直接移动栈底（这个情况是发生在使用次数都为1时，栈顶元素此时+1的情况）。最优的时间复杂度情况是O(1)，直接栈顶数据更新。最后就是节点的删除操作，仅仅只是删除操作时间复杂度肯定是O(1)的。但是事情往往没有这么简单，必须要考虑当前添加进来的元素是到达容量限制的新元素，还是栈里面已经存在的元素呢？难道我们又要去遍历一次栈然后来做删除操作吗？这是完全没有必要的，因为要出现删除节点的情况，肯定是发生在向栈中Push元素时发生。因此我将上面各个情况分为三种大体情况，并为这三种情况提供了三个回调，而这个三个回调都是放在上面的context中： 在栈顶插入元素（appendInStackRootCallback）； 处理栈底情况（appendInStackBottomCallback）； 处理中间节点（appendInStackCallback）； 基于这： 我们可以一次循环中完成新增、移动、删除操作！ 上面提到的三个回调，可以通过调用PPWebFetchLFUCache实例方法来看一下一个整体过程： 123456789101112131415161718192021- (BOOL)insertCacheMap:(NSData *)object forKey:(NSString *)key&#123; PPWebLFUFetchCacheContextRef ctx = PPWebLFUFetchCacheContextCreate( &amp;_lfuStack, (__bridge void *)(self), &amp;progressingAppendInStackRootCallback, &amp;progressingAppendInStackBottomCallback, &amp;progressingAppendInStackCallback); bool result = _PPWebFetchLFUInlayerQueueAdd(ctx, (char *)[key UTF8String]); if (result == false) &#123; PPWebLFUFetchCacheContextRelease(&amp;ctx); return NO; &#125; if (![self.cacheMap.allKeys containsObject:key]) &#123; safeProgressWith(^&#123; [self.cacheMap setObject:object forKey:key]; self.currentCacheUsage += object.length; &#125;); &#125; PPWebLFUFetchCacheContextRelease(&amp;ctx); return YES;&#125; 在上面创建上下文的代码中，第一个参数为保存在PPWebFetchLFUCache单例中的一个成员变量，而info参数主要用来传递self，这里用context时，_lfuStack会被context保留，而_lfuStack又会被PPWebFetchLFUCache单例保留，但是在函数返回之前会对context做release操作，会把对_lfuStack的保留置空，所以不要想着OC里面常出现的引用计数不会降为0的问题。而且也不会出现相互持有的关系。而回调函数中，主要来看progressingAppendInStackRootCallback的回调： 123456789101112void progressingAppendInStackRootCallback(void *info, char *const key)&#123; PPWebFetchLFUCache *cacher = (__bridge PPWebFetchLFUCache *)(info); if (!cacher) &#123; return; &#125; if (cacher.cacheMap.allKeys.count &gt;= kMaxMemoryCountLimit) &#123; [cacher deleteCacheMap]; progressingAppendInStackRootCallback(info, key); &#125;else&#123; return; &#125;&#125; 下面我直接把删除函数贴出来，这并没有什么难点： 1234567891011121314151617_PPWebLFUInlayerNodeRef _PPWebFetchLFUInlayerQueueDelete(PPWebLFUFetchCacheContextRef context ,char **url)&#123; if (!(context-&gt;node)) &#123; return NULL; &#125; _PPWebLFUInlayerNodeRef lead = NULL; lead = *(context-&gt;node); __block _PPWebLFUInlayerNodeRef *_broot = (context-&gt;node); if ((*_broot)-&gt;next) &#123; safeProgressWith(^&#123; *_broot = (*_broot)-&gt;next; &#125;); &#125; if (url) &#123; (*url) = (lead-&gt;url); &#125; return lead;&#125; 上面出现的deleteCacheMap方法中会把不再使用的节点free掉。 后语上面代码中很多地方都用到了safeProgressWith函数，其实现也在上面列出来了。使用它的目的有两个：第一个、PPWebFetchLFUCache类的操作是可以在多线程异步环境下操作的，所以我必须要保证cacheMap的数据同步；第二个、虽然基于C的操作我都是放在一个串行的队列中进行： 123456async_inbackground(^&#123; BOOL result = [self insertCacheMap:data forKey:url]; if (complete) &#123; complete(result); &#125;&#125;); 但是_lfuStack成员变量是可以通过hook的方法拿到，并让其在异步环境下去进行修改，这个我没法去控制，但是我要做到在LFU内做到一个同步操作，所以基于跟节点的操作都是在加锁状态下完成的。这里需要注意的就是不要出现互斥锁的嵌套使用，如果使用的是同一个锁变量的话，那肯定会造成死锁的。 完。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[来唠嗑一下线程中的一些事儿]]></title>
      <url>%2F2017%2F11%2F16%2Ftalk_about_thread%2F</url>
      <content type="text"><![CDATA[由于前段时间的工作中，在一个并发编程题中栽了跟头,也因此增加了我对这一方面的理解。下面我会结合例子的方式来阐述一下我的一点儿小理解。 线程 对于并发编程可能首先想到的便是和多线程有关，这又需要涉及到线程的概念。维基百科上关于线程的解释，我提取一个我认为比较关键的概念： 它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 每个线程存在自己的栈和寄存器集合，所以在这种情况下去保证线程相对安全的时候应该要使用violate变量（防止编译器缓存了被多个线程寄存器并发用到的变量，让编译器直接去变量地址获取）。 上面的重点在于“线程是包含于进程中，并且一条线程实际上一段代码的执行流”（代码区是被进程内多个线程共享的）。这里也就不过多深入地去解释了，贴一个我翻译的官方的多线程编程文档，并配合有创建线程不同方式的代码。我之所以专门把这个提出来是因为我在这个知识基础上遇到过一个面试题——“我们使用异步的方式从服务端获取到了我们需要的数据，然后我们如何去更新对应视图？”。如果不去细想的话直接扔出一段代码：12345678910 [self post:url aPara:nil completionBlock:^(id responseObject, NSError *error) &#123;#if defined(USE_GCD_UPDATE_UI) &amp;&amp; USE_GCD_UPDATE_UI == 1 dispatch_async(dispatch_get_main_queue(), ^&#123; /// 更新UI &#125;);#else /// updateView中更新UI [self performSelectorOnMainThread:@selector(updateView:) withObject:responseObject waitUntilDone:NO];#endif &#125;]; 为什么在子线程中更新UI是不安全的 他会继续追问你，我们为什么必须要把更新UI的任务放在主线程来做？放到子线程不可以吗？对于这个问题我只能用我浅显地认识来解释一下这个问题，因为操作系统相关的东西我几乎忘的差不多了。这里先抛出一个概念——基于UIKit的控件是线程不安全的。那么为什么苹果要把UIKit设计为线程不安全？ 最直观的来说，在牺牲性能为代价的前提下，使用同步能够确保代码的正确执行。在大多数情况下使用同步工具都会造成延迟。锁和原子操作通常会涉及到使用内存屏障和内核级的同步来确保代码正确执行。当出现锁竞争的情况下，线程可能会被阻塞从而导致体验上的延迟卡顿。所以我猜测有基于这个原因导致了苹果将UIKit设计成了线程不安全。这就回答了上面提出的“我们为什么必须要把更新UI的任务放在主线程来做？” 下面我通过画图的方式来表达一下在并行状态下UIKit不使用同步工具的情形：就如上图所示在主线程和子线程的消息队列中同时去修改同一内存空间中的值，如果不添加一个同步操作的话会发生意想不到的事情。Objective-C中的对象是存放在堆区，而堆区和前面我提过的代码区一样是线程共享的。现在我们知道为什么需要我们在主线程中去更新UI。而对于另一个问题：放到子线程不可以吗？或许在AsyncDisplayKit中能够找到子线程处理视图的答案。 子线程是如何实现在主线程中更新UI 现在回到最初的问题上来，子线程和主线程是怎样协调工作来更新视图的呢？更新的代码我在上面已经放出来了，但是面试官的目的是想要知道其底层实现，先来看一下官方文档中出现的一个图片：如果要完整的讲一下我的理解的话，需要以下这些假设。我们把右边绿色的这一部分当做是子线程，而左边紫色的部分当做是主线程；并且我们有自定义一个输入源（因为我想完整的模拟这个场景，而不是使用系统提供的封闭的输入源），我们要通过该输入源来给主线程的Runloop发送消息（你可能会问为什么要用输入源？我直接发消息不可以吗？不好意思，Runloop就人输入源或者定时器源）。 首先来创建一个自定的输入源，这个输入源负责从子线程给主线程的Runloop发送消息：123456/// .h@interface RunloopSource : NSObjectvoid runloopsrc_schedule(void *info, CFRunLoopRef rl, CFRunLoopMode mode);void runloopsrc_perform(void *info);void runloopsrc_cancel(void *info, CFRunLoopRef rl, CFRunLoopMode mode);@end 上诉头文件中的三个函数分别是： schedule表示注册成功并提供外部给子线程传递数据；perform是子线程通过输入源想要给主线程传输的主要出口；cancel是在我们异步处理完了之后，调用CFRunLoopSourceInvalidate函数告知主线程Runloop该输入源已经完成其职责。1234567891011121314151617181920212223242526272829303132333435363738394041///.m- (instancetype)init&#123; self = [super init]; if (self) &#123; CFRunLoopSourceContext ctx = &#123; .info = (__bridge void *)(self), .retain = NULL, .release = NULL, .copyDescription = NULL, .equal = NULL, .schedule = runloopsrc_schedule, .perform = runloopsrc_perform, .cancel = runloopsrc_cancel &#125;; &#125; return self;&#125;void runloopsrc_schedule(void *info, CFRunLoopRef rl, CFRunLoopMode mode)&#123; ...&#125;void runloopsrc_perform(void *info)&#123; RunloopSource *src = (__bridge RunloopSource *)info; [src sourceFire];/// 接口用c，但是处理数据，看习惯，习惯用OC&#125;void runloopsrc_cancel(void *info, CFRunLoopRef rl, CFRunLoopMode mode)&#123; ...&#125;- (void)sourceFire&#123; if (self.sourceFire_handle == nil) &#123; return; &#125; @synchronized (command_data) &#123; /// 处理数据 /// 回传给主线程数据 /// 在输入源中，也就是这个函数中去给主线程的Runloop发送消息，让其更新界面 /// - (void)performSelector:(SEL)aSelector onThread:waitUntilDone:modes: &#125; CFRunLoopSourceInvalidate(runloop_src);&#125; 到这里假设我们已经从- (void)URLSession: dataTask:didReceiveData:;（NSURLSessionDataDelegate协议）获取到了数据，此时在runloopsrc_perform 中调用performSelector方法给主线程Runloop发送消息。现在我们把注意力放在上图左边的紫色部分，可以看出它一直处于一个循环中。如果此时消息队列中存在消息，那么该Runloop会处理消息队列中的消息，如果消息队列为空，那么Runloop应该是处于一个休眠状态。当他收到了由我们从子线程的自定义输入源发来的消息时，他会被唤醒来处理该消息。此时在主线程中去执行更新UI的事件。 对于这一块儿我并没有十足的把握，如果有更好的理解麻烦告知与我，万分感谢。 我所了解的线程小常识到这儿了主要就说一点儿我所了解的线程，其中主要包括了线程优先级和调度问题，线程和他寄存器之间的一点儿恩怨！ 关于线程优先级和调度在多对一的线程模型中，一个内核线程对应了多个用户级线程，其实这时候的并发并不是真正意义上的并发，它应该是基于CPU轮转的方式来调度不同用户级线程，让他们每个都执行一小段时间，做到类似并发的效果。所以后面的线程模型都是基于多对多模型，它既可以实现真实的并发，又可以减少一对一模型中线程切换的消耗。 我们可以给线程设置不同的优先级来改变它们的先后执行顺序，除了我们指定的方式，系统会在以下两种情况下去更改线程优先级： I/O密集型线程会比CPU密集型线程更容易被系统提高优先级。因为I/O密集型线程会经常进入waiting状态，而进入waiting状态说明它的任务花费时间短。而CPU密集型线程则是耗费完时间片之后进入ready状态。 对于I/O密集型线程来说，如果给它分配了较低优先级。而CPU密集型线程分配了较高线程优先级，那么就会造成I/O密集型线程处于“饿死”状态。所以系统会将长时间没有运行线程的优先级提高。 编译器优化所带来的问题编译器为了能够让CPU在获取数据更快速，它会把一些需要经常访问的数据读取到寄存器中。为什么寄存器比内存快？，我的理解是由于寄存器存在于CPU内，内存和CPU之间相隔了一个北桥芯片，而它们是通过PCI总线来连接的，就距离上来说这可能是一个原因（我瞎扯淡）。因为这个优化会产生一些小问题，看下面一段代码：123456789101112NSThread thread1 = [NSThread detachNewThreadWithBlock:^&#123; NSLock *lock = [[NSLock alloc] init]; [lock lock]; i++; [lock unlock];&#125;];NSThread thread2 = [NSThread detachNewThreadWithBlock:^&#123; NSLock *lock = [[NSLock alloc] init]; [lock lock]; i++; [lock unlock];&#125;]; 这是线程安全的吗？我只能说不一定，因为这是一个偶然事件。下面我来说一下我理解的这个偶然事件是怎么发生的？ 【thread1】读取i的值到线程1的寄存器集合R1（R1 = 0）； 【thread1】R1++（由于之后可能还要访问i，所以thread1暂时不会把R1写回到i）； 【thread2】读取i的值到线程2的寄存器集合R2（R2 = 0）； 【thread2】R2++（R1 = 1）； 【thread2】将R2写回i； 【thread1】过了很久之后，将R1写回i（i=1）； 很明显这并不是我们想要的结果，这就是由于编译器的优化把值读取到了线程响应的寄存器集合中，改变的根本不是同一块儿内存上的值。所以为了解决这个问题可以使用前面提到的violate变量，以此来告诉编译器不要将该变量读取到寄存器中，而是直接在内存中进行操作。 并发与并行文章的最后我们唠叨一下并发这个词儿，关于并发和并行知乎上有一个回答解释的很通俗易懂。所以针对Apple的并发编程指南，指的是有能力同时去执行多个任务，但并不是指一定要同时执行多个任务。GCD就不说了，大部分时间都是在使用它（因为它在接口使用上易用）。重点来说一下NSOperation，它是即强大又难用。 在开始使用NSOperation之前，我们自己需要清楚“我们要干什么？Apple提供的NSOperation是否满足需求？我们自定义NSOperation子类是基于并行还是串行？等等”。这里提到的并行和串行就不解释了，再解释就是一篇科普文了。NSHipster上提到了关于NSOperation： NSOperation表示了一个独立的计算单元。作为一个抽象类，它给了它的子类一个十分有用而且线程安全的方式来建立状态、优先级、依赖性和取消等的模型。 所以NSOperation和NSOpertaionQueue不仅仅只是用于网络的情况，当然与之对应的GCD同样可以用于其他事物。试想一下我们是否可以把NSOperation用于一个加载动画。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[iOS中Native的方式集成Vuforia、其源码解读以及自定义模型]]></title>
      <url>%2F2017%2F09%2F13%2Fios_nativa_vuforia%2F</url>
      <content type="text"><![CDATA[随着前有Apple在iOS11中提供了ARKit，后有Google推出的ARCore，显然掀起了一股AR热潮（都是一堆废话，说白了就是公司要求做）。 由于Vuforia已经存在较长时间了，相对于EasyAR或者百度AR更为成熟一点儿，所以它成了第一个技术选择。EasyAR和百度的AR——DuMix AR后面再依次去学习。好吧，先开始来学习Vuforia吧！该文章同步发布在我的博客. 集成步骤由于这些步骤相对来说比较基础，我就直接罗列出来。 1、开发者官网https://developer.vuforia.com； 2、下载ios-sdk和ios-sample，并按照官方文档要求将ios-sample放入到ios-sdk的sample文件夹下 3、在vuforia的开发者官网上的License Manager和Target Manager，添加License-key和database 4、将上一步添加的License-key，放在ios-sample中的代码文件SampleApplicationSession.mm中的方法Vuforia::setInitParameters(mVuforiaInitFlags,&quot;&quot;);中。具体步骤见官网。 Vuforia::setInitParameters(mVuforiaInitFlags,"AT16FIX/////AAAAGVieZ/kg1UkghTnYAz5zXWs8+y5JjeF/NJRcjgVDoCSvsrSt+lWzFMcIVBbQ2YSFRF+6J0GceHoaz8NctXib3cndJEacXmR+1FyO5FhalO7sC4hE9d1/x72qTNDhkPs4rF04JulMYT876Grsnmg9C61oyaDVwBfSpzNZ7gx3NADkkV5q4NQs4ghZwVCdMhj6LVt1YTJcwiuULtDTEgpFZZeW/nC8yiC53hpUFOVxhH++ILx1T65jpY8yDn6ct++3mgVeVotg/5tWXYb5FYqBtJiwU/LJJxhJYqUWyy4pd9dHUJBQojuAE8FoW1DmjokrpDWgjOMMp3am4GjNT04hCg+o0Z3SByYx6VIqfSR9fsXw"); 5、将第3步中Target Manager创建的database，传入相关的图片文件。也可以不传，这步可选；怎样使用设备数据。我们在官方Developer创建，下载对应的Database，在添加图片时，对应的星星数越高表明识别度越高解压并将其引入到工程中：这一步可以不做，因为这只是在给后面打基础而已，如果只是运行demo的话是不需要做这一步的。如果做了这一步，在扫描你对应的图片的时候是没有任何效果的，具体的操作后面。 6、编译运行，由于需要使用到传感器，所以必须使用真机来运行。关于真机运行的相关事项查看apple developer 源码阅读顺序 源码说明：Voforia SDK版本：vuforia-sdk-ios-6-5-19iOS Samples版本：vuforia-samples-core-ios-6-5-20 如果不想看源码相关可直接跳过这部分，直接跟着“收尾”做自定义的tracker和模型（替换Teapot茶壶模型为自己的） 为何要阅读源码？因为在Voforia的官方文档中我没有找到我自己想要的信息。所以我们需要通过阅读源码，来找到怎样才能去修改贴在目标图像中虚拟模型。以sample中ImageTargetsViewController为例来解读！首先查看ImageTargetsViewController.h文件，我们先不看成员变量。先来看属性 属性 属性类型 初步作用 eaglView ImageTargetsEAGLView* 初步认定为一个展示视图 tapGestureRecognizer UITapGestureRecognizer* 一个点击手势 vapp SampleApplicationSession* 初步认定为一个会话层（类似于ISO网络七层模型中，在TCP可以归于应用层，也就是说想偷懒可以直接将其代码放入控制器中。个人理解） showingMenu BOOL 一个flag 从上表中出现的属性，我们先来分析一下属性eaglView和vapp。 SampleApplicationSession类在ImageTargetsViewController控制器类中，和下面会讲到的ImageTargetsEAGLView都有SampleApplicationSession类型的属性，所以我们有必要先来看看该类。同样的先看头文件，因为头文件能够让我们对于该类有大体的认识，而不拘于类具体的实现细节。 粗略来看，提供了一个初始化方法；一个初始化AR的方法；四个对AR的操作方法（它们不是我们需要的重点，等到需要的时候再来仔细阅读）；以及一个对Camera的方法：1234567- (id)initWithDelegate:(id&lt;SampleApplicationControl&gt;) delegate;- (void) initAR:(int) VuforiaInitFlags orientation:(UIInterfaceOrientation) ARViewOrientation;- (bool) startAR:(Vuforia::CameraDevice::CAMERA_DIRECTION) camera error:(NSError **)error;- (bool) pauseAR:(NSError **)error;- (bool) resumeAR:(NSError **)error;- (bool) stopAR:(NSError **)error;- (bool) stopCamera:(NSError **)error; 上述的initAR方法是通过异步实现的，当其AR初始化完成之后会调用方法下面会提到的代理方法onInitARDone。顺藤摸瓜，我们来看看该代理，那么该代理所需要处理的事务有哪些呢？这里先将SampleApplicationControl的所有方法先列出来：123456789101112@required- (void) onInitARDone:(NSError *)error;- (bool) doInitTrackers;- (bool) doLoadTrackersData;- (bool) doStartTrackers;- (bool) doStopTrackers;- (bool) doUnloadTrackersData;- (bool) doDeinitTrackers;- (void)configureVideoBackgroundWithViewWidth:(float)viewWidth andHeight:(float)viewHeight;@optional- (void) onVuforiaUpdate: (Vuforia::State *) state; 该代理方法中大多是涉及到的是tracker。通过从初始化方法开始查看方法调用，得出了一个程序执行流程图，我们主动调用initAR方法，其结果会由回调方法onInitARDone反应给开发者。开发者可以用通过调用doInitTrackers来控制是否需要去加载tracker数据，如果可以加载数据则通过调用回调方法doLoadTrackersData来获取数据。关于该类中其他几个方法startAR , pauseAR, resumeAR, stopAR由调用人员主动调用，调用这些方法会触发对应的方法回调。现在我们需要把目光转向ImageTargetsEAGLView类，并去具体的看一下里面的相关细节。 SampleAppRenderer类这个类主要是做渲染相关的工作，其源码大多数为OpenGL。所以对于该类我只做具体的作用分析，而不去解释具体的源代码（因为我也不懂），如有需要的话，自行深究吧，哈哈哈😄。这里先将各个方法的作用罗列出来： 方法名 方法作用 initWithSampleAppRendererControl 类初始化方法 initRendering 渲染相关的初始化 setNearPlane:farPlane: 配置投影矩阵数据 renderFrameVuforia 由Vuforia调用，渲染数据帧到屏幕 renderVideoBackground 后台渲染视频 configureVideoBackgroundWithViewWidth:andHeight: 视频相关的配置 updateRenderingPrimitives 更新渲染数据 下面具体分析：老规矩，同样先看头文件，我们根据头文件暴露出来的方法一层一层往里剥。该类存在一个协议SampleAppRendererControl，和一个初始化方法initWithSampleAppRendererControl。使用这个方法需要传入一个遵守SampleAppRendererControl协议的类实例，第二个参数来决定VR/AR的模式，以及三个用于决定投影矩阵的参数。除了在初始化方法设置投影矩阵的参数，该类提供了一个public方法setNearPlane:farPlane:。进入到.mm文件中查看该初始化方法可以看出，只是对类内部私有属性进行相关的赋值操作以及对硬件设备进行相关的设置吧。 现在来看看方法initRendering，这个方法里面主要是做了一些OpenGLES的东西，我们只需要知道里面做了一些和具体业务逻辑无关的东西就行了。 接下来看renderFrameVuforia的作用是什么？源代码中说的很清楚：使用OpenGL绘制当前帧，当需要将当前帧渲染到屏幕上时，Vuforia会定期的在后台线程调用该方法。同样和业务逻辑无关，源码不细看。同样方法renderVideoBackground也是使用OpenGL来做，我们只需要从该方法的名字得知其用途（后台渲染视频）即可。 configureVideoBackgroundWithViewWidth:andHeight:方法从名字就可以知道其作用。updateRenderingPrimitives方法的作用是：当屏幕尺寸发生改变或者是设备朝向改变之后，调用该方法来更新渲染原始数据。 最后需要介绍一下该类很重要的的一个协议方法：renderFrameWithState，该方法被用于获取渲染相关的数据。通过对.mm文件可知，每渲染一次都会调用该方法一次。 ImageTargetsEAGLView类该类的头文件所暴露出来的初始化方法- (id)initWithFrame:(CGRect)frame appSession:(SampleApplicationSession *) app，我们以该方法入手来分析。第一个参数为当前视图的大小设置，第二个参数为前面我们讲到过的一个类实例。头文件中余下的方法还有：123456- (void)finishOpenGLESCommands;- (void)freeOpenGLESResources;- (void) setOffTargetTrackingMode:(BOOL) enabled;- (void) configureVideoBackgroundWithViewWidth:(float)viewWidth andHeight:(float)viewHeight;- (void) updateRenderingPrimitives; 方法finishOpenGLESCommands , freeOpenGLESResources分别对应着结束OpenGL和释放OpenGL的资源。configureVideoBackgroundWithViewWidth:andHeight: , updateRenderingPrimitives和类SampleAppRenderer公开的方法名一样，这里我猜测它们作用是一样的。setOffTargetTrackingMode:方法作用目前还不是很清晰，需要去.mm文件中详查。 现在进入实现文件中，源码中提到了关于OpenGL线程安全的问题。iOS上的OpenGL ES是线程不安全的，在程序中Vuforia使用下面的方法来保证线程（OpenGL 上下文）安全： a、在主线程中创建OpenGL ES上下文。 b、Vuforia相机开始时，将其位于我们自己EAGLView视图上，并开启renderer线程。 c、Vuforia会在renderer线程上，定期调用我们的renderFrameVuforia（SampleAppRenderer类提到）方法。当第一次调用该方法的时候，defaultFramebuffer并不存在，调用createFramebuffer方法来创建它。createFramebuffer由主线程调用，而与此同时renderer线程会被阻塞。因此确保OpenGL ES上下文不会被并行使用 在initWithFrame:appSession:的实现方法中会进行session，OpenGL的context和Renderer的赋值，初始化和绑定工作。而方法configureVideoBackgroundWithViewWidth:andHeight: , updateRenderingPrimitives在其实现方法中的确只是简单的调用了一下SampleAppRenderer 类的实例方法。 现在主要来看看方法setOffTargetTrackingMode :，它的实现很简单只是对其私有成员变量NO。但是却在协议方法renderFrameWithState中大量的使用。该方法大部分是OpenGL相关的工作，我没有深究下去，只整理出来一个工作流程图：目前来看ImageTargetsEAGLView类的主要作用在于保证OpenGL在iOS中达到线程安全，创建buffer和对buffer的管理，提供了对OpenGL的控制，而实际的渲染则由SampleAppRenderer来实现。 ImageTargetsViewController类现在将目光回到ImageTargetsViewController类上面来。由于是一个控制器类，所以我直接从.mm文件中着手。根据ViewController的加载顺序来看具体的逻辑，首先查找loadView方法，如果没有则查找viewDidLoad。源码中，loadView方法主要创建了vapp，eaglView以及对vapp初始化了AR相关的事务（其他视图和手势等先忽略，只关心属性vapp,eaglView相关的逻辑），将ViewController的View设置为eaglView。 在loadView中将vapp的代理设置为控制器自身，此时通过上面介绍 SampleApplicationSession时对应的程序执行流程，将目光放在对应的部分协议方法上面。123456@protocol SampleApplicationControl- (void) onInitARDone:(NSError *)error;- (bool) doInitTrackers;- (bool) doLoadTrackersData;- (bool) doStartTrackers;@end 从图-1可以看出是由doInitTrackers的返回值来判断是否需要去加载tracker数据(doLoadTrachersData)，最后在onInitARDone方法流程结束。通过这个就确定了我们的源码查看顺序：1/// doInitTrackers --&gt; doLoadTrackersData --&gt; onInitARDone 那么在ImageTargetsViewController类中，其流程图如下：自此我们的源码阅读就告一段落，最后我们将要去实现开始提到的目的！ 收尾读到这里，自定义的数据集的切入点在方法doLoadTrackersData方法中，并且要doInitTrackers方法返回YES。如果没有执行“安装步骤”中的第5步的话，现在可以去做了！做完之后添加如下代码到工程中：12345678///ImageTargetsViewController.mm -&gt; doLoadTrackersDatadataSetCustom = [self loadObjectTrackerDataSet:@&quot;WillDB_Device.xml&quot;];/// 这个dataset为你自己的名字if (dataSetCustom == NULL) &#123; return NO;&#125;if (! [self activateDataSet:dataSetCustom]) &#123; return NO;&#125; 运行程序，扫描对应的图片发现是能够成功扫描对应的图片的。但是系统的图片能出来一个“茶壶”，而我们自己的图片上面什么也没有呢？在这里我不想又去使用这个烦人的“茶壶”OpenGL模型了，我选择的是一个皮卡丘的原型（在文末我会将改造过的demo传到Github可以去那里下载这个原型）。 模型obj到opengl数据的转换就目前我知道的来说，在Xcode中无法使用.obj的模型数据的。我在网上找到了一个工具obj2opengl，具体的使用方法见这里，我还是大体来说一下使用步骤：将下载好的文件放到特定的文件夹中，然后把对应的obj文件和它放在一起，使用终端进入obj2opengl.pl文件所在文件夹之后，输入如下命令：1./obj2opengl.pl yourobjfilename 成功后，它会生成一个头文件，这就是通过obj文件生成的纹理坐标代码，在该头文件中有3个数组，这三个数组分别对应着xxxVerts [], xxxNormals [], xxxTexCoords []，和一个xxxxNumVerts（xxx为你的obj文件名字），具体使用说明。 模型替换通过前面的源码阅读，我们知道ImageTargetsViewController类是用来加载tracker数据的，SampleAppRenderer类是做渲染相关的数据，SampleApplicationSession类是使用tracker数据并控制AR，最后只剩下一个ImageTargetsEAGLView类。在该类中会做如下操作： 1、在textureFilenames数组中，添加一个新的纹理。这个自己选择一个纹理图片，我是随便选的，所以看起来会很丑。 2、在ImageTargetsEAGLView类的头文件中添加一个私有成员变量pikachuModel。用它来代替例子中的buildingModel。并在SampleApplication3DModel.h文件中添加方法pikachu_ReWrite，并在SampleApplication3DModel.m文件中添加如下代码： 12345678- (void)pikachu_ReWrite&#123;#if kUse3DModel == 1 _numVertices = XY_PikachuMNumVerts; _vertices = XY_PikachuMVerts; _normals = XY_PikachuMNormals; _texCoords = XY_PikachuMTexCoords;#endif&#125; 3、在ImageTargetsEAGLView.mm的方法loadBuildingsModel中添加如下代码： 12pikachuModel = [[SampleApplication3DModel alloc] init];[pikachuModel pikachu_ReWrite]; 4、将ImageTargetsEAGLView.mm文件中所有的buildingModel替换为pikachuModel，最后调节一下变量kObjectScaleOffTargetTracking的值，这个值调节由自己决定。 上述的修改灵感大多是来自头文件Teapot.h，但是我们使用obj2opengl时生成的文件中并没有Teapot.h中teapotIndices对应的数组。相反多了一个无符号的整形变量xxxNumVerts，所以除了上诉的方法以外还有另外一种方法，具体的代码修改如下：123456/// ImageTargetsEAGLView.mm -&gt; renderFrameWithState方法中glVertexPointer(3, GL_FLOAT, 0, XY_PikachuMVerts);glNormalPointer(GL_FLOAT, 0, XY_PikachuMNormals);glTexCoordPointer(2, GL_FLOAT, 0, XY_PikachuMTexCoords);glDrawArrays(GL_TRIANGLES, 0, XY_PikachuMNumVerts); 在使用这个方法时其（用obj2opengl生成的头文件的数组中的）数值比例是需要修改的，而且还需要对模型进行翻转。这个方法具体见How do I replace the Teapot和Replace the teapot model。在修改源码时主要就是在修改方法renderFrameWithState，它在介绍ImageTargetsEAGLView类时在文件的最开头就有提到，它是在每捕捉到一次tracker之后就会运行一次。到这里一个很基本的Vuforia集成，源码的解读以及自定义tracker和模型就算完成了，最后附上Demo地址。 相关链接 obj2opengl obj2opengl Github OpenGL Transformation How do I replace the Teapot]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OC与C的交互及其内存管理]]></title>
      <url>%2F2017%2F08%2F01%2Foc_bridge_c_memory%2F</url>
      <content type="text"><![CDATA[首先我们从最基本的C中三种链接属性，分别是：外部(external)、内部(internal)、无(none)。我们可以通过关键字extern、static来修改变量的链接属性。 extern关键将一个变量声明为外部的链接属性之后，便可以去访问其他文件中同名该变量。static关键字在用于代码块外部的变量时是将其设置为内部链接属性，如果是在代码块内部则将该变量声明为静态变量。 然后再来看看C中变量的存储类型。存储类型决定了变量的创建、销毁时机。存储变量的位置一共三个地方：普通内存、运行时堆栈、硬件寄存器。结合C中的三种链接属性，具体可以分为： 栈区：代码块中的变量在一般情况下为自动变量（由高地址向低地址生长） 堆区：由malloc、realloc、calloc等函数动态生成的变量。这些变量我们只能访问其地址，而且当我们不再使用之后需要收到去free掉（由低地址向高地址生长）。 全局区／静态区：代码块之外声明的变量总是存储于静态内存中（默认的链接属性为external）。未初始化的变量放在一起，已经初始化的紧挨地放着。由于函数实参总是在堆栈中进行传递，所以函数的形参不能设置为static。 常量区：常量字符串 代码区 在代码块内部声明的变量的缺省存储类型是自动的，即它存储于堆栈中，称为自动变量。如果代码块被多次执行，那么自动变量将会重复创建，每一次创建时，它们在内存中的位置可能会不同。 至于上面提到的寄存器中的变量，因为CPU对于寄存器的读取速度非常快，通常编译器会将使用频率很高的变量将其移到寄存器中。如果寄存器变量在多线程编程时出现了问题，我们可能需要显式将该变量声明为volatile，让编译器不对该变量进行优化。 12345678910111213141516171819/** 全局静态区 */int a = 10; /// externalextern int b;/// externalstatic int c;/// internalint d(int e)&#123;/// 函数d 默认为external int f = 15;/// auto 栈区 static int g = 20;/// 静态变量 静态区 return 0;&#125;static int h(int i)&#123;/// 函数h 修改为static，internal register int j;/// 寄存器类型，但是不一定起作用 int *k = malloc(sizeof(int));/// 堆区 free(k); const int m = 25;/// 常量区 return 1;&#125; C中各个类型变量的内存管理C语言中的内存管理与链接属性和所在内存区域都有直接关系。栈区的自动变量会在其作用域之后自动进行销毁；堆区的中由用户动态的创建的内存，需要手动调用free函数来释放（否则会造成内存泄漏）； 全局区／静态区中的变量由系统创建和销毁，它们在程序开始运行之前就创建好，静态区的变量在程序运行过程中我们不能去修改； 常量区程序结束后由系统释放。 关于堆的一点儿说明：如果我们在使用malloc和free时是无序的话，最终会产生堆碎片。而且被分配的内存是经过对齐的，一般为2的乘方。 堆的末端由一个称为break的指针来标识，当堆管理器需要更多内存时，它可以通过系统调用brk和sbrk来移动break指针。 OC与C的交互(__bridge) 当oc在和c相关的函数（CoreFoundataion、Runtime）进行交互时，我们需要将OC的类型传递到C中，也需要将C中的数据返回给OC使用。这其中就需要使用它们类型之间的转换。在id类型或者对象变量赋值给void *或者逆向赋值时都需要进行特定的转换，单纯的赋值我们可以使用 __bridge 。 123NSObject *obj = [[NSObject alloc] init];void *p_obj = (__bridge void *)(obj);NSObject * r_obj = (__bridge NSObject *)(p_obj); 相对于__bridge，我们可以使用``bridge_retained修饰符，它即可以进行转换，也能持有被转换的对象__（上例中的obj ``），因此该对象不会被废弃。其语法形式如下： 1__bridge_retained &lt;#CF type#&gt;)&lt;#expression#&gt; bridge中还有个``bridge_transfer ，它的作用和__bridge_retained相反，被转换的变量（上例中的p_obj ）所持有的对象（上例中的obj ）会在r_obj ``被赋值之后释放掉，其语法形式如下： 1__bridge_transfer &lt;#Objective-C type#&gt;)&lt;#expression#&gt; 把上诉例子进行修改： 123NSObject *obj = [[NSObject alloc] init];void *p_obj = (__bridge_retained void *)(obj);NSObject * r_obj = (__bridge_transfer NSObject *)(p_obj); 当我们在C语言的结构中，需要使用OC的类型作为结构成员，除了将OC的类型转换为void *之外，我们可以使用__unsafe_unretained修饰符（这个修饰符会在后面介绍）。 12345678910/// 在C中使用OC的对象方式typedef struct rls_temp_ctx&#123; NSObject __unsafe_unretained *obj; void *target;&#125; rls_temp_context;/// 在C中传入OC对象rls_temp_context tmp_ctxs = &#123; .obj = [NSObject new], .target = (__bridge void *)(self)&#125;; 但是在使用obj时，由于__unsafe_unretained存在悬浮指针的问题，必须要判断该值是否存在。 OC内存管理前面看了C的内存管理，还看了C和OC的交互，最后就来看看在OC中内存管理应该注意的事项。 现在我们讨论OC的内存管理是基于ARC的，其中对象变量的创建和释放问题和C的内存管理有点儿相似。大多数情况下系统会帮我们进行内存管理，我们只需要明确自己所声明的对象或者变量存在于什么区域（上面提到的内存区域），给它们添加合适的修饰符等等。 大部分情况下，对于栈区、堆区、全局静态区的变量对象和C是相同的，我们可以类比来分析OC中对象或者变量的创建和释放时机。ARC中栈区用autoreleasepool管理的变量和C中的自动变量的内存管理时机很相似。 在OC中使用基于C的函数时，通过malloc等函数声明的变量，都需要我们明确地调用free函数进行释放！抑或在使用CoreFondation、Runtime时，基本上如果遇到了包含有Copy， Create等关键字函数，在使用完成之后都需要手动释放内存。2017-09-13更新：当我们使用Runtime时，运用下面的方法来动态创建一个对象时，被创建的对象不会被释放，但是对应的release方法又是MRC时代的。所以我们可以使用如下方法来解决：1234567/// 创建对象id obj = ((id(*)(id,SEL))objc_msgSend)(((id(*)(id,SEL))objc_msgSend)([self class],@selector(alloc)),@selector(init));........./// 释放对象((id(*)(id,SEL))objc_msgSend)(obj,NSSelectorFromString(@&quot;release&quot;)); 内存管理关键字下面来介绍一下，在Objective-C的ARC中所涉及到的关键字。 1、__strong为默认值，在声明成员变量和方法参数时也可以使用！ 1__strong id obj_var = [[NSObject alloc] init]; 作用：默认的行为。 2、__weak是不会持有对象实例，__weak修饰符可以避免循环引用 1234567__weak id obj2 = nil;&#123; __strong id obj_var = [[NSObject alloc] init];/// 自己生成对象并持有 obj2 = obj_var;/// obj2持有对象的弱引用 NSLog(@&quot;__weak %@&quot;,obj2);/// 此时由于在obj_var变量可用域中，obj2此时有值&#125;NSLog(@&quot;__weak %@&quot;,obj2);/// 由于不在obj_var作用域之外，obj_var被释放。而且obj2是弱引用于obj_var的，所以此时obj2值为空 作用：避免循环引用，不持有对象实例 3、__unsafe_unretained修饰符的变量不属于编译器的内存管理对象。它和__weak类似，不会持有对象实例； 12345678__unsafe_unretained id obj1 = nil;&#123;/// 在obj_var作用域内，__unsafe_unretained和__weak是一样的 __strong id obj_var = [[NSObject alloc] init]; obj1 = obj_var; NSLog(@&quot;__unsafe_unretained %@&quot;,obj1);&#125;NSLog(@&quot;__unsafe_unretained %@&quot;,obj1);/// 此时变量已经被遗弃，成为悬浮指针 在使用__unsafe_unretained修饰符时，赋值给strong修饰符的变量时，需要检查被赋值的对象是否存在（也就是被unsafe_unretained修饰的变量） 作用：在iOS4之前__weak的替代品，但是在将其赋值给其他时，最好做非空判断 4、__autoreleasing修饰符的变量替代调用MRC时代的autorelease方法，该对象会被注册到autoreleasepool中。以下是__autoreleasing修饰符的使用场景： 1）、在生成对象时，编译器会检查方法名是否是以alloc/new/copy/mutablcopy开始（自己生成自由持有）。如果不是自己生成的则自动将返回值注册到autoreleasepool中。2）、对象作为返回值时，编译器会自动将其注册到autoreleasing中。3）、在使用weak修饰符的变量时就必定要使用注册到autoreleasepool中的对象。4）、id的指针或者对象的指针(NSObject /NSError )在没有显示指定时会被附加上__autoreleasing修饰符__。 12NSError *error = nil;BOOL result = [self performOperationWithError:&amp;error]; 最后还是去看看这套题，它的解释对于理解内存的释放很有益处。对于这套题我已经推荐了几次了，哈哈哈。 相关引用 ARC]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从头认识GCD——相关函数的使用]]></title>
      <url>%2F2017%2F07%2F29%2Fgcd_func%2F</url>
      <content type="text"><![CDATA[在上一篇文章中，我们对GCD有了基本的认知，知道其中一些简单的类型，和一些简单函数。这本篇文章中，我们将继续学习GCD中我们在日常开发中使用较多的函数，及其使用方法。在本篇会介绍dispatch_after、dispatch_apply、dispatch_group_t、dispatch_semaphore_t和dispatch_barrier等相关函数。 dispatch_after／dispatch_time_t我先来说说dispatch_after，从某种意义上来说，它属于任务提交的一种方式。在刚刚接触iOS开发的时候，我一直在想“ 对于dispatch_after它是同步提交代码块还是异步提交的代码块的呢？ ”。后来看到Apple的文档中说到”This function waits until the specified time and then asynchronously adds block to the specified queue”，也就是说它的延迟执行，并不是马上就将代码块就提交到指定的队列中，而是等到指定的时间通过异步的方式将提其提交到指定的队列中去。因此从这段话中也可以看出它仅仅是dispatch_async的一种。该函数的声明如下： 1void dispatch_after(dispatch_time_t when, dispatch_queue_t queue, dispatch_block_t block); 到这里就需要来系统地说一说dispatch_after函数的第一个参数，一个dispatch_time_t类型的变量。dispatch_time_t实际是uint64_t类型。系统为该类型定义了两个特殊值，分别是DISPATCH_TIME_NOW、DISPATCH_TIME_FOREVER，其中DISPATCH_TIME_NOW表示值为0，而DISPATCH_TIME_FOREVER表示为无穷大（infinity）。除了这两个特殊值之外，我们可以使用函数dispatch_time()来创建相对于默认时钟的时间；或者使用dispatch_walltime()函数获取绝对时间。对于dispatch_time()函数，第一个参数我们传入DISPATCH_TIME_NOW或者DISPATCH_TIME_FOREVER值。 dispatch_time()函数第二个参数接受的是 基于纳秒级别的数值 。 这时候就需要将具体的数字乘以一个常数，在官方文档中列出了相关的常数。 常数 意义 具体数值 NSEC_PER_SEC 表示一秒能转换成多少纳秒 1000000000ull USEC_PER_SEC 表示一秒能转换成多少微秒 1000000ull NSEC_PER_USEC 表示一微秒转换成多少纳秒 1000ull 12345/// 使用相对时间，相对于现在延迟五秒dispatch_time_t time_t = dispatch_time(DISPATCH_TIME_NOW, 5 * NSEC_PER_SEC);dispatch_after(time_t, dispatch_get_main_queue(), ^&#123; NSLog(@&quot;Run&quot;);&#125;); 如果我们想要该代码块延迟到某一指定时刻去执行，我们只需要去修改dispatch_after中的dispatch_time_t类型中值，在这里我们使用函数dispatch_walltime来获取绝对的时间戳值。dispatch_walltime()函数的一个参数是struct timespec类型的一个变量，它是一个结构： 12345_STRUCT_TIMESPEC&#123; __darwin_time_t tv_sec; long tv_nsec;&#125;; 分别为秒和纳秒。timespec是基于纳秒级别的数值，关于dispatch_walltime具体是方式之一如下： 123456789/// 延迟到某一绝对时刻执行struct timespec __tp;double sec, n_sec;n_sec = modf(1500794750.797543543, &amp;sec);__tp.tv_sec = sec;__tp.tv_nsec = n_sec;dispatch_after(dispatch_walltime(&amp;__tp, 0), dispatch_get_main_queue(), ^&#123; ...&#125;); 上诉代码要等到时间戳为1500794750时才会将代码块提交到指定的事件队列中。 dispatch_applydispatch_apply是dispatch_sync函数配合不同的的dispatch_queue_t队列，来循环执行任务。 如果在dispatch_apply函数中传入的是一个并发队列，那么block中的任务就可以被并发的调用！相对于一般的for循环来说要高效许多。 12345dispatch_queue_t apply_queue = dispatch_queue_create(&quot;com.example.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, apply_queue, ^(size_t index) &#123; NSLog(@&quot;%zd&quot;,index);&#125;);NSLog(@&quot;End&quot;); 结果如下0, 2, 3, 1, 4, End。但是我们将上面的并发队列改成串行队列之后： 12345dispatch_queue_t apply_queue = dispatch_queue_create(&quot;com.example.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, apply_queue, ^(size_t index) &#123; NSLog(@&quot;%zd&quot;,index);&#125;);NSLog(@&quot;End&quot;); 返回的结果0, 1, 2, 3, 4, End和正常的for循环没有什么差距。但是不管是在并发的队列还是在串行的队列中，End总是最后才打印的。 dispatch_group_t相关函数使用dispatch_group可以把许多操作进行合并。在将多个任务block提交之后，我们可以在dispatch_group中获取到这些操作全部完成的时间（不管是串行执行还是并行执行）。现在我们有一个场景：第一步，我们需要将多个本地资源传递给服务器。我们用dispatch_group相关的技术来实现这个需求。创建一个dispatch_group_t类型的变量实现非常简单，不像其他GCD函数需要一些其他的参数： 1dispatch_group_t upload_group = dispatch_group_create(); 当创建好了dispatch_group之后，我们需要将这些任务进行提交，这里我使用上一节的dispatch_apply来将多个任务放在并发的队列中： 1234567dispatch_queue_t upload_queue = dispatch_queue_create(&quot;com.example.upload.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, dispatch_get_global_queue(QOS_CLASS_UTILITY, 0), ^(size_t index) &#123; dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2 * NSEC_PER_SEC)), upload_queue, ^&#123; /// 模拟网络请求 NSLog(@&quot;Upload %zd&quot;,index); &#125;);&#125;); 在大部分的应用中的上传请求，都有一个上传完成的标志。第二步，那么在这个场景中我们如何知道所有图片已经上传成功呢？我们使用同步的方式，用户的交互不起作用，静静地等待上传完成： 1234567891011dispatch_group_t upload_group = dispatch_group_create();dispatch_queue_t upload_queue = dispatch_queue_create(&quot;com.example.upload.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, dispatch_get_global_queue(QOS_CLASS_UTILITY, 0), ^(size_t index) &#123; dispatch_group_enter(upload_group); dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2 * NSEC_PER_SEC)), upload_queue, ^&#123;/// 模拟网络请求 NSLog(@&quot;Upload %zd&quot;,index); dispatch_group_leave(upload_group); &#125;);&#125;);dispatch_group_wait(upload_group, DISPATCH_TIME_FOREVER);NSLog(@&quot;Upload Complete&quot;); dispatch_group的管理是基于计数来做的。dispatch_group_enter会增加该Group内部的任务计数，dispatch_group_leave会减少该Group中未完成的计数，它们两个函数必须配对使用。dispatch_group_wait函数和我们在上一篇文中讲到的dispatch_block_wait函数功能类似，只不过dispatch_group_wait是针对多个block的同步方法，它会等到Group中所有的任务执行完毕之后才会去继续执行后面的内容。 既然上面提到了dispatch_group_wait函数对应dispatch_block_wait函数，那么很明显应该存在dispatch_block_notify函数对应的Group函数。我们将上面的函数进行稍加改动，将同步的方式改为异步的方式，让用户能够做其他的操作： 123456789101112dispatch_group_t upload_group = dispatch_group_create();dispatch_queue_t upload_queue = dispatch_queue_create(&quot;com.example.upload.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, dispatch_get_global_queue(QOS_CLASS_UTILITY, 0), ^(size_t index) &#123; dispatch_group_enter(upload_group); dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2 * NSEC_PER_SEC)), upload_queue, ^&#123;/// 模拟网络请求 NSLog(@&quot;Upload %zd&quot;,index); dispatch_group_leave(upload_group); &#125;);&#125;);dispatch_group_notify(upload_group, dispatch_get_main_queue(), ^&#123; NSLog(@&quot;Upload Complete&quot;);&#125;); 其实相对于使用繁琐的dispatch_group_enter、dispatch_group_leave，Apple给我们提供了更为简单的函数dispatch_group_async。我这样做的目的是为了在一开始就能让我们清楚，在Group内部是什么在决定着dispatch_group_wait 、dispatch_group_notify的触发时机，我们还是对上面的例子进行稍加修改： 12345678910dispatch_group_t upload_group = dispatch_group_create();dispatch_queue_t upload_queue = dispatch_queue_create(&quot;com.example.upload.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_apply(5, dispatch_get_global_queue(QOS_CLASS_UTILITY, 0), ^(size_t index) &#123; dispatch_group_async(upload_group, upload_queue, ^&#123; NSLog(@&quot;Upload %zd&quot;,index); &#125;);&#125;);dispatch_group_notify(upload_group, dispatch_get_main_queue(), ^&#123; NSLog(@&quot;Upload Complete&quot;);&#125;); 很明显对于使用dispatch_group_async给我们带来便利的同时，在灵活性上也就出现缺失，再者就是在用Group做同步的时候使用dispatch_group_enter、dispatch_group_leave是更好的选择！ dispatch_semaphore_t相关函数在系统中，给予每一个进程一个信号量，代表每个进程目前的状态，未得到控制权的进程会在特定地方被强迫停下来，等待可以继续进行的信号到来（来自维基百科）。通俗一点儿讲就是说在进程内部有一原子递增和递减的计数器（也就是该数据变量具有原子性）。如果触发了某个操作使得信号量小于等于0，那么该操作将会被阻塞，直到其信号量大于0。上面提到过，信号量是基于进程的。所以： 信号量不依赖于任何队列，它可以在任何线程中使用。 在GCD中，函数dispatch_semaphore_signal增加信号量计数，如果之前信号量计数小于等于0，该函数会唤醒当前正在等待的线程。相反，函数dispatch_semaphore_wait会减少信号量计数，如果当该信号量计数小于或者等于0之后，会阻塞当前线程，等待其他操作来增加信号量计数。 123456789101112131415161718192021- (NSArray *)downloadSync&#123; NSMutableArray *contents = [NSMutableArray array]; dispatch_semaphore_t semaphore = dispatch_semaphore_create(0); dispatch_group_t upload_group = dispatch_group_create(); dispatch_queue_t upload_queue = dispatch_queue_create(&quot;com.example.download.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0)); dispatch_apply(5, dispatch_get_global_queue(QOS_CLASS_UTILITY, 0), ^(size_t index) &#123; dispatch_group_enter(upload_group); dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(2 * NSEC_PER_SEC)), upload_queue, ^&#123; NSString *cts = [NSString stringWithFormat:@&quot;%zd&quot;,index]; NSLog(@&quot;~ %@ ~&quot;,cts); [contents addObject:cts]; dispatch_group_leave(upload_group); &#125;); &#125;); dispatch_group_notify(upload_group, dispatch_get_main_queue(), ^&#123; dispatch_semaphore_signal(semaphore); &#125;); dispatch_semaphore_wait(semaphore, DISPATCH_TIME_FOREVER); return contents;&#125; 我们现在来看看上面这个方法可以正常的返回吗？除了dispatch_semaphore_t相关的代码，我都是直接从上面拷贝下来，没有做任何修改。当我跑起来之后，始终方法downloadSync不会返回，这里很明显的是造成了死锁的问题！由于dispatch_semaphore_wait函数会阻塞当前线程（它此时是处于主线程中），dispatch_group_notify函数的任务线程即为主线程对应的主任务队列。dispatch_semaphore_wait需要等到函数dispatch_semaphore_signal来增加信号量计数之后才会继续执行主线程，而dispatch_group_notify又要在主线程中执行（由于主线程被阻塞）之后才能去调用dispatch_semaphore_signal函数，因此就造成了死锁，程序永远不会继续执行！。解决办法也很简单，将dispatch_semaphore_signal放在一个并行的任务队列中进行： 123dispatch_group_notify(upload_group, dispatch_get_global_queue(QOS_CLASS_USER_INITIATED, 0), ^&#123; dispatch_semaphore_signal(semaphore);&#125;); 上面使用信号量的相关函数，实现了异步转同步的需求。 dispatch_barrierdispatch_barrier的作用是在并发队列中实现同步操作。在并发队列中，任务的提交顺序会影响到执行顺序，当异步提交的任务在dispatch_barrier之后，该任务需要等到dispatch_barrier提交的任务执行完成之后才会开始执行。把上面的话用下面的图通俗的来解释一下： 用下面的伪代码来实现一下上图中的相关任务： 12345dispatch_async(task_queue, task_1);dispatch_async(task_queue, task_2);dispatch_async(task_queue, task_3);dispatch_barrier_async(task_queue, task_4);dispatch_async(task_queue, task_5); 函数dispatch_barrier_async中block参数，会被目标队列复制并持有，直到任务完成时被释放。官方文档中提到： 目标队列必须是用户手动创建的并发队列，如果传入的是串行队列或者是全局并发队列，那么这个函数就和dispatch_async类似。 dispatch_barrier_sync在做同步操作时和dispatch_barrier_async效果类似，但是它必须得等到block任务完成之后才会返回！而且dispatch_barrier_sync函数的目标线程不会复制和持有block。 dispatch_once在这篇文章的最后以dispatch_once来做一个结尾，对于dispatch_once我们iOS开发者用的太多了。该函数在多线程环境下同样也是安全的，如果是在多线程中进行调用，它会同步地等待block任务执行完成！官方文档中提出：对于dispatch_once函数的 第一个参数必须是存储在全局区或者静态区的变量 1234static dispatch_once_t predicate;dispatch_once(&amp;predicate, ^&#123; ... &#125;); 关于dispatch_once更多的文章见dispatch_once，以及对应的源码once.c。第三篇文章会在后面放出来，我准备写关于dispatch_source和dispatch_data以及dispatch_io等相关知识。 相关链接根据文中出现顺序 Apple Dispatch Github Dispatch Time Multiplier Constants Elapsed Time 信号量]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从头认识GCD——派发队列基础]]></title>
      <url>%2F2017%2F07%2F29%2Fgcd_basic%2F</url>
      <content type="text"><![CDATA[本文包括了从最基础的获取任务队列开始，配置任务队列，创建任务，提交任务一步一步地来复习GCD中所涉及到的知识。（建议在PC端浏览） 包括使用较少的dispatch_qos_class_t 、dispatch_block_t等等知识点。 GCD任务队列能够让开发者能够更加专注于同步或者异步任务task，而不用把重点放在创建线程和具体同步和加锁等相关操作。但是如果我们想异步做更加灵活的任务的话（比如后台任务之类的），那选择线程肯定是更好的选择。毕竟操作简单带来就是灵活性的确实嘛！首先先来看看派发队列。 当用户向某一线程提交一个task时，_dispatch_queuet作为任务队列以用户期望的方式来管理这些task。 管理的任务的方式有两种类型，分别是串行队列(DISPATCH_QUEUE_SERIAL)和并行队列(DISPATCH_QUEUE_CONCURRENT)，它们两个是由宏定义的。 一、获取任务队列现在问题来了，我们既然知道有这么一个类型了，那我们总要有方式来得到它啊是吧。就目前而言，Apple给我们提供获取该类型变量的方式有三种，分别是： dispatch_get_main_queue：程序主线程的任务队列，这是一个串行队列（DISPATCH_QUEUE_SERIAL）。在程序main()函数被调用之前由系统自动创建。在官方文档中还提到了，我们可以主动去执行被添加到main_queue的任务task（也就是说我们可以主动来调用添加到主线程队列的block）。三个方法分别是：dispatch_main()、UIApplicationMain 、CFRunLoopRun()，选用其中一个。我尝试了一下使用dispatch_main()会导致程序中断。 dispatch_get_global_queue：由系统定义并管理的一个全局并行队列。在获取时，我们需要指定任务队列的系统等级（DISPATCH_QUEUE_PRIORITY_HIGH、DISPATCH_QUEUE_PRIORITY_DEFAULT、DISPATCH_QUEUE_PRIORITY_LOW、DISPATCH_QUEUE_PRIORITY_BACKGROUND）。 1dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); 但是在iOS8以后，使用枚举qos_class_t的值，提供了细粒度更高的全局任务队列，关于QOS在后面统一梳理一下。 1dispatch_get_global_queue(QOS_CLASS_UTILITY, 0); 该函数的返回值上使用dispatch_resume、dispatch_suspend无效， dispatch_queue_create：除了上诉系统提供的两种类型的任务队列之外，我们还可以自己去创建任务队列。我们可以自己创建串行（DISPATCH_QUEUE_SERIAL）和并行（DISPATCH_QUEUE_CONCURRENT）两种类型的队列，但是它们都有一个变种DISPATCH_QUEUE_SERIAL_INACTIVE, DISPATCH_QUEUE_CONCURRENT_INACTIVE。它们同样会有涉及到QOS的创建方法，后面一起记录一下 1dispatch_queue_create(&quot;com.example.gcd&quot;, DISPATCH_QUEUE_CONCURRENT); 上诉三种就是获得任务队列方法，我们在设置dispatch_ge_global_queue的第二个参数时一般设置为0。上面这三种方式是我们在日常开发中，使用并发编程时通过GCD的方式来获取任务队列的方法。在大部分时间使用并行的任务队列时，global_queue能够基本满足需求；对于我来说创建线程的场景，主要是当我们需要一个串行的任务，但是又不想在主线程去执行时使用。既然我在上面提到了QOS，下面我们就系统的来认识一下QOS。 二、通过QOS配置队列 由于在我们的程序中，存在各种各样的场景，比如用户界面刷新，网络请求，资源下载，缓存存取之类的。为了能够保证程序的高效响应，需要对不同的任务对资源的消耗做出一些调整。此时我们就可以使用QOS来解决不同任务的资源分配问题，QOS可以用于dispatch_queue, NSOperation, NSOperationQueue, NSThread ,pthreads中，这篇文章中主要讲一下在dispatch_queue中的使用场景。 在官方文档中也说，关于QOS的只能在iOS8以后使用 QOS_CLASS 执行时机 相关使用场景 USER_INTERACTIVE 必须是要及时处理 等级最高。主要用户用户交互，比如主线程上的刷新用户界面等等。 USER_INITIATED 需要很快完成工作 它主要用于比如已经开了一个任务，此时需要立刻执行的场景。意思就是说需要瞬间完成的工作 ❌ DEFAULT —— 这个我们一般不使用，dispatch_get_global_queue就是这一等级。 UTILITY 可能需要相当长一段时间 不需要及时响应，比如下载操作之类的，但是用户是可以看见进度之类的 BACKGROUND 长时间类型任务 完全是后台执行，用户不知道进度的 ❌ UNSPECIFIED —— 开发人员没有指定，系统根据情况进行选定QOS等级 上诉QOS对应OC参数如下： QOS-Class 对应OC USER_INTERACTIVE NSQualityOfServiceUserInteractive USER_INITIATED NSQualityOfServiceUserInitiated UTILITY NSQualityOfServiceUtility BACKGROUND NSQualityOfServiceBackground 在dispatch_queue中，如果我们想要指定QOS的等级的话，我们可以使用函数dispatch_queue_attr_make_with_qos_class。在创建任务队列时使用方法如下： 12dispatch_queue_attr_t attr_qos = dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INTERACTIVE, 0);dispatch_queue_t queue = dispatch_queue_create(&quot;com.example.gcd&quot;, attr_qos); 因为 QOS对于dispatch_queue来说是无法变更的属性，以致于我们无法去更改已存在任务队列的QOS属性。但是我们可以使用dispatch_queue_get_qos_class函数来获取任务队列的QOS： 123456dispatch_qos_class_t qos_class = dispatch_queue_get_qos_class(the_queue, 0);/// 一般用于 根据已知队列来获取同qos等级的全局任务队列dispatch_get_global_queue(dispatch_queue_get_qos_class(the_queue, nil), 0);/// 或者是 根据已知的全局任务队列来创建与其qos相等的任务队列dispatch_queue_t the_global = dispatch_get_global_queue(QOS_CLASS_UTILITY, 0);dispatch_queue_t the_queue = dispatch_queue_create(&quot;com.example.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, dispatch_queue_get_qos_class(the_global, 0), 0)); 当我们要获取全局队列时，在此之前可以使用DISPATCH_QUEUE_PRIORITY_HIGH、DISPATCH_QUEUE_PRIORITY_DEFAULT、DISPATCH_QUEUE_PRIORITY_LOW、DISPATCH_QUEUE_PRIORITY_BACKGROUND。现在我们可以使用QOS来获取一个全局的并发任务队列，因此我们有必要来了解一下它们之间的差异和共性： 以前 现在QOS Main Thread QOS_CLASS_USER_INTERACTIVE DISPATCH_QUEUE_PRIORITY_HIGH QOS_CLASS_USER_INITIATED DISPATCH_QUEUE_PRIORITY_DEFAULT QOS_CLASS_DEFAULT DISPATCH_QUEUE_PRIORITY_LOW QOS_CLASS_UTILITY DISPATCH_QUEUE_PRIORITY_BACKGROUND QOS_CLASS_BACKGROUND 具体使用方法如下： 1dispatch_get_global_queue(QOS_CLASS_USER_INTERACTIVE, 0); 除此之外，我们还可以在dispatch_block中对每一个人任务块来设置Qos等级，这里我先将dispatch_block提出来，后面我会对其进行较为详细的解释。 1234dispatch_block_t the_block = dispatch_block_create_with_qos_class(0, QOS_CLASS_UTILITY, -8, ^&#123; ...&#125;);dispatch_async(the_queue, the_block);///dispatch_sync, dispatch_after等等需要用到dispatch_block的地方 三、创建任务 前面两点说了任务的执行地点和怎样来创建和配置任务的执行地点，但是我们必须得知道任务是什么？怎么创建任务？在GCD中使用block来作为任务提交给特定的任务队列，例如_dispatch_blockt或者直接是一个简单的block。对于dispatch_block_t类型的变量，首先我们得要知道怎么去创建它。首先根据我们的尝试（下面的例子出自Apple官方），对block进行直接赋值： 123456789101112dispatch_block_t error_block;NSInteger x = 0;if (x) &#123; error_block = ^void(void)&#123; NSLog(@&quot;TRUE&quot;); &#125;;&#125;else&#123; error_block = ^void(void)&#123; NSLog(@&quot;FALSE&quot;); &#125;;&#125;error_block();/// unsafe 官网中解释到：“ 由于该dispatch_block_t变量是在栈内存上声明的，如果执行过该变量作用域之后就有可能导致该变量被释放 ”。到这里我们还是不得不提一下block在MRC和ARC下的区别，我们先看一篇测试，在这篇测试中很明显的一个点便是：“ MRC中有NSStackBlock类型，NSMallocBlock类型，NSGlobalBlock类型同时存在。但是在ARC中不再存在NSStackBlock类型，而是直接声明为NSMallocBlock类型” 。也就是说在ARC中就算是在函数方法中声明的block变量也是被声明为NSMallocBlock类型。 NSMallocBlock类型就不存在上诉官网中提到的变量被提前释放的问题，这一步我并没有去实践，所以上诉结论是否为真，既然官方不建议这么做，那便放弃使用该方法。使用一下两种方式来创建dispatch_block_t变量： dispatch_block_create dispatch_block_create_with_qos_class 当我们在使用上诉两种方法来创建dispatch_block_t变量时，遇到的第一个便是dispatch_block_flags_t参数。它是一个枚举类型： 枚举类型 作用 DISPATCH_BLOCK_ASSIGN_CURRENT 说明该块会被分配在创建该对象的上下文中（直接执行该块对象时推荐使用） DISPATCH_BLOCK_BARRIER 类似于在做同步操作时的barrier DISPATCH_BLOCK_DETACHED 表明dispatch_block与当前的执行环境属性无关 DISPATCH_BLOCK_ENFORCE_QOS_CLASS 当dispatch_block提交到队列或者直接提交执行做同步操作时，该值是默认值 DISPATCH_BLOCK_INHERIT_QOS_CLASS 异步执行的默认值，优先级低于DISPATCH_BLOCK_ENFORCE_QOS_CLASS。可以用该值来覆盖原来QOS类 DISPATCH_BLOCK_NO_QOS_CLASS 表明dispatch_block不分配QOS类 来创建dispatch_block变量： 12345678/// 第一种使用QOS的方式来创建dispatch_blockdispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;RUN&quot;);&#125;);/// 直接创建dispatch_blockdispatch_block_create(DISPATCH_BLOCK_NO_QOS_CLASS, ^&#123; ...&#125;); 对于dispatch_block_create_with_qos_class方法中relative_priority的参数的规则是：relative_priority的值需要在0到QOS_MIN_RELATIVE_PRIORITY（-15）之间。 我们创建的block会被拷贝到堆上，并由dispatch_block_t类型的变量所持有。创建完成之后，我们可以将其提交到对应的任务队列中（下一节提到的dispatch_async等等函数…），也可以直接去执行（比如：task_block()）。 既然可以直接去输入一个block块，那为什么我们还需要去使用dispatch_block_t？存在即有价值，那么最明显的优势便是：我们可以对该任务块执行取消操作！例如： 12345dispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;RUN&quot;);&#125;);dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(0.5 * NSEC_PER_SEC)), dispatch_get_main_queue(), task_block);dispatch_block_cancel(task_block); 但是如果dispatch_block已经开始执行，便无法取消该任务的执行。比如下面的例子中，我们对上面的代码进行一点小小的修改： 1234567891011dispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;RUN&quot;);/// 成功执行 /// 模拟一个长时间的耗时任务 [NSThread sleepForTimeInterval:3]; NSLog(@&quot;End&quot;);/// 成功执行&#125;);dispatch_async(dispatch_get_main_queue(), task_block);dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(1 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^&#123; /// 保证dispatch_block_t已经开始执行 dispatch_block_cancel(task_block);&#125;); 在这里我们是无法去取消已经执行的块。dispatch_block_testcancel函数的作用是让我们能够知道当前任务块是否已经被取消。 在调用dispatch_block_cancel函数时，我们必须要确定即将被cancle的块没有捕获任何其他外部变量，如果持有将会造成内存泄漏。 除此之外我们来认识一下dispatch_block_wait 函数，它的作用是以同步的方式执行并等待，得等待指定的任务块执行完成之后，抑或者是超时之后然后去执行当前线程的后续任务。如下： 123456789dispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;Start&quot;); [NSThread sleepForTimeInterval:3]; NSLog(@&quot;End&quot;);&#125;);dispatch_async(dispatch_get_main_queue(), task_block);NSLog(@&quot;Before Wait&quot;);dispatch_block_wait(task_block, DISPATCH_TIME_FOREVER);NSLog(@&quot;After Wait&quot;); 此时运行并不会得到Start。由于dispatch_block_wait函数是使用的同步的方式，只要是在该线程的执行流中，它不管你是同步提交还是异步提交（这两种提交方式在下面一节马上会讲）的方式，dispatch_block_wait函数如果是在被执行的block之前执行，后续的代码都会被挂起，并不仅仅是dispatch_block_wait函数后的代码，也包括block中的代码。因此也就导致了在同一个任务队列中（都处于main_queue中）的dispatch_block_t永远不会执行。解决办法也很简单，第一种我们先让block执行起来；第二种我们让它们处在不同队列中即可： 12345678910dispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;Start&quot;); [NSThread sleepForTimeInterval:3]; NSLog(@&quot;End&quot;);&#125;);dispatch_queue_t block_queue = dispatch_queue_create(&quot;com.example.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_async(block_queue, task_block);NSLog(@&quot;Before Wait&quot;);dispatch_block_wait(task_block, DISPATCH_TIME_FOREVER);NSLog(@&quot;After Wait&quot;); 我们可以利用这个方法来做由异步转同步的需求（后面还会介绍dispatch_semaphore_t，它同样可以达到这个效果）。 最后来看一下函数_dispatch_blocknotify，它的作用是当指定的dispatch_block_t变量执行完了之后，通知到给特定的任务队列。在上面的例子中，我们在block_queue中去执行了我们的任务块，但是我们想要在它执行完了以后在main_queue中来执行相关的操作，比如我们需要在main_queue中更新UI界面之类的： 12345678910dispatch_block_t task_block = dispatch_block_create_with_qos_class(DISPATCH_BLOCK_INHERIT_QOS_CLASS, QOS_CLASS_USER_INITIATED, -8, ^&#123; NSLog(@&quot;Start&quot;); [NSThread sleepForTimeInterval:3]; NSLog(@&quot;End&quot;);&#125;);dispatch_queue_t block_queue = dispatch_queue_create(&quot;com.example.gcd&quot;, dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_CONCURRENT, QOS_CLASS_USER_INITIATED, 0));dispatch_async(block_queue, task_block);dispatch_block_notify(task_block, dispatch_get_main_queue(), ^&#123; NSLog(@&quot;Notify&quot;);&#125;); 四、将任务提交到队列 在文章的最后，我们来看看怎样把已经创建好的任务提交到特定的任务队列中去！对于提交操作主要涉及到的函数有：dispatch_async、dispatch_sync、dispatch_block_perform、dispatch_group_async、dispatch_barrier_async、dispatch_barrier_sync。在这篇文章中先讲前面三个。再后面文章中详解dispatch_group_t、dispatch_barrier时在进行对应的学习。 dispatch_async使用异步地方式去提交任务块，何为异步？异步方法调用它通过使用一种立即返回的异步的变体并提供额外的方法来支持接受完成通知以及完成等待改进长期运行的(同步)方法（出自维基百科）。dispatch_sync使用同步的方式取提交任务块。下图是根据我自己的理解来解释了一下异步和同步的差异性。 上诉函数分别有对应的版本，分别是dispatch_async_f、dispatch_sync_f。它们两个和前面的区别在于，这两个函数不使用block的方式，而是使用C函数指针的方式来执行任务。它们中的context是以void *类型的变量作为参数，传递给函数指针指向的具体函数。 123456789101112131415161718/// 异步使用blockdispatch_async(queue, ^&#123; ...&#125;);/// 同步使用blockdispatch_sync(queue, ^&#123; ...&#125;);/// 异步使用函数指针dispatch_async_f(dispatch_get_main_queue(), (__bridge void * _Nullable)(self), task_place);void task_place(void *data)&#123; ...&#125;/// 同步使用函数指针dispatch_sync_f(block_queue, (__bridge void * _Nullable)(self), task_place);void task_place(void *data)&#123; ...&#125; 最后我们来看看本应属于dispatch_block_t中应该讲解的函数dispatch_block_perform，但是它作为一个提交任务的函数，放在这里讲我觉得要更为合适一点。它会创建一个dispatch_block_t变量，并在该任务队列中以同步的方式来执行block中的内容。 12345dispatch_block_perform(DISPATCH_BLOCK_BARRIER, ^&#123; NSLog(@&quot;Start&quot;); [NSThread sleepForTimeInterval:3]; NSLog(@&quot;End&quot;);&#125;); 上面的代码以下代码效果一样（取自Apple官方文档）: 123dispatch_block_t b = dispatch_block_create(flags, block);b();Block_release(b); 但是dispatch_block_perform方法可以以更加高效的方式来进行以上步骤，而不需要在对象分配时将block拷贝到指定堆中。 到这里把最基础的部分算是走了一遍，可以说是走了最小的一步，但是本文的目的是力求以清晰地路线把每一步所涉及到的知识深挖严查。在后续的文章中会继续介绍GCD中的其他函数和相关的使用方法。 相关链接以文章中出现顺序： Prioritize Work with Quality of Service Classes Concurrency Programming Guide Objective-C Blocks Quiz Transitioning to ARC Release Notes 异步调用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[最大堆（创建、删除、插入和堆排序）]]></title>
      <url>%2F2017%2F05%2F09%2Fdata_struct_max_heap%2F</url>
      <content type="text"><![CDATA[什么是最大堆和最小堆？最大（小）堆是指在树中，存在一个结点而且该结点有儿子结点，该结点的data域值都不小于（大于）其儿子结点的data域值，并且它是一个完全二叉树（不是满二叉树）。 注意区分选择树，因为选择树（selection tree）概念和最小堆有些类似，他们都有一个特点是“树中的根结点都表示树中的最小元素结点”。同理最大堆的根结点是树中元素最大的。那么来看具体的看一下它长什么样？（最小堆这里省略） 这里需要注意的是：在多个子树中，并不是说其中一个子树的父结点一定大于另一个子树的儿子结点。最大堆是树结构，而且一定要是完全二叉树。 最大堆ADT那么我们在做最大堆的抽象数据类型（ADT）时就需要考虑三个操作：（1）、创建一个最大堆；（2）、最大堆的插入操作；（3）、最大堆的删除操作；最大堆ADT如下： 123456789struct Max_Heap &#123; object: 由多个元素组成的完全二叉树，其每个结点都不小于该结点的子结点关键字值 functions: 其中heap∈Max_Heap,n,max_size∈int,Element为堆中的元素类型，item∈ Element Max_Heap createHeap(max_size) := 创建一个总容量不大于max_size的空堆 void max_heap_insert(heap, item ,n) := 插入一个元素到heap中 Element max_heap_delete(heap,n) := if(heap不为空) &#123;return 被删除的元素 &#125;else&#123;return NULL&#125;&#125;///其中:=符号组读作“定义为” 最大堆内存表现形式 我们只是简单的定义了最大堆的ADT，为了能够用代码实现它就必须要考虑最大堆的内存表现形式。从最大堆的定义中，我们知道不管是对最大堆做插入还是删除操作，我们必须要保证插入或者删除完成之后，该二叉树仍然是一个完全二叉树。基于此，我们就必须要去操作某一个结点的父结点。 第一种方式，我们使用链表的方式来实现，那么我们需要添加一个额外的指针来指向该结点的父结点。此时就包括了左子结点指针、右子结点指针和父结点指针，那么空链的数目有可能是很大的，比如叶子结点的左右子结点指针和根结点的父结点指针，所以不选择这种实现方式（关于用链表实现一般二叉树时处理左右子结点指针的问题在线索二叉树中有提及）。 第二种方式，使用数组实现，在二叉树进行遍历的方法分为：先序遍历、中序遍历、后序遍历和层序遍历。我们可以通过层序遍历的方式将二叉树结点存储在数组中，由于最大堆是完全二叉树不会存在数组的空间浪费。那么来看看层序遍历是怎么做的？对下图的最大堆进行层序遍历：从这里可以看出最后得到的顺序和上面图中所标的顺序是一样的。 那么对于数组我们怎么操作父结点和左右子结点呢？对于完全二叉树采用顺序存储表示，那么对于任意一个下标为i(1 ≤ i ≤ n)的结点：（1）、父结点为：i / 2（i ≠ 1），若i = 1，则i是根节点。（2）、左子结点：2i（2i ≤ n）， 若不满足则无左子结点。（3）、右子结点：2i + 1(2i + 1 ≤ n)，若不满足则无右子结点。 最终我们选择数组作为最大堆的内存表现形式。 基本定义: 1234567#define MAX_ELEMENTS 20#define HEAP_FULL(n) (MAX_ELEMENTS - 1 == n)#define HEAP_EMPTY(n) (!n)typedef struct &#123; int key;&#125;element;element heap[MAX_ELEMENTS]; 下面来看看最大堆的插入、删除和创建这三个最基本的操作。 最大堆的插入最大堆的插入操作可以简单看成是“结点上浮”。当我们在向最大堆中插入一个结点我们必须满足完全二叉树的标准，那么被插入结点的位置的是固定的。而且要满足父结点关键字值不小于子结点关键字值，那么我们就需要去移动父结点和子结点的相互位置关系。具体的位置变化，可以看看下面我画的一个简单的图。 12345678910void insert_max_heap(element item ,int *n)&#123; if(HEAP_FULL(*n))&#123; return; &#125; int i = ++(*n); for(;(i != 1) &amp;&amp; (item.key &gt; heap[i/2].key);i = i / 2)&#123;/// i ≠ 1是因为数组的第一个元素并没有保存堆结点 heap[i] = heap[i/2];/// 这里其实和递归操作类似，就是去找父结点 &#125; heap[i] = item;&#125; 由于堆是一棵完全二叉树，存在n个元素，那么他的高度为:log2(n+1)，这就说明代码中的for循环会执行O(log2(n))次。因此插入函数的时间复杂度为：O(log2(n))。 最大堆的删除最大堆的删除操作，总是从堆的根结点删除元素。同样根元素被删除之后为了能够保证该树还是一个完全二叉树，我们需要来移动完全二叉树的最后一个结点，让其继续符合完全二叉树的定义，从这里可以看作是最大堆最后一个结点的下沉操作。例如在下面的最大堆中执行删除操作： 1234567解答：1）、对于最大堆的删除，我们不能自己进行选择删除某一个结点，我们只能删除堆的根结点。因此在图a中，我们删除根结点20；2）、当删除根结点20之后明显不是一个完全二叉树，更确切地说被分成了两棵树。3）、我们需要移动子树的某一个结点来充当该树的根节点，那么在(15,2,14,10,1)这些结点中移动哪一个呢？显然是移动结点1，如果移动了其他结点（比如14，10）就不再是一个完全二叉树了。4）、此时在结点（15，2）中选择较大的一个和1做比较，即15 &gt; 1的，所以15上浮到之前的20的结点处。5）、同第4步类似，找出（14，10）之间较大的和1做比较，即14&gt;1的，所以14上浮到原来15所处的结点。6）、因为原来14的结点是叶子结点，所以将1放在原来14所处的结点处。 这图中是用temp分别和图中的max做比较，来看temp是否会下沉 12345678910111213141516171819element delete_max_heap(int *n)&#123; int parent, child; element temp, item; temp = heap[(*n)--]; item = heap[1]; parent = 1,child=2; for(;child &lt;= *n; child = child * 2)&#123; if( (child &lt; *n) &amp;&amp; heap[child].key &lt; heap[child+1].key)&#123;/// 这一步是为了看当前结点是左子结点大还是右子结点大，然后选择较大的那个子结点 child++; &#125; if(temp.key &gt;= heap[child].key)&#123; break; &#125; heap[parent] = heap[child];///这就是上图中第二步和第三步中黄色部分操作 parent = child;/// 这其实就是一个递归操作，让parent指向当前子树的根结点 &#125; heap[parent] = temp; return item;&#125; 同最大堆的插入操作类似，同样包含n个元素的最大堆，其高度为:log2(n+1)，其时间复杂度为：O(log2(n))。 总结：由此可以看出，在已经确定的最大堆中做删除操作，被删除的元素是固定的，需要被移动的结点也是固定的，这里我说的被移动的元素是指最初的移动，即最大堆的最后一个元素。移动方式为从最大的结点开始比较。 最大堆的创建为什么要把最大堆的创建放在最后来讲？因为在堆的创建过程中，有两个方法。会分别用到最大堆的插入和最大堆的删除原理。创建最大堆有两种方法：（1）、先创建一个空堆，然后根据元素一个一个去插入结点。由于插入操作的时间复杂度为O(log2(n))，那么n个元素插入进去，总的时间复杂度为O(n * log2(n))。（2）、将这n个元素先顺序放入一个二叉树中形成一个完全二叉树，然后来调整各个结点的位置来满足最大堆的特性。现在我们就来试一试第二种方法来创建一个最大堆：假如我们有12个元素分别为： 1&#123;79,66,43,83,30,87,38,55,91,72,49,9&#125; 将上诉15个数字放入一个二叉树中，确切地说是放入一个完全二叉树中，如下：但是这明显不符合最大堆的定义，所以我们需要让该完全二叉树转换成最大堆！怎么转换成一个最大堆呢？ 最大堆有一个特点就是其各个子树都是一个最大堆，那么我们就可以从把最小子树转换成一个最大堆，然后依次转换它的父节点对应的子树，直到最后的根节点所在的整个完全二叉树变成最大堆。那么从哪一个子树开始调整？ 我们从该完全二叉树中的最后一个非叶子节点为根节点的子树进行调整，然后依次去找倒数第二个倒数第三个非叶子节点… 具体步骤在做最大堆的创建具体步骤中，我们会用到最大堆删除操作中结点位置互换的原理，即关键字值较小的结点会做下沉操作。 1）、就如同上面所说找到二叉树中倒数第一个非叶子结点87，然后看以该非叶子结点为根结点的子树。查看该子树是否满足最大堆要求，很明显目前该子树满足最大堆，所以我们不需要移动结点。该子树最大移动次数为1。 2）、现在来到结点30，明显该子树不满足最大堆。在该结点的子结点较大的为72，所以结点72和结点30进行位置互换。该子树最大移动次数为1。 3）、同样对结点83做类似的操作。该子树最大移动次数为1。 4）、现在来到结点43，该结点的子结点有{87,38,9}，对该子树做同样操作。由于结点43可能是其子树结点中最小的，所以该子树最大移动次数为2。 5）、结点66同样操作，该子树最大移动次数为2。 6）、最后来到根结点79，该二叉树最高深度为4，所以该子树最大移动次数为3。 自此通过上诉步骤创建的最大堆为: 所以从上面可以看出，该二叉树总的需要移动结点次数最大为：10。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void create_max_heap(void)&#123; int total = (*heap).key; /// 求倒数第一个非叶子结点 int child = 2,parent = 1; for (int node = total/2;node &gt; 0; node--) &#123; parent = node; child = 2*node; int max_node = 2*parent+1; element temp = *(heap + parent); for(;child &lt;= max_node &amp;&amp; max_node &lt;= total; child = child * 2,max_node = 2*parent+1)&#123; if ((*(heap + child)).key &lt; (*(heap + child + 1)).key) &#123;/// 取右子结点 child++; &#125; if (temp.key &gt; (*(heap + child)).key) &#123; break; &#125; *(heap + parent) = *(heap + child); parent = child; &#125; *(heap + parent) = temp; &#125;&#125;/** * * @param heap 最大堆； * @param items 输入的数据源 * @return 1成功，0失败 */int create_binary_tree(element *heap,int items[MAX_ELEMENTS])&#123; int total; if (!items) &#123; return 0; &#125; element *temp = heap; heap++; for (total = 1; *items;total++,(heap)++,items = items + 1) &#123; element ele = &#123;*items&#125;; element temp_key = &#123;total&#125;; *temp = temp_key; *heap = ele; &#125; return 1;&#125;///函数调用int items[MAX_ELEMENTS] = &#123;79,66,43,83,30,87,38,55,91,72,49,9&#125;;element *position = heap;create_binary_tree(position, items);for (int i = 0; (*(heap+i)).key &gt; 0; i++) &#123; printf(&quot;binary tree element is %d\n&quot;,(*(heap + i)).key);&#125;create_max_heap();for (int i = 0; (*(heap+i)).key &gt; 0; i++) &#123; printf(&quot;heap element is %d\n&quot;,(*(heap + i)).key);&#125; 上诉代码在我机器上能够成功的构建一个最大堆。由于该完全二叉树存在n个元素，那么他的高度为:log2(n+1)，这就说明代码中的for循环会执行O(log2(n))次。因此其时间复杂度为：O(log2(n))。 堆排序 堆排序要比空间复杂度为O(n)的归并排序要慢一些，但是要比空间复杂度为O(1)的归并排序要快！ 通过上面最大堆创建一节中我们能够创建一个最大堆。出于该最大堆太大，我将其进行缩小以便进行画图演示。最大堆的排序过程其实是和最大堆的删除操作类似，由于最大堆的删除只能在根结点进行，当将根结点删除完成之后，就是将剩下的结点进行整理让其符合最大堆的标准。 1）、把最大堆根结点91“删除”，第一次排序图示：进过这一次排序之后，91就处在最终的正确位置上，所以我们只需要对余下的最大堆进行操作！这里需要注意一点： ⚠️⚠️⚠️注意，关于对余下进行最大堆操作时：并不需要像创建最大堆时，从倒数第一个非叶子结点开始。因为在我们只是对第一个和最后一个结点进行了交换，所以只有根结点的顺序不满足最大堆的约束，我们只需要对第一个元素进行处理即可 2）、继续对结点87进行相同的操作：同样，87的位置确定。 3）、现在我们来确定结点83的位置： 4）、经过上诉步骤就不难理解堆排序的原理所在，最后排序结果如下： 经过上诉多个步骤之后，最终的排序结果如下： 1[38、43、72、79、83、87、91] 很明显这是一个正确的从小到大的顺序。 编码实现这里需要对上面的代码进行一些修改！因为在排序中，我们的第0个元素是不用去放一个哨兵的，我们的元素从原来的第一个位置改为从第0个位置开始放置元素。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950void __swap(element *lhs,element *rhs)&#123; element temp = *lhs; *lhs = *rhs; *rhs = temp;&#125;int create_binarytree(element *heap, int items[MAX_SIZE], int n)&#123; if (n &lt;= 0) return 0; for (int i = 0; i &lt; n; i++,heap++) &#123; element value = &#123;items[i]&#125;; *heap = value; &#125; return 1;&#125;void adapt_maxheap(element *heap ,int node ,int n)&#123; int parent = node - 1 &lt; 0 ? 0 : node - 1; int child = 2 * parent + 1;/// 因为没有哨兵，所以在数组中的关系由原来的：parent = 2 * child =&gt; parent = 2 * child + 1 int max_node = max_node = 2*parent+2 &lt; n - 1 ? 2*parent+2 : n - 1; element temp = *(heap + parent); for (;child &lt;= max_node; parent = child,child = child * 2 + 1,max_node = 2*parent+2 &lt; n - 1 ? 2*parent+2 : n - 1) &#123; if ((heap + child)-&gt;key &lt;= (heap + child + 1)-&gt;key &amp;&amp; child + 1 &lt; n) &#123; child++; &#125; if ((heap + child)-&gt;key &lt; temp.key) &#123; break; &#125; *(heap + parent) = *(heap + child); &#125; *(heap + parent) = temp;&#125;int create_maxheap(element *heap ,int n)&#123; for (int node = n/2; node &gt; 0; node--) &#123; adapt_maxheap(heap, node, n); &#125; return 1;&#125;void heap_sort(element *heap ,int n)&#123; ///创建一个最大堆 create_maxheap(heap, n); ///进行排序过程 int i = n - 1; while (i &gt;= 0) &#123; __swap(heap+0, heap + i);/// 将第一个和最后一个进行交换 adapt_maxheap(heap, 0, i--);///将总的元素个数减一，适配成最大堆，这里只需要对首元素进行最大堆的操作 &#125;&#125; 调用：123456/// 堆排序int n = 7;int items[7] = &#123;87,79,38,83,72,43,91&#125;;element heap[7];create_binarytree(heap, items, n);heap_sort(heap, n); 在实现堆排序时最需要注意的就是当没有哨兵之后，父结点和左右孩子结点之间的关系发生了变化：12parent = 2 * child + 1;///左孩子parent = 2 * child + 2;///右孩子 关于对排序相关的知识点已经整理完了。其时间复杂度和归并排序的时间时间复杂度是一样的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[栈（Stack）和堆（Heap）]]></title>
      <url>%2F2017%2F03%2F21%2Fstack_heap_with_c%2F</url>
      <content type="text"><![CDATA[目前来说我们知道怎么去声明一个基础类型的变量，比如int，float，等等。以及复杂数据类型数组和结构，声明它们的时候C会把这些变量放在栈上。每个线程都有一个栈，而程序通常只有一个堆。 栈（Stack） 什么是栈？它是内存中一块特殊的区域，用于保存在函数中声明的零时变量（其中也包括main()函数）。栈是LIFO(Last in First Out 后进先出)的数据结构，进出操作是由CPU来管理和优化的。每当函数声明了一个变量，该变量就会被推入(Pushed)栈中。每当函数退出时，所有的变量都会被函数推出栈，并被释放掉(Free)。一旦变量被释放，该内存区域就可以被其他栈变量使用。 使用栈的优势是它会为你管理内存，而不需要你手动去分配或者释放内存。更进一步说，由于CPU可以有效地管理栈内存，所以从栈中读写变量是很快的。 理解栈的关键是需要知道函数什么时候退出，此时栈中所有的变量被推出，因此栈变量是局部的（也就是局部变量）。C中经常出现的一个错误就是，在函数返回以后去访问函数内部中栈变量。 如果使用太多的栈空间会导致溢出，比如在使用递归的时候，该函数使用了太多的局部变量在递归过程中就有可能造成栈溢出。 总结 栈是LIFO数据结构； CPU管理内存，而不需要手动去管理。正是因为这个原因从栈中读写变量很快的； 栈变量是局部的（也就是局部变量）； 栈的容量会随着函数的Push和Pop变化； 堆（Heap） 堆也是内存中一块特定区域，但是CPU并不会自动管理相关的操作，而且它的空间大小会有一定的浮动。在堆上分配内存的时候，在C中使用malloc()和calloc()函数。在不需要堆上这块内存之后，需要使用free()函数释放掉它。如果不释放的话就会造成内存泄漏，这块内存就会被闲置。 和栈不同之处在于，堆内存数据的读写速度会比栈慢。 栈（Stack）和堆（Heap）的差异配置堆栈大小 堆的大小在程序启动时分配，数值在不同操作系统中可能有所不同。 在Cocoa中想要修改线程的栈大小的话，可以使用NSThread的实例方法setStackSize:，如果使用POSIX线程技术创建的线程的话，想要设置栈大小的话使用pthread_attr_setstacksize函数。 ⚠️如果要设置栈大小就必须要在创建线程之前完成。 123456789101112131415/// 第一种NSThread *thread = [[NSThread alloc] initWithTarget:self selector:@selector(backgroudMethod:) object:nil];[thread setStackSize:1024];[thread start];/// 第二种pthread_attr_t attr;pthread_t posix_tread_id;int returnVal;returnVal = pthread_attr_init(&amp;attr);returnVal = pthread_attr_setstacksize(&amp;attr, 1024);/// 在创建线程前设置堆栈大小char *data;data = &quot;To ensure that a thread knows what work to do&quot;;int thread_error = pthread_create(&amp;posix_tread_id, &amp;attr, posix_thread_mainroutine, data); 生命周期 栈是和线程相关联的，意思就是说当线程退出时，栈被回收。而堆通常是在启动程序时分配，当程序退出之后被回收。 什么时候使用栈什么时候使用堆 需要申请较大内存空间（比如struct，array之类的），而且需要该变量存在较长时间，就是将该变量放在堆中； 如果需要动态修改struct或者array的大小，将该变量放在堆上。使用malloc()，calloc()，realloc()和free()等函数来管理内存； 如果使用相对较小的变量，并且只在函数中使用它们，此时该变量就存在于栈上。这样做会更快而且更简单；]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[动画中关于KVC官方文档翻译]]></title>
      <url>%2F2017%2F03%2F08%2Fanimation_kvc_translate%2F</url>
      <content type="text"><![CDATA[CoreAnimation让CAAnimation和CALayer都遵守NSKeyValueCoding协议，因此为它们增加了一些默认的keys（对应的value），添加的keyPath中包含了了CGPoint,CGRect,CGSize和CATransform3D类型。 1.键值编码兼容的容器类CAAnimation和CALayer类就是作为键值编码兼容的容器类，我们可以根据任意的keys来设置对应的value，即便这个key不是CALayer公开的属性，比如：1[theLayer setValue:[NSNumber numberWithInteger:50] forKey:@&quot;someKey&quot;]; 同样也可以通过任意已知的keys来查找对应的values，可以使用下面的代码通过预先设置好的somekey来检索values：1someKeyValue=[theLayer valueForKey:@&quot;someKey&quot;]; 2.默认支持的valueCoreAnimation在键值编码时规定：一个类可以给没有value的key提供一个默认值。CAAnimation和CALayer类都提供了类方法defaultValueForKey。 对于为key提供了默认value的类，在创建这个类的子类时必须要重写它的defaultValueForKey方法。 当你在实现这个方法的时候，需要检查key的参数列表，并且返回一个合适的value值，下面提供了一个例子，layer提供了defaultValueForKey:方法，为maskToBounds属性设置默认值：12345+ (id)defaultValueForKey:(NSString *)key&#123; if ([key isEqualToString:@&quot;masksToBounds&quot;]) return [NSNumber numberWithBool:YES]; return [super defaultValueForKey:key];&#125; 3.封装当一个key的数据是由一个标量值或者一个C的数据结构时，你必须要在其被分配到layer之前对其进行封装。同样的，当要访问这些Type时，也必须检查对象，然后使用合适的方法来打开合适的值。下表显示了Objective-c和c类型封装 C type 输入 CGPoint NSValue CGSize NSValue CGRect NSValue CATransform3D NSValue CGAffineTransform NSAffineTransform (OS X only) 不同类型封装的类 4.为KeyPath的提供的结构CAAnimation和CALayer类使用KeyPath来访问指定的字段，这功能可以让你在做动画时为特定的KeyPath提供数据。使用setValue:forKeyPath和valueForKeyPath:方法设置，然后用valueForKeyPath:获取相应的值。 (1)、CATransform3D KeyPaths你可以使用更强大的KeyPath，查找包含了CATransform3D类型属性的值。在需要指定layer的transforms完整的KeyPath时，我们可以根据下表中提供的数据，使用transform和sublayerTransform的值。例如，我们需要制定绕着layer的z轴旋转时，我就需要指定KeyPath为transform.rotation.z。 Field Key Path 描述 rotation.x 围绕X轴，旋转值为弧度，NSNumber类型 rotation.y 围绕y轴，旋转值为弧度，NSNumber类型 rotation.z 围绕z轴，旋转值为弧度，NSNumber类型 rotation 围绕z轴，旋转值为弧度，NSNumber类型，它和设置rotation.z一样 scale.x x轴缩放，NSNumber类型 scale.y y轴缩放，NSNumber类型 scale.z z轴缩放，NSNumber类型 scale 三个轴缩放的平均值，NSNumber类型 translation.x x轴位移，NSNumber类型 translation.y y轴位移，NSNumber类型 translation.z z轴位移，NSNumber类型 translation x，y上面位移，NSSize 和CGSize 下面展示了怎样通过setValue:forKeyPath方法来修改一个layer，这个例子设置了layer在x轴上位移了10个像素点，来显示layer在x轴上的移动:1[myLayer setValue:[NSNumber numberWithFloat:10.0] forKeyPath:@&quot;transform.translation.x&quot;]; ⚠注意：通过keyPath来设置value值的时候不能像Objective-C里面对属性的赋值，必须配合KeyPath字符串使用setValue:forKeyPath方法来进行赋值。 (2)、CGPoint KeyPath如果当前给的是一个CGPoint类型，则可以根据下表进行设置。例如，当我们想要修改layer的position的x值时，可以在KeyPath中写position.x。 Structure Field 描述 x x的分量 y y的分量 (3)、CGSize KeyPath Structure Field 描述 width size的width值 height size的height值 (4)、CGRect KeyPath例如，要更改layer的bounds属性的width值，可以写入关键路径bounds.size.width Structure Field 描述 origin 坐标，类型CGPoint origin.x 坐标的x值，类型CGFloat origin.y 坐标的y值，类型CGFloat size 大小，类型CGSize size.width size的width值 size.height size的height值 结语翻译这篇文章的目的因为我在做动画中需要每次都差到对应的KeyPath，很麻烦，索性我就将其翻译出来。到目前为止，这片文章大部分翻译算是完成了，看起来很粗糙，能看懂就最好了。 原来地址：Key-Value Coding Extensions]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Unicode和UTF-8、UTF-16以及UTF-32]]></title>
      <url>%2F2017%2F03%2F02%2Funicode%2F</url>
      <content type="text"><![CDATA[写在前面如果你是iOS开发者，并且在处理NSString字符上遇到了一些问题，强烈建议去看看Objc中国上关于 NSString 与 Unicode。上面介绍了一些关于NSString相关的东西，比如characterAtIndex:返回的可能是包含组合序列（emoji最为常见）等等。 简介Unicode对世界上大部分的文字系统进行了整理、编码，使得电脑可以用更为简单的方式来呈现和处理文字。这是维基百科对Unicode下的定义。Unicode的实现方式包含了UTF-8、UTF-16（字符用两个字节或者四个字节表示）和UTF-32（用四个字节来表示），下面对面一一进行介绍。 UTF-8UTF-8的最明显的一个特点是它是变长的，它可以使用1到4个字节表示一个符号，根据不同的符号变化字节长度。先把阮一峰在《字符编码笔记：ASCII，Unicode和UTF-8》中对UTF-8的编写规则的一个总结放出来。 ️️️UTF-8的编码规则很简单，只有二条：1、对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。2、对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 我的解释：第一个字节前面n为设1是为了知道当前字符占用多少字节，而后面字节的前两位为什么要设置为10下面会马上进行解释。现在我们来具体的分析一下Unicode的不同范围：下面中前两个描述是否为ASCII，后两个描述多字节序列 U+0000到U+007F（ASCII）从U+0000到U+007F被编码为0x00~0x7F的单字节，这是ASCII码的所有字符，一共128个字符，所以Unicode是完全用来容纳ASCII的。对于上面结论中提到的后面字节的前两位一律设为10因为必须要大于7F才和ASCII码分开。 大于 U+007F（非 ASCII）所有大于 U+007F 的字符被编码为一串多字节序列，这样就可以区分一串多字节序列是多字节码还是 ASCII 码。 0xFE 和 0xFF 不会被用于 UTF-8 编码中。 多字节序列的第一个字节在0xC0~0xFD中，剩余字节在0x80~0xBF内。这里解释一下为什么第一个是在0xC0~0xFD中，理解这里需要再回去看看上面注意中提到的Unicode编码规则。因为表示的是多字节就表明n是大于1的，所以第一个字节最小的值为：11000000即C0（每四位表示一个十六进制数，这也是为什么在编程的时候喜欢用十六进制数的原因），如果在没有限制的情况下，通过上面的结论我们可以得到第一个字节能表示的最大的数是0xFE（11111110），就是前面7位设置1最后一位设置为0，但是上面一条中提到不包含FE，所以第一个字节的最大值为0xFD(11111101)。同理因为后面字节的前两位一律设为10所以多字节除了第一个字节的其他字节最大值为10111111(BF)。 总结UTF-8 编码字符最长可达六个字节 1234567Unicode 字符: UTF-8 码:U-00000000 - U-0000007F: 0xxxxxxx ///表示ASCIIU-00000080 - U-000007FF: 110xxxxx 10xxxxxx ///U-00000800 - U-0000FFFF: 1110xxxx 10xxxxxx 10xxxxxxU-00010000 - U-001FFFFF: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxxU-00200000 - U-03FFFFFF: 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxxU-04000000 - U-7FFFFFFF: 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 举个例子：汉字“王”的Unicode码为U+73B8转换为二进制为:0111 0011 1010 1000，”73b8”位于上面的第三类，把转换的16个二进制依次放入（一定是依次放入不管空格的）上诉的x中： 123411100111 10001110 10101000/// 同样我们来验证一下阮一峰举例的“严”字/// 4E25 同样属于上诉的第三类 ，对应的二进制 =&gt; 0100 1110 0010 0101/// 11100100 10111000 10100101 得到的结果和他文章中的一样。 到这里我自己觉得应该是把UTF-8的编码方式说清楚了，最后再来一个编码的顺序（很适合于我的方式） 编码的顺序对于单字节：直接将其转换为八位的二进制就可以了；对于多字节：1.找到Unicode码对应的二进制数据2.查看该Unicode码在分类中属于第几类3.一次填入二进制码 UTF-16UTF-16是Unicode字符编码五层次模型的第三层：字符编码表（Character Encoding Form，也称为”storage format”）的一种实现方式。即把Unicode字符集的抽象码位映射为16位长的整数（即码元）的序列，用于数据存储或传递。这里需要说明一下基本多文种平面-BMP和辅助平面-SMP，在维基百科中每一个平面相关的图片下面都说了”每个写着数字的格子代表256个码点”，即00~FF。例如：位于BMP中00格子中的一个码点表示为:0x00E5。下面同样用一下阮一峰的规则总结： 基本平面的字符占用2个字节，辅助平面的字符占用4个字节。也就是说，UTF-16的编码长度要么是2个字节（U+0000到U+FFFF），要么是4个字节（U+010000到U+10FFFF）。 为了能够区分它本身是一个字符，还是需要跟其他两个字节放在一起解读。在BMP中，从U+D800到U+DFFF之间BMP的区段是永久保留不映射到字符（从维基百科的图中D8~DF之间表示unallocated code points）。 UTF-16结论(D800~DFFF)具体来说，辅助平面的字符位共有pow(2,20)个，也就是说，对应这些字符至少需要20个二进制位。UTF-16将这20位拆成两半，前10位映射在U+D800到U+DBFF（空间大小pow(2,10)），称为高位（H），后10位映射在U+DC00到U+DFFF（空间大小pow(2,10)），称为低位（L）。这意味着，一个辅助平面的字符，被拆成两个基本平面的字符表示。1HHHH HHHH HHLL LLLL LLLL ️注意-结论高位：D800~DBFF;低位：DC00~DFFF; 所以，当我们遇到两个字节，发现它的码点在U+D800到U+DBFF之间，就可以断定，紧跟在后面的两个字节的码点，应该在U+DC00到U+DFFF之间，这四个字节必须放在一起解读。（这里我就直接引用阮一峰的解释，因为他解释很通俗易懂。） 解释一下这里为什么是pow(2,20)，在基本平面之外有16个辅助平面（即pow(2,4)），而每一个辅助平面pow(2,16)个码位（辅助平面和基本平面一样，每个码位里面都包含了256个码点）。123///辅助平面字符，转码公式。H = Math.floor((c-0x10000) / 0x400)+0xD800L = (c - 0x10000) % 0x400 + 0xDC00 H为上文提到的高位，L位上文提到的低位。举例说明一下:1234567/// 对于小于0xFFFF的即基本平面的字符，为两个字节U+8D9E = 0x8D9E ///对应的二进制格式为:10001101 10011110/// 对出于辅助平面的字符/// 对于U+1D306H = Math.floor((0x1D306-0x10000) / 0x400)+0xD800 = d834L = (0x1D306 - 0x10000) % 0x400 + 0xDC00 = df06 UTF-32因为UTF-32对每个字符都使用4字节，就空间而言，是非常没有效率的。特别地，非基本多文种平面的字符在大部分文件中通常很罕见，以致于它们通常被认为不存在占用空间大小的讨论，使得UTF-32通常会是其它编码的二到四倍。 结论所以当我们在使用字符串的时候，通常使用length的时候，要看他的编码方式，并不是一个字符就代表了一个字节有可能是两个字节、四个字节甚至可能最多能到6个字节都是有可能的，这应该就能理解Swift中对于字符串的处理了。 参考文献Unicode代码图表字符编码笔记：ASCII，Unicode和UTF-8什么是UTF-8Unicode与JavaScript详解Unicode编码及其实现：UTF-16、UTF-8，and moreUTF-16UTF-32]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Swift3 Unsafe[Mutable]Pointer]]></title>
      <url>%2F2017%2F03%2F02%2Fswift3_pointer%2F</url>
      <content type="text"><![CDATA[这篇文章水准不高，可能因为我自己能力有限，英文水平也就这样，自己能看懂，可能存在误人子弟的可能性，所以如果有人有机会看到了这边文章就当是一个小白的入门级的笔记吧！如果需要更深入的了解请查看文末的参考链接为了将我的PhotoCutter适配Swfit3一看到一大堆的Unsafe[Mutable]Pointer的错误就是脑壳疼！最头疼的事没有找到这方面的中文资料，只有自己来弄了，然后记录一下，现在项目还是用OC，一天不写就生疏,怕以后来自己又忘记了，然后自己纪录一下吧… 这里我先粗略地介绍：1.我的理解:UnsafeMutablePointer其实就是UnsafePointer的可以变化的类型，但是UnsafePointer又不允许你去改变指针元素 2.Unsafe[Mutable]RawPointer:在swift3以前为Unsafe[Mutable]Pointer&lt;Void&gt;,也就是c中的void * 3.Unsafe[Mutable]BufferPointer表示一连串的数组指针 withUnsafePointer/withUnsafeMutablePointer比如下面我用c的方式创建和销毁了一个int型的指针a: int \*a = malloc(sizeof(int)); \*a = 10; free(a) 假设在swift中`var a:Int = 10`,现在我们的目的是想创建一个指针a,我们需要将`a`转成`*a`，我们需要怎么做呢？这里可以用到`withUnsafePointer/withUnsafeMutablePointer` 这两个函数会以swift类型和一个block为参数，而这个目的指针就是这个block的参数。也就是说你想将某一个swift类型的参数转换为一个指针result，这个result就是你想获得的指针，也就是下面两个例子中的ptr，希望我这个描述没有把你绕晕！ 这里我也以swift.org上面的socket例子来写吧! var addrin = sockaddr_in() 创建UnsafeMutablePointer withUnsafeMutablePointer(to: &addrin) { ptr in //ptr:UnsafeMutablePointer\ } 创建UnsafePointer withUnsafePointer(to: &addrin) { ptr in //ptr: UnsafePointer\ } withUnsafeBytes/withUnsafeMutableBytes通过withUnsafeBytes/withUnsafeMutableBytes获得的bytes只能在在函数closure里面进行使用，这个函数只相对于Data类型来获取bytes使用！ func unsafebytes() { guard let data = ".".data(using: .ascii) else{ return } data.withUnsafeBytes { (byte:UnsafePointer) -> Void in print(byte) } } unsafebytes() withMemoryRebound我们可以使用withMemoryRebound函数，来将一个类型的指针转换为另外一个类型的指针，使用这个函数的时候也有一些需要注意点，在[UnsafeRawPointer Migration] (1)的介绍中说到:Conversion from UnsafePointer&lt;T&gt; to UnsafePointer&lt;U&gt; has been disallowed，所以只能将UnsafePointer&lt;Int&gt;转换为UnsafeMutablePointer&lt;UInt8&gt;. UnsafePointer -&gt; UnsafeMutablePointer var a = 10 withUnsafePointer(to: &a) { a_pt in a_pt.withMemoryRebound(to: UInt8.self, capacity: 1, { a_pt_uint8 in //a_pt_uint8:UnsafeMutablePointer }) } 具体的使用场景:在使用socket的时候需要bind或者connect的时候这个函数的具体使用场景在[UnsafeRawPointer Migration] (1)中也有提到。sockaddr_in －&gt; sockaddr var addrin = sockaddr_in() let sock = socket(PF_INET, SOCK_STREAM, 0) let result = withUnsafePointer(to: &addrin) { $0.withMemoryRebound(to: sockaddr.self, capacity: 1) { connect(sock, $0, socklen_t(MemoryLayout.stride)) } } assumingMemoryBound将UnsafeRawPointer转换为UnsafePointer&lt;T&gt;类型，也就是swift3之前的UnsafePointer&lt;Void&gt;到UnsafePointer&lt;T&gt;。这个和前面提到的函数withMemoryRebound的区别就是: assumingMemoryBound可以看成是withMemoryRebound的一个特例，即:assumingMemoryBound为UnsafePointer&lt;Void&gt;到UnsafePointer&lt;T&gt;，withMemoryRebound为UnsafePointer&lt;U&gt;到UnsafeMutablePointer&lt;T&gt; 代码示例: let strPtr = UnsafeMutablePointer\.allocate(capacity: 1) let rawPtr = UnsafeRawPointer(strPtr) let intPtr = rawPtr.assumingMemoryBound(to: Int.self) bindMemory绑定一个类型\到已经被分配的内存空间，返回一个绑定在self内存上UnsafePointer&lt;T&gt;的指针，需要注意的是这个函数是用于Unsafe[Mutable]RawPointer。 /// - Precondition: The memory is uninitialized. /// - Postcondition: The memory is bound to 'T' starting at `self` continuing /// through `self` + `count` * `MemoryLayout.stride` /// - Warning: Binding memory to a type is potentially undefined if the /// memory is ever accessed as an unrelated type. 操作 内存状态 类型 rawptr = allocate() uninitialized None tptr = rawptr.bindMemory(T) uninitialized bound to T tptr.initialize() initialized bound to T 从上面的表格结合文档里面对于bindMemory的说明来看，我对于bindMemory的理解就是，使用函数之前这块内存空间是没有被初始化的，使用bindMemory的目的是将T绑定到self后面self + count MemoryLayout&lt;T&gt;.stride长度的的这块内存空间上来。但是绑定上来并不代表初始化了，此时这个内存空间仍然是没有初始化的，所以最后需要调用函数initialize的函数来初始化!用这个函数同样可以把`void `的C类型转换为Swift的类型。关于Custom memory allocation这个函数的使用可能会有问题…先上一段我自己理解的代码吧 let a = 100 let a_rawptr = UnsafeMutableRawPointer.allocate(bytes: MemoryLayout\.size, alignedTo: MemoryLayout\.alignment) let bind_rawptr = a_rawptr.bindMemory(to: Int.self, capacity: MemoryLayout\.stride) bind_rawptr.initialize(to: a) unsafeBitCast返回一个翻译成某一特定类型的值！,这个会破坏Swift的类型系统！ 特别注意️:不到万不得已不要使用这个函数 实战PhotoCutter为了适配Swift3，这其中大部分和指针相关的东西需要适配，我开始看到这些也是懵逼的，根本不懂怎么改，只有自己去慢慢学。我的方法可能很差，就目前而言是适配了，下面贴上我的修改的代码吧! Swift2.x options = CFDictionaryCreate(kCFAllocatorDefault, UnsafeMutablePointer(UnsafePointer(keys)), UnsafeMutablePointer(UnsafePointer(values)), 2, &kcKeysBack, &kcValuesBack) Swift3.0 fileprivate func buffer(to type:T.Type, source:[T]) -> UnsafeMutablePointer{ var buffer = UnsafeMutablePointer.allocate(capacity: source.count) for idx in 0..]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[创建一个更轻的ViewController]]></title>
      <url>%2F2017%2F03%2F02%2Flight_viewcontroller%2F</url>
      <content type="text"><![CDATA[现在的项目越来越臃肿，一个控制器的代码量越来越多，业务最繁重的一个控制器代码量已经达到了1000多行！这就导致给控制器瘦身是一定要做的。说实话这种的是很不好组织语言的，但是还是按照惯例还是在这里来记录一下自己想法经历和结果。 注意:文中会同时出现Swift代码和objc代码，出现这个的原因是为了演示针对使用AF进行网络请求和数据处理，就用了其他工程的代码来进行演示。样例工程是用Swift写的没有集成AF库，只是模拟了一个网络请求，但是Swift的代码同样适用于objc，这里大多的管理类都是继承自NSObject，希望见谅吧。 目标现在我们的目的是来分离一个登录页面的Controller。我先把这个界面的效果图放出来 分析这个页面比较简单，一个简单的输入用户名称和密码，然后登录给出正确还是错误的结果！这里需要简单处理一下用户名密码的输入情况来绝对按钮的颜色的交互情况。我将一个业务场景进行划分可以分为以下5个： 1.控制器 ——-Controller2.视图 ———ViewOperator3.网络请求—–Request4.数据处理—–DataManager5.协议代理—–Delegate 职责划分1.控制器(Controller)控制器的职责需要统调视图(ViewOperator),网络请求(Request),数据处理(DataManager),代理协议(Delegate)以及不同控制器之间的联系。 2.视图(ViewOperator)ViewOperator的作用是将控制器里面与视图相关的操作剥离出来。同时也包括了按钮的点击。 3.协议代理(Delegate)剥离出controller中的delegate的回调，比如登录界面UITextField的相关代理操作，也可以是TableView的delegate和dataSource的分离。 4.网络请求(Request)分离控制器中的网络请求部分，比如在一个包含了tableView的界面，数据加载，下拉刷新，上拉加载的相关方法. 5.数据处理(DataManager)在网络请求完成的回调，回调回来的数据是不需要放在网络请求里面去做的，所以将网络请求数据回调放在DataManager中来。数据处理完成是需要给Controller一个数据回调的。 第一步来分离Controller中的视图通常视图相关的操作如果都放在Controller会产生很多行的代码的，所以第一步我们需要将控制器和视图相关操作分离出来。在使用StoryBoard来创建一个ViewController时，需要在控制器中拖一些button,label,textfield等等控件，这些控件的定制以及交互等等都要拖出代码进行处理。所以这里我可以给当前控制器的Scene添加一个object 然后自定义个LoginViewOperator来继承自NSObject，将这个object的CustomClass改为LoginViewOperator。此时你可以将上诉的控件都拖到这个class里面，比如: public class LoginViewOperator:NSObject{ @IBOutlet var fields: [UITextField]! @IBOutlet weak var loginbtn: UIButton! @IBOutlet weak var indicator: UIActivityIndicatorView! @IBAction func login( sender: UIButton) { }}同时我也可以直接将LoginViewOperator拖到Controller中，来让Controller来管理LoginViewOperator `。 class LoginViewController { @IBOutlet var view_operator: LoginViewOperator!}如果有自定义视图的话，自定义视图的相关操作可以放在这个类中去做，或者可以给这个视图添加一个helper(CustomViewHelper)通过他来做自定义视图的相关操作 第二步来分离Controller中的代理协议加入在一个业务场景中有一个tableView，或者textfield，或者其他的系统的控件等等，和他们打交道肯定需要回调的，把这些放在控制器中也是很占位置的，必须将他们分离出来。在当前场景主要是UITextFieldDelegate的分离，我们需要创建一个类继承自NSObject,并让他遵守UITextFieldDelegate。 public class EDLoginTextFieldDelegate:NSObject{ public var textdidChange:((UITextField)-&gt;Void)?}extension EDLoginTextFieldDelegate:UITextFieldDelegate{ public func textFieldDidChange( textField: UITextField){ textdidChange?(textField) } public func textFieldShouldReturn( textField: UITextField) -&gt; Bool { return true } public func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -&gt; Bool { return true }}上面方法中textFieldDidChange是通过在LoginViewOperator中的UITextField添加的target-action的，这个会在接下来讲到。此时在LoginViewOperator新建一个变量delegate: lazy var delegate:EDLoginTextFieldDelegate = EDLoginTextFieldDelegate().then{ //text did change $0.textdidChange = {[unowned self] in //在这里处理当textfield在发生变化时，视图需要做出的改变，也就是上面gif中通过判断输入框中是否有值来改变button的alpha和enable的操作 } //text did end //text did begin}同时将delegate赋值给UITextField的delegate，修改上面outlet出来的fields变量： @IBOutlet var fields: [UITextField]!{ didSet{ fields.forEach{ $0.delegate = delegate //给每一个field都添加一个target-action，这个action不要写在LoginViewOperator中，因为这个实际上和delegate是类似的，不是一个视图操作，所以我这里绕了一圈在delegate的textdidChange进行了回调。 $0.addTarget(delegate, action: #selector(delegate.textFieldDidChange(_:)), for: .editingChanged) } if let username = User.mine.name{ fields.first?.text = username } } }上面就是我在分离一个UITextFieldDelegate所做的操作。在这里看来额外添加的这个delegate可能多此一举，因为操作相对比较少，但是如果是在tableView中的话，你需要在numberOfSections,numberOfRowsInSection,cellForRowAt以及willDisplayCell中需要写一大堆的逻辑，在这里就会体现出协议代理的分离带来的好处。 在这里建议：如果在使用数据回调的时候可以使用delegate而不是block，这样就可以把放在controller中的block代码分离到CustomDelegate中来，后面在分离数据处理部分会用到delgate。 第三步来分离Controller中的网络请求这一步我用objc的代码来进行讲解，因为在样例工程是没有涉及到网络请求的，所以我将我们公司项目的中的网络请求部分的分离代码贴出来。同样我们需要创建一个类DailyProhRequst来继承于NSObject，该类分离控制器的网络请求。 @interface DailyProhRequst : NSObject@end并为DaulyProhRequst添加三个方法: 下拉加载 + (NSInteger)headerRefresh:(NSDictionary *)para currentPage:(NSInteger)page dataOperator:(DailyProhDataOperator *)operators; 上拉刷新的网络操作 + (NSInteger)footerRefresh:(NSDictionary *)para currentPage:(NSInteger)page dataOperator:(DailyProhDataOperator *)operators; 简单的数据加载 + (NSInteger)reloadData:(NSDictionary *)para currentPage:(NSInteger)page dataOperator:(DailyProhDataOperator *)operators;如果需要上拉加载下拉刷新数据请求之类的，可以直接调用上面上个方法中的一个，在上面方法中还提到了dataOperator，它是用来整理数据的，这部分放到后面来讲。这三个方法只进行网络并把数据传给dataOperator，request对controller是没有回调的！在上面的分离视图部分，我们将登录按钮的@IBAction放在了LoginViewOperator中，我们需要将这个按钮事件回调给控制器。其实严谨来讲，我们是没有必要将按钮的IBAction放在视图中来的，这里是我的失误。所以在控制器中点击按钮进行一个网络请求的操作就是[DailyProhRequst headerRefresh:@{} currentPage:weakSelf.currentPage dataOperator:weakSelf.dataOperator]，网络请求的分离相对来说比较简单。 第四步创建数据操作类来管理数据同上面一样适用objc的代码进行讲解。这里数据可以分为网络请求返回的数据和抽取本地db的数据，我主要讲一下通过网络获取数据进行数据处理的数据管理类。首先我们同样需要创建一个类来继承自NSObject，并添加一个方法从Requst中获取原始的网络数据: @interface DailyProhDataOperator : NSObject@end同时我们给DailyProhDataOperator类添加一个获取数据的方法- (void)fetchData:(id)responseobject requstFailed:(NSError *)error;而且我们的目的是必须要将处理好的数据（可能是你自己定一个数据模型）返回给Controller来更新View（由ViewOperator来更新操作）,所以需要创建一个delegate： @protocol DailyProhDataOperatorHandler @end并给协议添加两个回调方法- (void)dataOperatorSuccess:(DailyProhDataModel *)dataSource;- (void)dataOperatorFailed:(NSError *)error;然后给DailyProhDataOperator类添加一个代理属性@property (weak ) id&lt;DailyProhDataOperatorHandler&gt; handler;并在网络请求分离中的方法中进行修改: +(NSInteger)reloadData:(NSDictionary )para currentPage:(NSInteger)page dataOperator:(DailyProhDataOperator )operators{ //在网络请求或者失败的回调中添加数据处理类的入口 //[operators fetchData:responseObject requstFailed:nil]; return 0;}在DataOperator中进行数据处理完成的回调[self.handler dataOperatorSuccess:data];这个delegate可以通过上面已经讲过的协议代理分离放在CustomDelegate的类中，由CustomDelegate和ViewOperator进行通信来达到根据数据来修改视图的效果。 结果虽然在样例工程中没有网络请求的部分，但是实际上网络请求在控制器中所占的代码就仅仅一个跳转相关的逻辑的代码而已，所以经过上诉的方式对controller进行瘦身之后，一个完整的功能的登录界面代码量为： 图中的request是我模拟的一个假的网络请求。 总结通过上诉的方式可以很大程度上将控制器代码进行缩减，而且指责划分也很明确。最后来说一下他们之间的关系： Controller &lt;-&gt; ViewOperator通过ViewOperator修改视图，Controller相关交互之后通过ViewOperator来进行界面更行 Controller &lt;-&gt; Delegate由delegate来分担Controller中的相关代理协议的工作，包括从delegate拿取数据等等， Controller &lt;-&gt; Requst由Controller来发起Requst Requst &lt;-&gt; DataOperatorDataOperator从Request获取数据，并对数据进行整理 Delegate &lt;-&gt; DataOperatorDataOperator把整理好的数据返回给Delegate Delegate &lt;-&gt; ViewOperatorDelegate把数据传给ViewOperator之后，由ViewOperator更新视图 这个只是罗列出了在当前业务逻辑下面他们之间的相互关系，只是为了梳理一下思路，在不同的逻辑下有不同的组合，但是一个业务场景在代码实现层面可以大体分成五种或者更多的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[BLUEPILL在项目中的实践]]></title>
      <url>%2F2017%2F03%2F02%2Fbluepill%2F</url>
      <content type="text"><![CDATA[Bluepill借助于CoreSimulator解决稳定性和可扩展性问题。使用CoreSimulator实现了将Bluepill从Xcode模拟器中隔离出来，并使Bluepill可并行使用多种模拟器运行测试。这里Xcode模拟器是一种随每次Xcode的更新而不断进化的黑盒。（来自InfoQ介绍bluepill时的一段话） 在bluepill的Release可以下载到的压缩包解压，然后在终端中敲入命令: ./bluepill -a ./Sample.app -s ./SampleAppTestScheme.xcscheme -o ./output/很简单，对于这最基本的命令，我们只需要有.app和.xcscheme这两个文件，然后将上面下载下来的压缩包解压之后的两个文件放在恰当的位置，应该就可以了。如果真的是这样，这篇文章也就没有存在的价值了，在这篇文章中将要做下面这几件事： Xcode工程项目结构体系； 如何获取上面提到的两个文件并使用上面这个最简单命令跑起来（是否包含了Test，如果没有需要添加Test）； Xcode中Test的基本操作； 相关参数说明； 当前环境:macOS Sierra 版本 10.12.3Xcode Version 8.2.1在我使用bluepill时，它只能在iOS 10.2环境下运行，查看Xcode支持的模拟器版本:xcrun simctl list runtimes 实践前需要知道的概念下面介绍的这几个概念在Apple Developer都可以找到，我仅仅把我认为比较有用的信息罗列出来一下。更多关于设置和使用方面我在文末列出来了，可以自己查看！ Xcode Project project包含了需要构建一个应用程序需要的所有的文件，资源和相关信息，而workspace是能够包含多个project的。 注意一个project是可以包含多个targets的！ 每个project都定义了一个默认的build settings。因为每个project包含了多个targets，所以我们可以为每个targets设置不同的build settings（在文档中特别说明了每个targets的build settings是重写了其所属的project的build settings）。 Xcode WorkspaceWorkspace是可以包含任意个project 的，但是一个project又可以属于多个WorkSpace。对于处于同一个Workspace的不同project，由于workspace中所有project的所有文件都是位于同一个文件目录中，因此并不需要拷贝它们到每一个project文件夹中。对于Workspace的这个共同目录，我们是可以自己指定一个构建目录（build directory）的，但是如果指定了构建目录在build project时，这个project所在的所有workspace的构建目录都将覆盖这个指定的构建目录！ targettarget指定了要构建的目标，在bluepill中会包含samepleApp、samepleApp_Test等targets。同时我们可以修改target的build setting和build phases，target会继承project的build setting，但是我们为target指定不同的build settings来覆盖project的build setting。 schemescheme是需要被build的target的集合。可以在Xcode中选择不同的scheme来指定当前需要build的target(在Xcode中同时只能选择一个scheme)。 实践开荒阶段在开荒阶段是没有使用WorkSpace的，一切的基础都是在Project上。 1.创建一个不包含Test和UITest的空项目 创建一个文件夹用来保存工程项目和下载的blupill解压出来的两个文件：bluepill和bp； 学过C语言的都知道，在使用cc xxx.c文件之后会生成一个.o文件，当然也可以使用cc xxx.c -o selfpill来重命名这个-o文件，使用selfpill文件的命令是：./selfpill（因为c的main的参数就是接收的终端命令），所以我猜测这其实c的一个-o文件，为了使用这两个文件，就需要将上述提到的bluepill和bp和工程项目放在同一个文件夹下。 这一步中我们创建不包含Test和UITest的空项目即不要勾选那两个和test相关的Checkbox，你肯定会疑问为什么要这么做，当我在看BLUEPILL的README的时候特别指出如果是使用终端进行build(使用xcodebuild，后面我会把这一步放在脚本中)的话需要使用build-for-testing，我猜测应该和test是有关的。所以我先测试一下没有test的情况是否会出错，如果出错，错误是什么？ 2.编译这个空项目 项目创建好之后编译一下之后第一目的就是在终端中输入上文提到的命令，但是这里有两个疑问：-a的参数.app的路径是什么？-s的.xcscheme的路径是什么？.app就是前面我们通过编译一次获得的一个文件夹，这个文件夹的地址是/Users/xxxx/Library/Developer/Xcode/DerivedData/在 DerivedData文件夹下找到刚刚创建的项目并点击进去，.app文件夹就在Build/Products/Debug-iphonesimulator/，如果你在创建好之后没有编译Products就是一个空文件夹；而.xcscheme在工程项目所在文件夹/bluepill_sameple.xcodeproj/xcuserdata/xxx.xcuserdatad/xcschemes/bluepill_sameple.xcscheme路径中提到的xxx是你在创建项目时的用户名。好了，现在我们可以在终端中数据命令: ./bluepill -a /Users/xxx/Library/Developer/Xcode/DerivedData/bluepill_sameple-hdwawthuaefpnyecnudlxrpzozyq/Build/Products/Debug-iphonesimulator/bluepill_sameple.app -s /Users/xxx/Desktop/bluepill_new_build/bluepill_sameple/bluepill_sameple.xcodeproj/xcuserdata/xxx.xcuserdatad/xcschemes/bluepill_sameple.xcscheme -o output敲回车之后我这里出现如下报错： ERROR: There is no ‘Plugins’ folder inside your app bundle at:/Users/Wil/Library/Developer/Xcode/DerivedData/bluepill_sameple-hdwawthuaefpnyecnudlxrpzozyq/Build/Products/Debug-iphonesimulator/bluepill_sameple.appPerhaps you forgot to ‘build-for-testing’? (Cmd + Shift + U) in Xcode.Also, if you are using XCUITest, check https://github.com/linkedin/bluepill/issues/16出现这个问题的原因是在.app文件夹下面没有Plugins文件夹。就算是按照提示说使用Cmd + Shift + U或者使用xcodebuild build-for-testing仍然是行不通的。走到这里我们有两条路，可以删除当前工程重新建一个包含了Test和UITest的项目，也可以在现有的Project中添加Test和UITest的Targets。我选择第二条，因为在我实际项目在这之前也是没有包含相关Test的。 3.在包含Test的Project中实践 现在我们需要在既有Project中添加一个Targets，File/New/Target.../iOS Unit Testing Bundle创建并在Scheme Menu中选择New Scheme选中刚刚我们添加的Targets。编译一下（这里可以使用Cmd + Shift + U或者选择Test的scheme并build，也可以使用build-for-testing命令: xcodebuild build-for-testing -project bluepill_sameple/bluepill_sameple.xcodeproj/ -scheme bluepill_sameple -sdk iphonesimulator10.2 -derivedDataPath build/进入.app文件夹下查看是否已经有了PlugIns文件夹，如果存在该文件夹则继续执行上一次出错的那个命令，运行成功，到这里已经能够使用最基础的命令。 前面提到可以选择Test的scheme并build，可能会出现一点问题:The scheme &#39;bluepill_samepleTests&#39; is not configured for Running。因为添加了这个Test的Target之后需要编辑一下对应的Scheme使它能够进行Running操作！具体的操作如下所示： 设置之后Cmd + B成功运行！ 完善阶段基本参数解释和使用 -a/-s/-o:这是三个最基本的参数，在前面使用的时候应该知道如何使用，这里不再进行解释！ -c:读取一个自定义的config.json文件作为bluepill的运行参数，例如:./bluepill -c config.json -l :获取在当前project中存在的testcase，它的打印结果是存在于.../bluepill_sameple.app/PlugIns文件夹下面！现在我为了演示多建立了一个Test Target(添加Scheme)然后编译：./bluepill -a /Users/用户名/Library/Developer/Xcode/DerivedData/bluepill_sameple-hdwawthuaefpnyecnudlxrpzozyq/Build/Products/Debug-iphonesimulator/bluepill_sameple.app -s /Users/用户名/Desktop/bluepill_new_build/bluepill_sameple/bluepill_sameple.xcodeproj/xcuserdata/Wil.xcuserdatad/xcschemes/bluepill_sameple.xcscheme -l打印结果:bluepill_samepleTests.xctestbluepill_samepleTests_target.xctest文件夹: -x/-i:-x在运行bluepill的时候不包含某一个testcase，-i和-x相反，它则是要包含某一个testcase，-x的优先级是大于-i的。./bluepill -a xxxx.app -s xxxx.xcscheme -x bluepill_samepleTests.xctest -r ‘iOS 10.2’;./bluepill -a xxxx.app -s xxxx.xcscheme -i bluepill_samepleTests.xctest -r ‘iOS 10.2’;其中关于-x和-i的参数可使用-l命令来获取！ -d/-n:使用命令：xcrun simctl list devices来获取当前可用的模拟器设备，在得到这些设备之后可以使用-d来指定需要启动的设备！其中-n可以指定同时运行的模拟器数量。比如：./bluepill -a xxxx.app -s xxxx.xcscheme -r ‘iOS 10.2’ -d ‘iPhone 5s’;其中命令前面是一样的，这里先省略！对于真机：在bluepill的Issue页面指出blupill不支持真机！ 目前对于bluepill的实践先到这里，后续还会继续更新遇到的相关问题！ 相关链接: Configuring Your Xcode Project Xcode Build Settings Reference]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTTP持久连接]]></title>
      <url>%2F2017%2F02%2F27%2Fhttp_keep_alive%2F</url>
      <content type="text"><![CDATA[HTTP/1.1允许http设备在事务处理结束之后将TCP连接保持在打开状态，以便为未来的http请求重用现存的连接。在事务处理结束之后仍然保持打开状态的TCP连接被称为持久连接。持久连接会在不同事务之间保持打开状态，直到客户端或者服务器决定将其关闭。已经打开的连接可以避免慢启动的拥堵适应阶段。以便更快的进行数据传输。 持久以及并行连接并行连接的缺点: 每个事务打开／关闭一个新的连接，会耗费时间和宽带的； 由于TCP慢启动，每条新连接的性能都会有降低； 可打开的并行连接数量实际上是有限的。 持久连接降低了时延和建立连接的开销，但是持久连接时可能会累积出大量的空闲连接。所以需要配合使用持久连接和并行连接。 HTTP/1.0+ keep-alive连接客户端实现了HTTP/1.0 keep-alive连接的客户端可以通过包含Connection: Keep-Alive首部请求将一条连接保持在打开状态。 服务端如果服务器愿意为下一条请求将连接保持在打开状态，就在通用首部中包含相同的内容。如果没有包含Connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在发回响应报文之后关闭连接。 ⚠️注意keep-alive首部只是请求将连接保持在活跃状态。在发出keep-alive请求之后，客户端和服务器可以在任意时刻关闭空闲的keep-alive连接，并可以限制keep-alive连接所处理事务的数量。 通用首部Keep-Alive选项 参数timeout是在Keep-Alive响应首部发送的。它估计了服务器希望将连接保持在活跃状态的时间。 参数max是在Keep-Alive响应首部发送的。它估计了服务器还希望为多少个事务抱持此连接的活跃状态。 Keep-Alive首部还可支持任意未经处理的属性。语法为：name [=value] Keep-Alive首部只有在提供了Connection:Keep-Alive时才能使用。例如：12Connection:Keep-AliveKeep-Alive:max=5, timeout=120 Keep-Alive连接的限制和规则 在HTTP1.0中，keep-alive并不是默认使用的。客户端必须发送一个Connection:Keep-Alive请求首部来激活keep-alive连接； 代理或网关必须将报文转发或将其高速缓存之前，删除在Connection首部中命名的所有首部字段以及Connection首部自身。 不应该与无法确定是否支持Connection首部代理服务器建立keep-alive连接，以防止出现哑代理。 HTTP/1.1 持久连接(Persistent Connection)HTTP/1.1 持久连接在默认情况下是激活的，要在事务处理结束之后将连接关闭，HTTP/1.1应用程序必须向报文中显示的添加一个Connection:close首部。不然HTTP/1.1 连接就仍然维持在打开状态。 ⚠️不发送Connection:close并不意味着服务器承诺永远将连接保持在打开状态。 持久连接的限制和规则 发送了Connection:close请求首部之后，客户端就无法在那条连接上发送更多的请求了。 如果客户端不想再连接上发送其他请求，就应该在最后一条请求中发送一个Connection:close请求首部。 只有当连接上所有报文的实体主体部分的长度和首部字段Content Length一样（或者用分块传输编码方式），这样连接才能持久保持 HTTP1.1的代理服务器不应该与HTTP1.0客户端建立持久连接。 HTTP1.1设备可以在任意时刻关闭连接，尽管是出于传输报文的过程中关闭连接。 管道化连接HTTP1.1允许在持久连接上可选的使用请求管道。这是在keep-alive连接上的进一步性能优化。在响应到达前，可以将多条请求放入队列中，这样做可以降低网络的环回时间，提高性能。 管道化连接的几个限制 如果http客户端无法确认连接是持久的，就不应该使用管道； 必须按照与请求相同的顺序回送http响应。 http客户端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化请求。 http客户端不应该用管道化的方式发送会产生副作用的请求(比如POST)。 关闭连接在连接管理中需要知道什么时候关闭连接以及如何去关闭连接。 “任意”接触连接所有的HTTP客户端、服务器或者代理都可以在任意时刻关闭一条TCP传输连接。通常会在一条报文结束时关闭连接。 但是，服务器永远都无法确定在它关闭“空闲”连接那时候，在客户端有没有数据要发送。如果出现这种情况，客户端就会在写入半截请求报文时发现出现连接错误的请求。 Content-Length及截尾操作每条HTTP响应都应该有精确的Content-Length首部，用以描述响应主题的尺寸。客户端或者代理受到一条随连接关闭而结束的http响应，且实际传输的实体长度与Content-Length并不匹配，接收端就应该质疑长度的正确性。如果接收端是缓存代理，接收端就不应该缓存这条响应。代理应该将有问题的报文原封不动地转发出去，而不应该试图去“校正”Content-Length。 连接关闭容限，重试以及幂等性如果客户端执行事务的过程中，传输连接关闭了，那么除非事务处理会带来一些副作用，否则客户端就应该重新打开连接，并重试。 幂等如果一个事务，不管是执行一次还是多次，得到的结果都是相同的，那么这个事务就是幂等的。 GET、HEAD、PUT、DELETE、TRACE和OPTIONS方法都是的。 客户端不应该用管道化的方式传送非幂等请求(就是说比如POST请求不应该使用管道化方式)。 正常关闭连接TCP连接都是双向的。tcp连接的每一端都有一个输入队列和一个输出队列，用于数据的读或写。 完全关闭和半关闭应用程序可以关闭tcp输入和输出信道中的任意一个，或者将两者都关闭了。 套接字调用close()会将tcp连接的输入和输出信道都关闭，这就是完全关闭。用shutdown()单独关闭输入或者输出信道，被称为半关闭。 TCP关闭及重置错误总之，关闭连接的输出信道总是很安全的。连接另一端的对等实体会在其缓冲区中读出所有数据之后收到一条通知，说明流结束了。关闭连接的输入信道比较危险，除非你知道另一端不打算再发送其他数据。如果另一端向你已关闭的输入信道发送数据，操作系统会向另一端的机器回送一条TCP“连接被对端重置”。 大部分操作系统都会将这种情况作为严重错误来处理，删除对端还未读去的所有缓存数据。但是这样做对于管道化来说简直就是噩梦，因为:比如你已经在一条持久连接上发送了10条管道式请求，响应已经收到了，正在操作系统的缓存区中存着。但是你发送了第11条请求，但是服务器认为你使用这条连接的时间太长，决定将其关闭，这个重置信息会清空你的缓冲区。 正常关闭实现正常关闭的应用程序首先应该关闭它们的输出信道，然后等待另一端的对等实体关闭它的输出信道。当两端都告诉对方它们不会再发送任何数据之后，连接就会被完全关闭，而不会有重置风险。如果在一定的时间区间内对端没有关闭输入信道，应用程序可以强制关闭连接。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《C和指针Note》之数组和指针]]></title>
      <url>%2F2017%2F02%2F22%2Fc_and_pointer_note_case4%2F</url>
      <content type="text"><![CDATA[记录指针和数组直接的关系!当前C语言环境: Apple LLVM version 8.0.0 (clang-800.0.38) Target: x86_64-apple-darwin15.6.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin 一维数组数组名数组名的值是一个指针常量，也是数组第一个元素的地址。 注意⚠️数组具有确定的数量的元素，而指针只是一个标量值，只有数组名在表达式中使用时，编译器才会为他参数一个指针常量(意思就是你不能修改这个指针的值)。 指针常量所指向的是内存中数组的起始位置，如果修改这个指针常量，唯一可行的操作就是把整个数组移动到内存的其他位置，但是在程序完成链接之后，内存中数组的位置是固定的，所以当程序运行时，在想移动数组就晚了。 数组名不作为指针常量来表示的两种场景 注意：这里说的是不作为指针常量。 1.数组名作为sizeof操作符：sizeof返回整个数组所占用的字节，而不是每个元素所占用的字节，也不是指向数组的指针的长度。 2.数组名用于单目操作符&amp;时：返回一个指向数组的指针，而不是一个指向指针常量的指针。 int a[10]; int *c; c = &a[0];c = a;//这里赋值的是一个指针的拷贝。 下标引用和指针(间接取值操作)array[3]，*(array + 3)出了优先级之外，下标引用和间接访问完全相同。 int array[10];int *ap = array + 2; 1.ap:这是一个指针地址，所以该表达式和&amp;array[2]或者array+2相同。 2.*ap:间接访问，与array[2]和*(array + 2)相同。 3.ap[6]:C的下标引用和间接访问表达式是一样的，所以ap[6]和*(ap + 6)相同，与array[8]和*(array + 8)相同。 4.ap + 6:ap为一个指针地址，地址向后偏移6，则ap + 6和&amp;array[8]，array + 8相同。 5.*(ap + 6):上面说过ap+6为一个地址，由此可以得出*(ap+6)为间接求得地址对应的值，它和array[8]和*(array+8)相同，其实它和2&gt;.类似。 –&gt;6.ap[-1]:使用-1的偏移量使得道它前一个元素，也就是array[1]或者*(array + 2 - 1)。 上面说这么多，其实只要抓住：当前表示的地址，元素还是间接获取操作就可以了。 注意⚠️:上面提到的“C的下标引用和间接访问表达式是一样的”。 思考题:2[array]，这个表达式中的array是上文中的array。在这个上下文环境中，2[array]表达的意思是什么： 解答:因为前面我一直在强调，下标引用和间接表达式求值是相同的，所以: 第一步：我们可以把2[array]改写成*(2 + array) 第二步:由于加法运算符的两个操作数是可以交换位置的，所以把上面的表达式改写为:*(array + 2);也就是说2[array]其实和array[2]是相等的。 关于指针间接操作符和下标操作的比较 相对于指针的间接访问和下标操作，在可读性方面下标的方式更好，但是在执行效率上面下标不会比指针更有效率，但是指针有时候比下标效率更高。 具体的效率比较为: 1.当你根据某个固定数目的增量在一个数组中移动时，使用指针变量将比使用下标产生效率更高的代码。 2.声明为寄存器变量的指针通常比用于静态内存和堆栈中的指针效率更高。关于如何将变量声明为寄存器变量，我们可以使用register关键字来声明，比如:register int *p1;，register：这个关键字请求编译器尽可能的将变量存在CPU 内部寄存器中而不是通过内存寻址访问以提高效率。register 变量必须是一个单个的值，并且其长度应小于或等于整型的长度。而且register 变量可能不存放在内存中，所以不能用取址运算符“&amp;”来获取register 变量的地址。 3.像&amp;array[2]或者array+2这种在运行时求值的常量表达式代价很高。 数组的初始化数组的初始化需要一系列的值，例如： int array[5] = {1,2,3,4,5};//如果在初始化的时候，初始化的个数比数组的大小小的话，空余的元素将会被赋值为0。int array[] = {1,2,3,4,5};//如果在声明中没有给出数组的长度，编译器会把数组的长度设置为刚好能够容易所有初始值的长度。对于静态数组：存储于静态内存的数组只初始化一次，当程序执行时，静态数组已经初始化完毕。如果数组没有被初始化，数组元素的初始值将会自动设置为0。对于自动变量：由于自动变量位于运行时堆栈，所以自动变量在缺省的情况下是未被初始化的。所以这里需要思考的是：当数组的初始化在一个函数中，程序在每次进入该函数的时候，是否值得每次都对该数组重新进行初始化。如果不需要的的话，我们可以把该数组声明为static。 ######指定初始化器(c99)只初始化数组中的指定元素，方法是：在初始化列表中使用带方括号的下标指明待初始化的元素。1int array[5] = &#123;[5] = 23&#125;;//把array[5]初始化为23 多维数组如int xy[3][2]数组维数不止一个的称为多维数组。数组xy[3][2]在内存中的存储顺序为: (0,0) (0,1) (1,0) (1,1) (2,0) (2,1)//多维数组中的元素存储顺序按照最右边的下标率先变化的原则，称为行主序。关于是把第一个下标(上面定义的数组xy中的3)解释为行还是解释为列，都可以的，只要你在使用这个数组的时候使用同一种就可以。如果你把第一个下标解释为行第二个下标解释为列，那么当你按照存储顺序逐个访问数组元素时，所获得的元素是按行排列的，相反则是按列排列的。 数组名和下标int xy[3][2]，数组名xy是一个指向包涵2个整型元素的数组的指针（指向数组的指针）。下面我们来看看数组的下标和指针之间的关系: 1.xy:在三个包含两个整型元素的数组中，xy为指向第一个子数组。（注意：这是指针，说明了指向） 2.xy + 1:在三个包含两个整型元素的数组中，xy为指向第二个子数组，+1是根据包含2个整型元素的数组长度进行调整的，所以是指向第二个子数组。（注意：同上，这是指针，说明了指向） 3.*(xy + 1):获取指向第二个子数组的指针，通过间接操作符得到这个子数组，或者可以把该表达式写为xy[1]（即表示的是第二个子数组）。 4.*(xy + 1) ＋ 1：在第三点中我们取得了第二个子数组，记得我们在上面讲一维数组的时候，获取数组第n个元素的地址的办法是:array + n或者&amp;array[n]，在和*(xy + 1) ＋ 1进行对比之后不难发现，其表达的意思就是获取第二个子数组中第2个元素（因为数组下标是从0开始）的地址或者可以把该表达式写为xy[1] ＋ 1（注意：同上，这是指针，是一个地址） 5.*(*(xy + 1) + 1)：由间接操作符，获得第4点中的指针指向的具体元素。同上我们可以写为:*(xy[1] + 1)，进一步改写xy[1][1]; 指向数组的指针int vector[10];int matrix[3][4];int *vp = vector;int (*mp)[10] = matrix;//下标引用的优先级是高于间接引用的，所以我们需要在间接引用这里手动加上括号才行所以mp是一个指向整型数组的指针，vp是指向整型变量的指针。 这里需要注意一下：一定不要把指向数组的指针和指针数组浓混了，那个确保算术优先级的括号是很重要的，int (*mp)[10]代表的是指向数组的指针，而int *mp[10]表示的是指针数组。 当数组作为函数的参数的时候，多维数组和一维数组相同，都是用指针作为参数进行传递，这个指针是指向数组第一个元素的指针。 一维数组作为函数参数的函数声明形式实参：int vectors[10];函数声明:void vector(int *vec);或者void vector (int vet[]) 多维数组作为函数参数的函数声明形式实参：int matrixs[3][10];函数声明:void matrix(int (*mat)[10]);或者void matrix(int mat[][10]);void matrix(int mat[][10]);这里的关键在于编译器必须知道第二个及以后各维的长度才能对各下标进行求值，因此在原型中必须声明这个维的长度 关于多维数组初始化 第一种方式:int xy[3][2] = {1,2,3,4,5,6};这种就是在声明变量的时候就在后面跟着一长串的初始数据。 第二种方式:int xy[3][2];xy[0][0] = 1;xy[0][1] = 2;…xy[2][0] = 5xy[2][1] = 6;这和第一种的差别就在于，这一种是对数组元素一个一个的去赋值，这种存储顺序是以最右边下标率先变化的（前面注释提到的行主序）。 第三种方式:因为多维数组可以看成是每个元素由一个子数组组成，所以我们可以按照一个子数组为一个个体来初始化。int xy[3][2] = {{1,2},{3,4},{5,6}};这样看起来和第一种的方式是有点类似的。 总结 1 .数组变量是const指针，所以是不能被赋值的； 2.如果指针指向的不是一片连续的空间，那么对地址进行加操作（或者减操作）是没有意义；]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《C和指针Note》之指针]]></title>
      <url>%2F2017%2F02%2F22%2Fc_and_pointer_note_case3%2F</url>
      <content type="text"><![CDATA[指针。当前C语言环境: Apple LLVM version 8.0.0 (clang-800.0.38) Target: x86_64-apple-darwin15.6.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin 粗略的总结一下知识点 1.变量标识符与内存位置之间的关联并不是硬件提供的，而是编译器为我们提供的，硬件仍然通过地址访问内存位置。 2.数组中的元素存储于连续的内存地址中。 3.NULL指针作为一个不指向任何东西的特殊指针。在对指针进行解引用操作之前，必须确保它不是NULL指针(因为对一个NULL指针进行解引用是非法操作)。 4.指针的指针中，操作符具有从右向左的结合性，所以这个表达式相当于`(*c)`，所以可以从里向外求值。对于如下代码中:int a = 10; int *b = &a; int **c = &b; 表达式 相当的表达式 a 10 b &amp;a *b 12,a c &amp;b *c &amp;a,b **c 12,a,*b 注意⚠️在指针没有被初始化之前，一定不要对这个指针变量使用间接操作符。 习题练习纪录 1.字符串查找相关，两个字符串中找出第一个相同的字符串。解答: char *find_char(char const *source,char const *chars){ if (source == NULL || chars == NULL) { return NULL; } char const *f_p = chars; do { do { if (*source == *chars) { char *result = (char *)source; char *cp; *cp = *result; return cp; } } while (*chars++ != '\0'); chars = f_p; } while (*source++ != '\0'); return NULL; }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《C和指针Note》之操作符和表达式]]></title>
      <url>%2F2017%2F02%2F22%2Fc_and_pointer_note_case2%2F</url>
      <content type="text"><![CDATA[这篇主要记录操作符和表达式相关的只是！当前C语言环境:1234Apple LLVM version 8.0.0 (clang-800.0.38)Target: x86_64-apple-darwin15.6.0Thread model: posixInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin 移位操作符左移操作符&lt;&lt;,右移操作符&gt;&gt;;而且位移的操作数必须是整数类型。其中右移操作符存在两种情况：算术移位和逻辑移位；这里主要来说一说算术移位。 逻辑移位左边移入的位用0填充 算术移位算术移位也就是说会考虑到符号位，即左边移入的位由原值的符号位决定，如果符号位为1则移入的位为1，符号位为0则移入的位为0；对于移位操作，还必须知道数字在计算机中是以二进制的形式存在的，而且负数的表示形式还稍有不同。 负数在计算机中的二进制表示形式 假设在当前计算机中，int型占8位。比如要知道数字-10在计算机的表现形式，第一步：数字10的二进制值为00001010，第二步用100000000来减去00001010。得到的就是-10在二进制中的表现形式为:11110110。更多关于负数补码的介绍阮一峰的网络日志－－关于2的补码 这里我举例说明一下移位操作: int uint = 10; //00001010int sint = -10;//11110110printf(“%d\n”,uint &gt;&gt; 2);//00000010printf(“%d\n”,sint &gt;&gt; 2);//11111101在当前环境下： Apple LLVM version 8.0.0 (clang-800.0.38)Target: x86_64-apple-darwin15.6.0Thread model: posixInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin打印的结果分别为2和-3,所以从这里看出来编译器对于左移操作是算术移位。 ++和–操作符对于这两个操作符的计算就很简单了，还是来举例说明一下: int a,b,c,d;a = b = 10;c = ++a;d = b++;但是需要来理解这其中的原理: ++和–操作符原理抽象的说，前缀和后缀形式的增值操作符都复制一份变量值的拷贝，这些操作符的结果不是被他们所修改的变量，而是变量值的拷贝。 逗号操作符逗号操作符将多个表达式分隔开，这些表达式从左向右逐个进行求值，__整个逗号表达式的值就是最后那个表达式的值。 int (^f1)(int) = ^(int value){ return value + 1;};int (^f2)(int) = ^(int value){ return value + 2;};int (^f3)(int,int) = ^(int a,int b){ return a + b;};int x,a,b,c;x = 0;//从这里开始a = f1(x);b = f2(x + a);for (c = f3(a,b); c &lt; 10; c = f3(a,b)) { printf(“while statements c is:%d\n”,c); a = f1(++x); b = f2(x + a);}//到这里结束，这其中的代码将会被修改上面为原始的代码片段，现在我们需要使用逗号操作符来简化上面的代码，同时我选择用while循环来代替for循环。 while (a = f1(x),b = f2(x + a),c = f3(a,b),++x,c &lt; 10) { printf(“while statements c is:%d\n”,c);}现在，循环中用于获得下一个值的语句只需要出现一次，逗号操作符使源码更易于维护。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[《C和指针Note》之基础]]></title>
      <url>%2F2017%2F02%2F20%2Fc_and_pointer_note_base%2F</url>
      <content type="text"><![CDATA[C存在两种不同的环境：翻译环境和执行环境;翻译环境是将源代码转换为可执行的机器指令，而执行环境用于实际执行代码。 翻译其中翻译阶段主要包括了编译和链接两部分。 __ 编译将源代码转换为目标代码的过程，在这个过程中包含了预处理（预处理相关操作，比如define替换为实际值）和解析（判断源代码的意思），在最后生成目标代码（机器指令的初步形式）。 链接链接器会把各个目标文件捆绑起来形成一个可执行程序。在这个过程中会引入c函数库。 执行程序载入到内存中，并初始化在堆栈中没有初始化的变量。 __ 运行时堆栈用户保存函数的局部变量和返回值。 静态内存存储在静态内存中的变量将会在程序执行期间一直保留！ 程序的终止可以是main函数完成返回，也可以是主动执行了exit。 一个技巧如果在使用注释的时候/**/嵌套了多层会导致注释失效，这时候我们可以在最外层添加:123#if 0//中间为代码#endif 而且在使用注释的时候并不会把注释掉的部分从源代码中删除，只是不去执行而已，使用if endif的话是在逻辑上删除了这一段代码的。这在后面的预处理器那一节会讲更多。]]></content>
    </entry>

    
  
  
</search>
